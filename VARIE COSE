#MCLUSTICL SU PCA 
# Carica le librerie necessarie
library(terra)     # Per la gestione dei raster
library(mclust)    # Per Mclust e mclustICL

# Step 1: Caricamento dell'immagine e creazione dello stack
setwd("C:/composite")  # Imposta la directory di lavoro

# Calcolo del tempo di esecuzione per il caricamento dell'immagine e la creazione dello stack
time_stack_creation <- system.time({
    # Carica il raster multibanda
    img_84 <- rast("ritaglio.tif")
    
    # Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
    l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
    
    # Calcola gli indici NDVI, MNDWI e NDBI
    ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
    mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
    ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])
    
    # Crea lo stack con le bande selezionate e gli indici calcolati
    stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)
    
    # Estrai i valori del raster stack come dataframe e rimuovi i valori NA
    values_stack_1984 <- as.data.frame(values(stack_1984))
    values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]
})

# Stampa il tempo di esecuzione dello stack
print(paste("Tempo di esecuzione per creazione stack e estrazione valori: ", time_stack_creation["elapsed"], "secondi"))

# Step 2: Calcolo del tempo di esecuzione per la PCA sui dati
time_pca <- system.time({
    # Esegui la PCA su tutti i dati scalati (senza NA)
    pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)
    
    # Seleziona le prime 2 componenti principali
    pca_2comp <- pca_result$x[, 1:2]
})

# Stampa il tempo di esecuzione della PCA
print(paste("Tempo di esecuzione per PCA: ", time_pca["elapsed"], "secondi"))

# Step 3: Calcolo del tempo di esecuzione per mclustICL sulle prime due componenti della PCA
time_icl <- system.time({
    # Calcolo di mclustICL sulle prime due componenti della PCA
    icl_result <- mclustICL(pca_2comp)
})

# Stampa il tempo di esecuzione di mclustICL
print(paste("Tempo di esecuzione per mclustICL: ", time_icl["elapsed"], "secondi"))

# Visualizza i risultati di mclustICL
print(icl_result)


















#PCA 2 COMP CON MCLUSTICL
# Carica le librerie necessarie
library(terra)     # Per la gestione dei raster
library(mclust)    # Per Mclust e mclustICL

# Step 1: Caricamento dell'immagine e creazione dello stack
setwd("C:/composite")  # Imposta la directory di lavoro

# Calcolo del tempo di esecuzione per il caricamento dell'immagine e la creazione dello stack
time_stack_creation <- system.time({
    # Carica il raster multibanda
    img_84 <- rast("L5 Composite 1984-1990_masked.tif")
    
    # Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
    l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
    
    # Calcola gli indici NDVI, MNDWI e NDBI
    ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
    mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
    ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])
    
    # Crea lo stack con le bande selezionate e gli indici calcolati
    stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)
    
    # Estrai i valori del raster stack come dataframe e rimuovi i valori NA
    values_stack_1984 <- as.data.frame(values(stack_1984))
    values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]
})

# Stampa il tempo di esecuzione dello stack
print(paste("Tempo di esecuzione per creazione stack e estrazione valori: ", time_stack_creation["elapsed"], "secondi"))

# Step 2: Calcolo del tempo di esecuzione per la PCA sui dati
time_pca <- system.time({
    # Esegui la PCA su tutti i dati scalati (senza NA)
    pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)
    
    # Seleziona le prime 2 componenti principali
    pca_2comp <- pca_result$x[, 1:2]
})

# Stampa il tempo di esecuzione della PCA
print(paste("Tempo di esecuzione per PCA: ", time_pca["elapsed"], "secondi"))

# Step 3: Calcolo del tempo di esecuzione per mclustICL sulle prime due componenti della PCA
time_icl <- system.time({
    # Calcolo di mclustICL sulle prime due componenti della PCA
    icl_result <- mclustICL(pca_2comp)
})

# Stampa il tempo di esecuzione di mclustICL
print(paste("Tempo di esecuzione per mclustICL: ", time_icl["elapsed"], "secondi"))

# Visualizza i risultati di mclustICL
print(icl_result)

# Top 3 models based on the ICL criterion: 
#  VVV,4    VEV,4    VVV,5 
#-7867938 -7908104 -7917934 
# "Tempo di esecuzione per mclustICL:  8047.76 secondi"













#PCA 3 COMP PARALLEL MCLUSTICL

# Carica le librerie necessarie
library(terra)     # Per la gestione dei raster
library(mclust)    # Per Mclust e mclustICL
library(parallel)  # Per parallelizzazione

# Imposta il numero di core disponibili per la parallelizzazione
numCores <- detectCores()   # Usa n-1 core per non sovraccaricare il sistema
cl <- makeCluster(numCores)    # Crea un cluster con il numero di core disponibili

# Carica il pacchetto mclust su ogni core del cluster
clusterEvalQ(cl, library(mclust)) # Esegue library(mclust) su ogni nodo del cluster

# Step 1: Caricamento dell'immagine e creazione dello stack
setwd("C:/composite")  # Imposta la directory di lavoro

# Calcolo del tempo di esecuzione per il caricamento dell'immagine e la creazione dello stack
time_stack_creation <- system.time({
    # Carica il raster multibanda
    img_84 <- rast("L5 Composite 1984-1990_masked.tif")
    
    # Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
    l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
    
    # Calcola gli indici NDVI, MNDWI e NDBI
    ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
    mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
    ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])
    
    # Crea lo stack con le bande selezionate e gli indici calcolati
    stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)
    
    # Estrai i valori del raster stack come dataframe e rimuovi i valori NA
    values_stack_1984 <- as.data.frame(values(stack_1984))
    values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]
})

# Stampa il tempo di esecuzione dello stack
print(paste("Tempo di esecuzione per creazione stack e estrazione valori: ", time_stack_creation["elapsed"], "secondi"))

# Step 2: Calcolo del tempo di esecuzione per la PCA sui dati
time_pca <- system.time({
    # Esegui la PCA su tutti i dati scalati (senza NA)
    pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)
    
    # Seleziona le prime 3 componenti principali
    pca_3comp <- pca_result$x[, 1:3] 
})

# Stampa il tempo di esecuzione della PCA
print(paste("Tempo di esecuzione per PCA: ", time_pca["elapsed"], "secondi"))

# Step 3: Calcolo del tempo di esecuzione per mclustICL sulle prime tre componenti della PCA
# Esporta le variabili e le funzioni necessarie al cluster
clusterExport(cl, varlist = c("pca_3comp", "mclustICL"))

# Calcolo di mclustICL parallelizzando con parLapply
time_icl <- system.time({
    # Esegui `mclustICL` su tutti i core del cluster
    icl_result <- parLapply(cl, 1, function(i) mclustICL(pca_3comp))[[1]]
})

# Stampa il tempo di esecuzione di mclustICL
print(paste("Tempo di esecuzione per mclustICL: ", time_icl["elapsed"], "secondi"))

# Visualizza i risultati di mclustICL
print(icl_result)

# Chiudi il cluster
stopCluster(cl)

#inutile il parallelo
#Top 3 models based on the ICL criterion: 
#   VEV,5    VVV,4    VVV,5 
# -8832930 -8851853 -8881968 





#GOMITO CON KMEANS++ FONTE LIBRONE Learning Analytics Methods and Tutorials, però usando un altro kmeasn++ rispetto a quello del libro perchè rompe il cazzo con i passi

# Installa la libreria ClusterR se non è presente
if (!require("ClusterR")) {
  install.packages("ClusterR")
}
library(ClusterR)

# Imposta la working directory
setwd("C:/composite")

# Carica le librerie necessarie
library(terra)
library(cluster)
library(rio)
library(tidyverse)
library(stats)

# Carica l'immagine ritaglio.tif
img_84 <- rast("ritaglio.tif")

# Controlla i dettagli dell'immagine caricata
print(img_84)

# Seleziona le bande desiderate dall'immagine
# Ad esempio: Bande 1, 2, 3, 4, 5, e 7 (adatta in base al tuo raster)
selected_bands <- c(1, 2, 3, 4, 5, 7)
img_selected <- subset(img_84, selected_bands)

# Calcolo degli indici spettrali (NDVI, MNDWI, NDBI)
# NDVI: (B4 - B3) / (B4 + B3)
ndvi <- (img_selected[[4]] - img_selected[[3]]) / (img_selected[[4]] + img_selected[[3]])

# MNDWI: (B2 - B5) / (B2 + B5)
mndwi <- (img_selected[[2]] - img_selected[[5]]) / (img_selected[[2]] + img_selected[[5]])

# NDBI: (B5 - B4) / (B5 + B4)
ndbi <- (img_selected[[5]] - img_selected[[4]]) / (img_selected[[5]] + img_selected[[4]])

# Crea lo stack con le bande selezionate e gli indici
stack_1984 <- c(img_selected, ndvi, mndwi, ndbi)

# Assegna i nomi ai layer dello stack
names(stack_1984) <- c("B1", "B2", "B3", "B4", "B5", "B7", "NDVI", "MNDWI", "NDBI")

# Appiattisci lo stack in una matrice per l'analisi della PCA
stack_values <- values(stack_1984, na.rm = TRUE)

# Calcolo della PCA utilizzando tutte le bande e gli indici
pca_result <- prcomp(stack_values, scale. = TRUE, center = TRUE)

# Visualizza i risultati della PCA
summary(pca_result)

# Estrai le prime tre componenti principali
pca_values <- pca_result$x[, 1:3]

# Converte i valori PCA in una matrice per ClusterR
pca_matrix <- as.matrix(pca_values)

# Inizializzazione delle variabili per il metodo del gomito
K <- 10  # Numero massimo di cluster da testare
TWCSS <- numeric(K)  # Vettore per memorizzare i valori TWCSS
KM <- vector("list", K)  # Lista per memorizzare i modelli K-means

# Esegui il metodo del gomito per diversi valori di K utilizzando KMeans_rcpp con K-means++
for (k in 1:K) {
  set.seed(42)  # Per garantire la riproducibilità dei risultati
  
  # Esegui KMeans_rcpp con inizializzazione K-means++
  km_model <- KMeans_rcpp(pca_matrix, clusters = k, num_init = 10, max_iters = 100, initializer = 'kmeans++')
  
  # Memorizza il modello K-means
  KM[[k]] <- km_model
  
  # Estrai il valore TWCSS per il corrente valore di k
  TWCSS[k] <- sum(km_model$WCSS_per_cluster)  # Somma delle distanze intra-cluster
}

# Plot del metodo del gomito
plot(1:K, TWCSS, type = "b", pch = 19, col = "blue",
     xlab = "Numero di Cluster (K)", ylab = "Total Within-Cluster Sum-of-Squares (TWCSS)",
     main = "Metodo del Gomito per Determinare il Numero Ottimale di Cluster")





#GOMITO CON MATRICE DISTANZE 1 PER CENTO IMMAGINE

# Imposta la working directory
setwd("C:/composite")

# Carica le librerie necessarie
library(terra)
library(cluster)
library(rio)
library(tidyverse)
library(stats)

# Carica l'immagine L5 Composite 1984-1990_masked.tif
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Controlla i dettagli dell'immagine caricata
print(img_84)

# Seleziona le bande desiderate dall'immagine
# Ad esempio: Bande 1, 2, 3, 4, 5, e 7 (adatta in base al tuo raster)
selected_bands <- c(1, 2, 3, 4, 5, 7)
img_selected <- subset(img_84, selected_bands)

# Calcolo degli indici spettrali (NDVI, MNDWI, NDBI)
ndvi <- (img_selected[[4]] - img_selected[[3]]) / (img_selected[[4]] + img_selected[[3]])
mndwi <- (img_selected[[2]] - img_selected[[5]]) / (img_selected[[2]] + img_selected[[5]])
ndbi <- (img_selected[[5]] - img_selected[[4]]) / (img_selected[[5]] + img_selected[[4]])

# Crea lo stack con le bande selezionate e gli indici
stack_1984 <- c(img_selected, ndvi, mndwi, ndbi)

# Assegna i nomi ai layer dello stack
names(stack_1984) <- c("B1", "B2", "B3", "B4", "B5", "B7", "NDVI", "MNDWI", "NDBI")

# Appiattisci lo stack in una matrice per il campionamento
stack_values <- values(stack_1984, na.rm = TRUE)

# Calcola il numero di campioni (10% dei pixel)
set.seed(42)  # Per garantire la riproducibilità del campionamento
sample_size <- round(0.001 * nrow(stack_values))  # Calcola il 10% dei pixel
sample_indices <- sample(1:nrow(stack_values), sample_size)  # Estrai gli indici campionati

# Seleziona i campioni dai valori dello stack
sampled_values <- stack_values[sample_indices, ]

# Calcolo della PCA utilizzando il campionamento dei pixel
pca_result <- prcomp(sampled_values, scale. = TRUE, center = TRUE)

# Visualizza i risultati della PCA
summary(pca_result)

# Estrai le prime tre componenti principali dal campionamento
pca_values <- pca_result$x[, 1:3]

# Converti le componenti principali in un dataframe per il calcolo delle distanze
pca_df <- as.data.frame(pca_values)

# Calcolo delle distanze utilizzando le prime tre componenti principali

# Distanza Euclidea
dist_euclidean <- dist(pca_df, method = "euclidean")

# Distanza Manhattan
dist_manhattan <- dist(pca_df, method = "manhattan")

# Distanza Minkowski con p=3 (la funzione dist di base non supporta p, quindi usiamo proxy)
library(proxy)
dist_minkowski3 <- proxy::dist(pca_df, method = "Minkowski", p = 3)

# Visualizza un'anteprima delle prime righe delle distanze calcolate
cat("Distanza Euclidea (prime 5 righe e colonne):\n")
print(as.matrix(dist_euclidean)[1:5, 1:5])

cat("Distanza Manhattan (prime 5 righe e colonne):\n")
print(as.matrix(dist_manhattan)[1:5, 1:5])

cat("Distanza Minkowski con p=3 (prime 5 righe e colonne):\n")
print(as.matrix(dist_minkowski3)[1:5, 1:5])




#CH con rasterPCA



# Carica le librerie necessarie
library(terra)
library(RStoolbox)    # Per rasterPCA
library(ClusterR)
library(cluster)
library(fpc)
library(ggplot2)

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
bands <- img[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi <- (bands[[4]] - bands[[3]]) / (bands[[4]] + bands[[3]])
mndwi <- (bands[[2]] - bands[[5]]) / (bands[[2]] + bands[[5]])
ndbi <- (bands[[5]] - bands[[4]]) / (bands[[5]] + bands[[4]])

# Assegna i nomi specifici agli indici
names(ndvi) <- "NDVI"
names(mndwi) <- "MNDWI"
names(ndbi) <- "NDBI"

# Crea lo stack (stack di bande + indici)
stack <- c(bands, ndvi, mndwi, ndbi)

# Esegui la PCA utilizzando rasterPCA su tutte le bande e indici
pca_result <- rasterPCA(stack, nComp = 10, spca = FALSE, maskCheck = TRUE)

# Estrai i valori delle prime 2 componenti principali
pca_values <- as.data.frame(values(pca_result$map[[1:2]]))
pca_values_non_na <- pca_values[complete.cases(pca_values), ]

# Definisci il numero minimo e massimo di cluster da testare
k_min <- 2
k_max <- 15

# Inizializza un vettore per memorizzare i valori dell'indice CH
ch_values <- numeric(k_max - k_min + 1)

# Misura il tempo di esecuzione
start_time <- Sys.time()

# Ciclo for tradizionale per calcolare l'indice CH senza parallelismo
for (k in k_min:k_max) {
    # Esegui il clustering K-means++ sui primi due componenti della PCA
    kmeans_result <- KMeans_rcpp(pca_values_non_na, clusters = k, num_init = 5, initializer = "kmeans++", seed = 12)
    
    # Calcola l'indice Calinski-Harabasz
    ch_index <- calinhara(pca_values_non_na, kmeans_result$clusters)
    
    # Memorizza il valore dell'indice CH
    ch_values[k - k_min + 1] <- ch_index
}

# Calcola il tempo di esecuzione totale
end_time <- Sys.time()
execution_time <- end_time - start_time

# Crea un data frame per visualizzare i risultati
ch_df <- data.frame(Clusters = k_min:k_max, CH_Index = ch_values)

# Trova il numero ottimale di cluster basato sul massimo dell'indice CH
optimal_clusters <- ch_df$Clusters[which.max(ch_df$CH_Index)]

# Visualizza i risultati con ggplot2 e aggiungi una linea verticale al valore ottimale
ggplot(ch_df, aes(x = Clusters, y = CH_Index)) +
    geom_line(color = "blue", size = 1.2) +
    geom_point(color = "red", size = 3) +
    geom_vline(xintercept = optimal_clusters, linetype = "dashed", color = "green", size = 1.2) +
    ggtitle(paste("Calinski-Harabasz Index vs Number of Clusters\nOptimal Number of Clusters:", optimal_clusters)) +
    xlab("Number of Clusters") +
    ylab("Calinski-Harasz Index") +
    theme_minimal()

# Stampa il tempo di esecuzione totale
print(paste("Tempo di esecuzione totale senza parallelismo:", execution_time))






#DB CON RASTERpca PARALLLEO

# Carica le librerie necessarie
library(terra)         # Per la gestione dei raster
library(RStoolbox)     # Per rasterPCA
library(clusterSim)    # Per calcolare l'indice Davies-Bouldin
library(ClusterR)      # Per K-means++
library(cluster)       # Per il coefficiente silhouette
library(doParallel)    # Per il parallelismo
library(foreach)       # Per il ciclo parallelo

# Step 1: Caricamento dell'immagine e creazione dello stack
setwd("C:/composite")  # Imposta la directory di lavoro

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Step 2: Esecuzione della PCA sui dati usando rasterPCA
# Esegui la PCA su tutto lo stack
pca_result <- rasterPCA(stack_1984, nComp = 10, spca = FALSE, maskCheck = TRUE)

# Estrai le prime 2 componenti principali
pca_2comp <- as.data.frame(values(pca_result$map[[1:2]]))
pca_2comp_non_na <- pca_2comp[complete.cases(pca_2comp), ]

# Step 3: Configurazione del parallelismo
# Trova il numero di core disponibili
num_cores <- detectCores() - 1  # Utilizza un numero di core inferiore a quello massimo disponibile
cat("Numero di core utilizzati per il parallelismo:", num_cores, "\n")

# Crea il cluster e registra il parallel backend
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# Inizializza il vettore per memorizzare i valori di Davies-Bouldin
max_clusters <- 20  # Numero massimo di cluster da testare
db_values <- numeric(max_clusters)

# Step 4: Calcolo dell'indice Davies-Bouldin in parallelo
start_time <- Sys.time()  # Registra il tempo di inizio

# Usa foreach per parallelizzare il ciclo
db_values <- foreach(k = 2:max_clusters, .combine = c, .packages = c("ClusterR", "clusterSim")) %dopar% {
    # Esegui K-means++ con il numero di cluster k
    set.seed(42)  # Per riproducibilità
    kmeans_model <- KMeans_rcpp(pca_2comp_non_na, clusters = k, verbose = FALSE)
    
    # Assegna le etichette ai cluster
    clusters <- kmeans_model$clusters
    
    # Calcola l'indice Davies-Bouldin utilizzando clusterSim
    db_value <- index.DB(pca_2comp_non_na, clusters)$DB
    db_value
}

end_time <- Sys.time()  # Registra il tempo di fine
execution_time <- end_time - start_time  # Calcola la durata del processo
cat("Tempo totale di esecuzione:", execution_time, "\n")

# Stoppa il cluster per il parallelismo
stopCluster(cl)
registerDoSEQ()  # Torna alla modalità sequenziale

# Step 5: Visualizzazione dell'indice Davies-Bouldin con linea per il cluster ottimale
# Trova il numero ottimale di cluster basato sul valore minimo di DB
optimal_clusters_db <- which.min(db_values) + 1
cat("Numero ottimale di cluster basato sull'indice Davies-Bouldin:", optimal_clusters_db, "\n")

# Crea il grafico dell'indice Davies-Bouldin con linea verticale sul cluster ottimale
plot(2:max_clusters, db_values, type = "b", pch = 19, col = "red",
     main = "Indice Davies-Bouldin per Numero di Cluster",
     xlab = "Numero di Cluster", ylab = "Valore Davies-Bouldin (minore è meglio)")

# Aggiungi una linea verticale sul numero di cluster ottimale
abline(v = optimal_clusters_db, col = "blue", lty = 2, lwd = 2)

# Aggiungi testo al grafico per indicare il cluster ottimale
text(optimal_clusters_db, min(db_values), labels = paste("Cluster ottimale:", optimal_clusters_db), 
     col = "blue", pos = 4, cex = 0.8)







#SOM NBCLUST KMEANS 

# Carica le librerie necessarie
library(terra)         # Per la gestione dei raster
library(kohonen)       # Per la Self-Organizing Map (SOM)
library(NbClust)       # Per determinare il numero ottimale di cluster
library(leaflet)       # Per visualizzare i risultati
library(viridisLite)   # Per la palette turbo
library(ClusterR)      # Per K-means++
library(dplyr)         # Per la manipolazione dei dati

# Step 1: Caricamento dell'immagine e creazione dello stack
setwd("C:/composite")  # Imposta la directory di lavoro

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Step 2: Esecuzione della Self-Organizing Map (SOM)
# Definisci la griglia per la SOM (esempio 5x5)
som_grid <- somgrid(xdim = 5, ydim = 5, topo = "hexagonal")

# Esegui la SOM sui valori delle bande e degli indici
som_model <- som(as.matrix(values(stack_1984, na.rm = TRUE)), grid = som_grid, rlen = 100, alpha = c(0.05, 0.01))

# Ottieni i codici della SOM (prototipi)
som_codes <- som_model$codes[[1]]

# Step 3: Usa NbClust sui valori della SOM per determinare il numero ottimale di cluster
set.seed(123)
nbclust_result <- NbClust(data = som_codes, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "all")

# Determinazione automatica del numero ottimale di cluster
best_cluster_numbers <- nbclust_result$Best.nc[1, ]  # Estrae il numero di cluster suggerito da ciascun indice
optimal_clusters_nbclust <- as.numeric(names(which.max(table(best_cluster_numbers))))  # Calcola la modalità
cat("Numero ottimale di cluster basato sugli indici di NbClust:", optimal_clusters_nbclust, "\n")

# Step 4: Esegui K-means con il numero di cluster ottimale trovato da NbClust
kmeans_nbclust <- kmeans(som_codes, centers = optimal_clusters_nbclust, nstart = 100)

# Step 5: Creazione del raster classificato
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))  # Crea una maschera dai valori non NA del raster originale
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Step 6: Visualizza il raster classificato con leaflet
leaflet() %>% 
  # Aggiungi le tiles di base
  addTiles(group = "OpenStreetMap") %>% 
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
  
  # Aggiungi il raster classificato da NbClust con trasparenza
  addRasterImage(classified_raster_nbclust_single, 
                 colors = palette_turbo(optimal_clusters_nbclust), 
                 opacity = 0.6, 
                 group = "Classificato con NbClust") %>% 
  
  # Aggiungi i controlli per cambiare i layer di base e i gruppi di layer
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),  # Layer di base
    overlayGroups = c("Classificato con NbClust"),  # Layer classificati
    options = layersControlOptions(collapsed = FALSE)  # Espandi il menu dei layer di default
  ) %>% 
  
  # Aggiungi una barra di scala
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
  
  # Centra la mappa sul raster (modifica i valori per il tuo AOI)
  setView(lng = 16.5, lat = 39.0, zoom = 10)










# Carica le librerie necessarie
check_and_install <- function(packages) {
  installed <- packages %in% rownames(installed.packages())
  if (any(!installed)) {
    install.packages(packages[!installed])
  }
  invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr","factoextra","cluster", "kohonen", "parallel", "leaflet", "ggplot2", "viridis")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime due componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime due componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))
# [1] "Numero di osservazioni valide: 1069509"

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))
# [1] "Numero suggerito di neuroni: 5171"

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))
# [1] "Dimensioni della griglia suggerite: 72 x 72"

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input e alpha = 0
som_model <- supersom(
  list(pca_values), 
  grid = som_grid, 
  rlen = 500, 
  alpha = 0,                  # Imposta alpha a 0 per non avere apprendimento progressivo
  radius = quantile(dist(som_grid$pts), 2/3), 
  mode = "pbatch", 
  cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]


# Elbow method for kmeans
fviz_nbclust(som_values, kmeans, method = "wss") +
  geom_vline(xintercept = 3, linetype = 2)

# Average silhouette for kmeans
fviz_nbclust(som_values, kmeans, method = "silhouette")

# Compute gap statistic for kmeans
# we used B = 10 for demo. Recommended value is ~500
gap_stat <- clusGap(som_values, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 500)
print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)

# Gap statistic for hierarchical clustering
gap_stat <- clusGap(som_values, FUN = hcut, K.max = 10, B = 500)
fviz_gap_stat(gap_stat)











# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime due componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:2]  # Seleziona solo le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input
som_model <- supersom(
  list(pca_values), 
  grid = som_grid, 
  rlen = 1000, 
  
  radius = quantile(dist(som_grid$pts), 2/3), 
  mode = "pbatch", 
  cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

df<-as.data.frame(som_values)

mc<-Mclust(df,G=1:20)


fviz_mclust(mc, "BIC", palette = "jco")

icl<-mclustICL(df,G=1:20)

# Salva l'oggetto som_values come file RDS
saveRDS(som_values, "som_values_immagine_composita_84_90_sila_masked_rlen_1000_72X72_PCA_2_comp.rds")

# comunque 10 cluster con BIC e modello VVV
