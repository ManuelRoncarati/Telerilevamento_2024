# PCA sui Dati Grezzi (Preâ€‘SOM)
# Carica le librerie necessarie
library(terra)
library(factoextra)
library(ggplot2)

# Specifica la cartella contenente le immagini .tif
image_dir <- "C:/PN_Sila"
image_files <- list.files(path = image_dir, pattern = "\\.tif$", full.names = TRUE)

# Seleziona il primo file .tif trovato
if (length(image_files) == 0) {
  stop("Nessuna immagine .tif trovata nella cartella.")
}
first_image <- image_files[1]

# Carica il raster multibanda
raster_image <- rast(first_image)

# Calcola gli indici:
# NDVI = (NIR - Red) / (NIR + Red) (assumendo banda 4 = NIR, banda 3 = Red)
ndvi  <- (raster_image[[4]] - raster_image[[3]]) / (raster_image[[4]] + raster_image[[3]])
# MNDWI = (Green - SWIR) / (Green + SWIR) (assumendo banda 2 = Green, banda 5 = SWIR)
mndwi <- (raster_image[[2]] - raster_image[[5]]) / (raster_image[[2]] + raster_image[[5]])
# NDBI = (SWIR - NIR) / (SWIR + NIR) (assumendo banda 5 = SWIR, banda 4 = NIR)
ndbi  <- (raster_image[[5]] - raster_image[[4]]) / (raster_image[[5]] + raster_image[[4]])

# Crea uno stack con le bande originali ed i nuovi indici
stacked_raster <- c(raster_image, ndvi, mndwi, ndbi)

# Estrai i valori come matrice e rimuovi le righe contenenti NA
matrix_values <- values(stacked_raster)
cleaned_matrix <- matrix_values[complete.cases(matrix_values), ]

# Funzione per la normalizzazione Min-Max
normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

# Normalizza ogni colonna dell'intero dataset
normalized_matrix <- apply(cleaned_matrix, 2, normalize)

# Esegue la PCA sull'intero set di dati normalizzati
pca_raw <- prcomp(normalized_matrix)

# Visualizza il plot PCA sui dati reali (Pre-SOM) con il tema personalizzato
p1 <- fviz_pca_ind(pca_raw, 
             title = "PCA - Raw Data",
             geom = "point", 
             ggtheme = theme_classic()) +
    theme(
        plot.title = element_text(size = 25, face = "bold"),
        axis.title = element_text(size = 25),
        axis.text = element_text(size = 25)
    )
print(p1)

# Genera un dataset casuale con la stessa struttura dei dati reali
random_df <- as.data.frame(apply(normalized_matrix, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
pca_random <- prcomp(random_df)

# Visualizza il plot PCA sul dataset casuale (Pre-SOM) con il tema personalizzato
p2 <- fviz_pca_ind(pca_random, 
             title = "PCA - Random Data (Raw)",
             geom = "point", 
             ggtheme = theme_classic()) +
    theme(
        plot.title = element_text(size = 25, face = "bold"),
        axis.title = element_text(size = 25),
        axis.text = element_text(size = 25)
    )
print(p2)












## Carica le librerie necessarie
library(kohonen)    # Per la gestione delle Self-Organizing Maps
library(factoextra) # Per la visualizzazione dei risultati della PCA
library(ggplot2)

# Specifica la cartella contenente i modelli SOM
som_folder <- "C:/PN_Sila/som_Sila"
som_files <- list.files(path = som_folder, pattern = "_som_model\\.rds$", full.names = TRUE)

# Seleziona il primo file di modello SOM trovato
if (length(som_files) == 0) {
  stop("Nessun file di modello SOM trovato nella cartella.")
}
first_som_file <- som_files[1]

# Carica il modello SOM
som_model <- readRDS(first_som_file)

# Estrai i vettori del codebook (i pesi appresi dalla rete)
som_values <- som_model$codes[[1]]

# Esegue la PCA sull'intero set di dati della SOM
pca_som <- prcomp(som_values)

# Visualizza il plot PCA sui dati elaborati tramite SOM con il tema personalizzato
p3 <- fviz_pca_ind(pca_som, 
             title = "PCA - SOM Data",
             geom = "point", 
             ggtheme = theme_classic()) +
    theme(
        plot.title = element_text(size = 25, face = "bold"),
        axis.title = element_text(size = 25),
        axis.text = element_text(size = 25)
    )
print(p3)

# Genera un dataset casuale con la stessa struttura dei dati della SOM
random_df_som <- as.data.frame(apply(som_values, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
pca_random_som <- prcomp(random_df_som)

# Visualizza il plot PCA sul dataset casuale (SOM) con il tema personalizzato
p4 <- fviz_pca_ind(pca_random_som, 
             title = "PCA - Random Data (SOM)",
             geom = "point", 
             ggtheme = theme_classic()) +
    theme(
        plot.title = element_text(size = 25, face = "bold"),
        axis.title = element_text(size = 25),
        axis.text = element_text(size = 25)
    )
print(p4)











Calcolo della Statistica di Hopkins per i Dati Grezzi (Pre-SOM)
# Carica le librerie necessarie
library(terra)
library(hopkins)

# Specifica la cartella contenente le immagini .tif
image_dir <- "C:/PN_Sila"
image_files <- list.files(path = image_dir, pattern = "\\.tif$", full.names = TRUE)

# Seleziona il primo file .tif trovato
if (length(image_files) == 0) {
  stop("Nessuna immagine .tif trovata nella cartella.")
}
first_image <- image_files[1]

# Carica il raster multibanda
raster_image <- rast(first_image)

# Calcola gli indici:
ndvi <- (raster_image[[4]] - raster_image[[3]]) / (raster_image[[4]] + raster_image[[3]])
mndwi <- (raster_image[[2]] - raster_image[[5]]) / (raster_image[[2]] + raster_image[[5]])
ndbi <- (raster_image[[5]] - raster_image[[4]]) / (raster_image[[5]] + raster_image[[4]])

# Crea uno stack con le bande originali ed i nuovi indici
stacked_raster <- c(raster_image, ndvi, mndwi, ndbi)

# Estrai i valori come matrice e rimuovi le righe con NA
matrix_values <- values(stacked_raster)
cleaned_matrix <- matrix_values[complete.cases(matrix_values), ]

# Normalizza ogni colonna
normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
normalized_matrix <- apply(cleaned_matrix, 2, normalize)

# Campiona 10.000 osservazioni (o tutte se inferiori a 10.000)
sample_size <- min(10000, nrow(normalized_matrix))
sampled_matrix <- normalized_matrix[sample(nrow(normalized_matrix), sample_size), ]

# Calcola la statistica di Hopkins sui dati grezzi
hopkins_raw <- hopkins(sampled_matrix)

# Genera un dataset casuale con la stessa struttura dei dati campionati
random_df <- as.data.frame(apply(sampled_matrix, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
hopkins_random <- hopkins(random_df)

# Stampa i risultati
cat("Hopkins statistic for raw data:", hopkins_raw, "\n")
cat("Hopkins statistic for random data (raw):", hopkins_random, "\n")




Calcolo della Statistica di Hopkins per i Dati SOM (Post-SOM)

# Carica le librerie necessarie
library(kohonen)  # Per le Self-Organizing Maps
library(hopkins)

# Specifica la cartella contenente i modelli SOM
som_folder <- "C:/PN_Sila/som_Sila"
som_files <- list.files(path = som_folder, pattern = "_som_model\\.rds$", full.names = TRUE)

# Seleziona il primo file di modello SOM trovato
if (length(som_files) == 0) {
  stop("Nessun file di modello SOM trovato nella cartella.")
}
first_som_file <- som_files[1]

# Carica il modello SOM
som_model <- readRDS(first_som_file)

# Estrai i dati elaborati dalla SOM
som_values <- som_model$codes[[1]]

# Calcola la statistica di Hopkins sui dati SOM (senza campionamento)
hopkins_som <- hopkins(som_values)

# Genera un dataset casuale con la stessa struttura dei dati SOM
random_df <- as.data.frame(apply(som_values, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
hopkins_random <- hopkins(random_df)

# Stampa i risultati
cat("Hopkins statistic for SOM data:", hopkins_som, "\n")
cat("Hopkins statistic for random data (SOM):", hopkins_random, "\n")
