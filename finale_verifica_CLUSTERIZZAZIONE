PCA per i Dati Grezzi (Pre-SOM)
# Carica le librerie necessarie
library(terra)
library(factoextra)
library(ggplot2)  # Per eventuali visualizzazioni

# Specifica la cartella contenente le immagini .tif
image_dir <- "C:/PN_Sila"
image_files <- list.files(path = image_dir, pattern = "\\.tif$", full.names = TRUE)

# Seleziona il primo file .tif trovato
if (length(image_files) == 0) {
  stop("Nessuna immagine .tif trovata nella cartella.")
}
first_image <- image_files[1]

# Carica il raster multibanda
raster_image <- rast(first_image)

# Calcola gli indici:
# NDVI = (NIR - Red) / (NIR + Red) (assumendo banda 4 = NIR, banda 3 = Red)
ndvi <- (raster_image[[4]] - raster_image[[3]]) / (raster_image[[4]] + raster_image[[3]])

# MNDWI = (Green - SWIR) / (Green + SWIR) (assumendo banda 2 = Green, banda 5 = SWIR)
mndwi <- (raster_image[[2]] - raster_image[[5]]) / (raster_image[[2]] + raster_image[[5]])

# NDBI = (SWIR - NIR) / (SWIR + NIR) (assumendo banda 5 = SWIR, banda 4 = NIR)
ndbi <- (raster_image[[5]] - raster_image[[4]]) / (raster_image[[5]] + raster_image[[4]])

# Crea uno stack con le bande originali ed i nuovi indici
stacked_raster <- c(raster_image, ndvi, mndwi, ndbi)

# Estrai i valori come matrice e rimuovi le righe con NA
matrix_values <- values(stacked_raster)
cleaned_matrix <- matrix_values[complete.cases(matrix_values), ]

# Funzione per la normalizzazione Min-Max
normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

# Normalizza ogni colonna della matrice
normalized_matrix <- apply(cleaned_matrix, 2, normalize)

# Campiona 10.000 osservazioni (o tutte se inferiori a 10.000)
sample_size <- min(10000, nrow(normalized_matrix))
sampled_matrix <- normalized_matrix[sample(nrow(normalized_matrix), sample_size), ]

# Esegue la PCA sui dati grezzi (Pre-SOM)
pca_raw <- prcomp(sampled_matrix)
fviz_pca_ind(pca_raw, 
             title = "PCA - Raw Data",
             geom = "point", 
             ggtheme = theme_classic())

# Genera un dataset casuale con la stessa struttura (per confronto)
random_df <- as.data.frame(apply(sampled_matrix, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
pca_random <- prcomp(random_df)
fviz_pca_ind(pca_random, 
             title = "PCA - Random Data (Raw)",
             geom = "point", 
             ggtheme = theme_classic())











PCA per i Dati SOM (Post-SOM)
# Carica le librerie necessarie
library(kohonen)    # Per le Self-Organizing Maps
library(factoextra) # Per la visualizzazione dei risultati della PCA

# Specifica la cartella contenente i modelli SOM
som_folder <- "C:/PN_Sila/som_Sila"
som_files <- list.files(path = som_folder, pattern = "_som_model\\.rds$", full.names = TRUE)

# Seleziona il primo file di modello SOM trovato
if (length(som_files) == 0) {
  stop("Nessun file di modello SOM trovato nella cartella.")
}
first_som_file <- som_files[1]

# Carica il modello SOM
som_model <- readRDS(first_som_file)

# Estrai i dati elaborati dalla SOM
som_values <- som_model$codes[[1]]

# Esegue la PCA sui dati SOM (Post-SOM)
pca_som <- prcomp(som_values)
fviz_pca_ind(pca_som, 
             title = "PCA - SOM Data",
             geom = "point", 
             ggtheme = theme_classic())

# Genera un dataset casuale con la stessa struttura dei dati SOM
random_df <- as.data.frame(apply(som_values, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
pca_random <- prcomp(random_df)
fviz_pca_ind(pca_random, 
             title = "PCA - Random Data (SOM)",
             geom = "point", 
             ggtheme = theme_classic())






Calcolo della Statistica di Hopkins per i Dati Grezzi (Pre-SOM)
# Carica le librerie necessarie
library(terra)
library(hopkins)

# Specifica la cartella contenente le immagini .tif
image_dir <- "C:/PN_Sila"
image_files <- list.files(path = image_dir, pattern = "\\.tif$", full.names = TRUE)

# Seleziona il primo file .tif trovato
if (length(image_files) == 0) {
  stop("Nessuna immagine .tif trovata nella cartella.")
}
first_image <- image_files[1]

# Carica il raster multibanda
raster_image <- rast(first_image)

# Calcola gli indici:
ndvi <- (raster_image[[4]] - raster_image[[3]]) / (raster_image[[4]] + raster_image[[3]])
mndwi <- (raster_image[[2]] - raster_image[[5]]) / (raster_image[[2]] + raster_image[[5]])
ndbi <- (raster_image[[5]] - raster_image[[4]]) / (raster_image[[5]] + raster_image[[4]])

# Crea uno stack con le bande originali ed i nuovi indici
stacked_raster <- c(raster_image, ndvi, mndwi, ndbi)

# Estrai i valori come matrice e rimuovi le righe con NA
matrix_values <- values(stacked_raster)
cleaned_matrix <- matrix_values[complete.cases(matrix_values), ]

# Normalizza ogni colonna
normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
normalized_matrix <- apply(cleaned_matrix, 2, normalize)

# Campiona 10.000 osservazioni (o tutte se inferiori a 10.000)
sample_size <- min(10000, nrow(normalized_matrix))
sampled_matrix <- normalized_matrix[sample(nrow(normalized_matrix), sample_size), ]

# Calcola la statistica di Hopkins sui dati grezzi
hopkins_raw <- hopkins(sampled_matrix)

# Genera un dataset casuale con la stessa struttura dei dati campionati
random_df <- as.data.frame(apply(sampled_matrix, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
hopkins_random <- hopkins(random_df)

# Stampa i risultati
cat("Hopkins statistic for raw data:", hopkins_raw, "\n")
cat("Hopkins statistic for random data (raw):", hopkins_random, "\n")




Calcolo della Statistica di Hopkins per i Dati SOM (Post-SOM)

# Carica le librerie necessarie
library(kohonen)  # Per le Self-Organizing Maps
library(hopkins)

# Specifica la cartella contenente i modelli SOM
som_folder <- "C:/PN_Sila/som_Sila"
som_files <- list.files(path = som_folder, pattern = "_som_model\\.rds$", full.names = TRUE)

# Seleziona il primo file di modello SOM trovato
if (length(som_files) == 0) {
  stop("Nessun file di modello SOM trovato nella cartella.")
}
first_som_file <- som_files[1]

# Carica il modello SOM
som_model <- readRDS(first_som_file)

# Estrai i dati elaborati dalla SOM
som_values <- som_model$codes[[1]]

# Calcola la statistica di Hopkins sui dati SOM (senza campionamento)
hopkins_som <- hopkins(som_values)

# Genera un dataset casuale con la stessa struttura dei dati SOM
random_df <- as.data.frame(apply(som_values, 2, function(x) {
  runif(length(x), min = min(x), max = max(x))
}))
hopkins_random <- hopkins(random_df)

# Stampa i risultati
cat("Hopkins statistic for SOM data:", hopkins_som, "\n")
cat("Hopkins statistic for random data (SOM):", hopkins_random, "\n")
