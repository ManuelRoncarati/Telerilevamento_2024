# Carica le librerie necessarie
library(terra)
library(xgboost)
library(dplyr)
library(viridis)
library(caret)
library(sf)

# Imposta la directory di lavoro
setwd("C:/sila_1986")

# Carica il raster
immagine <- rast("falsi_1986.TIF")

# Estrai i valori delle bande dal raster come dataframe
values_bande <- as.data.frame(values(immagine))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Carica i dati di addestramento dallo shapefile
training_data <- st_read("aiuto.shp")

# Estrai i valori dei pixel per i poligoni dello shapefile
extracted_values <- extract(immagine, training_data, df = TRUE)

# Aggiungi le classi ai valori estratti abbinando gli ID
extracted_values$classe <- training_data$classe[match(extracted_values$ID, training_data$id)]

# Prepara il dataframe finale con le classi e i valori dei raster
training_data_final <- extracted_values %>% select(classe, everything())  # Mantieni tutte le colonne

# Converti le classi in numeri che partono da 0
training_data_final$classe <- as.numeric(factor(training_data_final$classe)) - 1

# Identifica le colonne di bande nel dataframe di addestramento
band_columns <- names(training_data_final)[!names(training_data_final) %in% c("classe", "ID")]

# Prepara i dati per XGBoost
X_train <- as.matrix(training_data_final %>% select(all_of(band_columns)))
y_train <- training_data_final$classe
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Imposta la griglia di parametri
param_grid <- expand.grid(
  eta = c(0.01, 0.1, 0.2),
  max_depth = c(4, 6, 8),
  nrounds = c(100, 200, 300)
)

# Definisci una funzione di valutazione
evaluate_model <- function(params) {
  xgb_params <- list(
    objective = "multi:softmax",
    num_class = length(unique(y_train)),
    eta = params$eta,
    max_depth = params$max_depth
  )
  
  # Addestra il modello XGBoost
  xgb_model <- xgb.train(
    params = xgb_params,
    data = dtrain,
    nrounds = params$nrounds,
    verbose = 0
  )
  
  # Valuta il modello sul set di addestramento
  preds <- predict(xgb_model, dtrain)
  accuracy <- sum(preds == y_train) / length(y_train)  # Calcola l'accuratezza
  
  return(accuracy)
}

# Trova i migliori parametri
best_accuracy <- 0
best_params <- NULL

for (i in 1:nrow(param_grid)) {
  params <- param_grid[i, ]
  accuracy <- evaluate_model(params)
  
  if (accuracy > best_accuracy) {
    best_accuracy <- accuracy
    best_params <- params
  }
}

print(best_params)
print(paste("Best Accuracy:", best_accuracy))

# Utilizza i migliori parametri trovati
xgb_params_best <- list(
  objective = "multi:softmax",
  num_class = length(unique(y_train)),
  eta = best_params$eta,
  max_depth = best_params$max_depth
)

# Addestra il modello XGBoost finale
xgb_model_best <- xgb.train(
  params = xgb_params_best,
  data = dtrain,
  nrounds = best_params$nrounds
)

# Prepara i dati per la previsione
X_pred <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))
dtest <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni sul raster
preds <- predict(xgb_model_best, dtest)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(immagine), ncol = ncol(immagine), crs = crs(immagine), ext = ext(immagine))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[non_na_mask] <- preds

# Visualizza il raster classificato usando plot()
plot(pred_raster, col = viridis(length(unique(preds))), main = "Raster Classificato")
