#XGBOOST MCLUST

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per XGBoost
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Tutte le colonne tranne 'classe'
y_train <- as.numeric(values_bande_non_na$classe)  # XGBoost richiede etichette numeriche

# Crea una matrice DMatrix per XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Parametri per XGBoost
params <- list(
    objective = "multi:softmax",  # Classificazione multiclasse
    num_class = num_clusters,     # Numero di classi (cluster)
    eval_metric = "mlogloss",     # Log-loss multiclasse (puoi cambiarlo in "merror" se vuoi la precisione)
    
    # Parametri aggiuntivi
    eta = 0.01,                    # Tasso di apprendimento (può essere abbassato a 0.01 per maggiore precisione)
    max_depth = 6,                # Profondità massima degli alberi
    subsample = 0.8,              # Percentuale di dati da campionare per ogni albero (evita l'overfitting)
    colsample_bytree = 0.8,       # Percentuale di colonne da campionare per ogni albero
    min_child_weight = 1,         # Peso minimo dei nodi foglia per la divisione
    gamma = 0,                    # Regolarizzazione per il controllo dell'overfitting
    lambda = 1,                   # Regolarizzazione L2 (Ridge)
    alpha = 0                     # Regolarizzazione L1 (Lasso)
)

# Addestra il modello XGBoost
xgb_model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 500,  # Numero di iterazioni (boosting rounds), aumentato per maggiore precisione
    early_stopping_rounds = 50,  # Arresto anticipato per evitare overfitting se non ci sono miglioramenti
    watchlist = list(train = dtrain),  # Lista per monitorare le prestazioni durante l'addestramento
    verbose = 1
)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)
dpred <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni con XGBoost
preds <- predict(xgb_model, dpred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con XGBoost", maxpixels = ncell(pred_raster))






#MCLUST E RF

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(randomForest)
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Imposta una semina per la riproducibilità
set.seed(123)

# Percentuale di pixel da campionare
percentuale <- 1  # 20% dei pixel

# Calcola il numero di pixel da campionare basandoti solo sulla percentuale
num_samples <- ceiling(nrow(values_bande_non_na) * percentuale)

# Campiona i pixel casualmente
sample_indices <- sample(seq_len(nrow(values_bande_non_na)), size = num_samples, replace = FALSE)
sampled_data <- values_bande_non_na[sample_indices, ]

# Identifica le colonne delle bande
band_columns <- names(sampled_data)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(sampled_data %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
sampled_data$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training
X_train <- as.data.frame(X)
y_train <- as.factor(sampled_data$classe)  # Converti le etichette in un fattore
train_data <- cbind(X_train, classe = y_train)

# Addestra il modello Random Forest
rf_model <- randomForest(classe ~ ., data = train_data, ntree = 100, mtry = 3)  # Imposta parametri manuali

# Carica il raster su cui effettuare le previsioni
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.data.frame(values_bande_non_na_full)
names(X_pred) <- band_columns  # Assicurati che i nomi delle colonne corrispondano

# Effettua le previsioni
preds <- predict(rf_model, X_pred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con Random Forest", maxpixels = ncell(pred_raster))







#MCLUST E CART

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(rpart)  # Per CART (Decision Tree)
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per CART
X_train <- values_bande_non_na %>% select(-classe)  # Tutte le colonne tranne 'classe'
y_train <- as.factor(values_bande_non_na$classe)  # Le etichette devono essere fattori

# Crea il modello CART utilizzando rpart
cart_model <- rpart(classe ~ ., data = data.frame(X_train, classe = y_train), method = "class")

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- values_bande_non_na_full

# Effettua le previsioni con CART
preds <- predict(cart_model, X_pred, type = "class")

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con CART (Decision Tree)", maxpixels = ncell(pred_raster))








#NATIVE BAYES


# Carica le librerie necessarie
library(terra)
library(dplyr)
library(e1071)  # Per Naive Bayes
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per Naive Bayes
X_train <- values_bande_non_na %>% select(-classe)  # Tutte le colonne tranne 'classe'
y_train <- as.factor(values_bande_non_na$classe)  # Le etichette devono essere fattori

# Crea il modello Naive Bayes
nb_model <- naiveBayes(X_train, y_train)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- values_bande_non_na_full

# Effettua le previsioni con Naive Bayes
preds <- predict(nb_model, X_pred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con Naive Bayes", maxpixels = ncell(pred_raster))


#DBSCAN e RF, complesso capire i parametri...

# Carica le librerie necessarie
library(terra)        # Per la manipolazione dei raster
library(dplyr)        # Per la manipolazione dei dati
library(dbscan)       # Per l'algoritmo di clustering DBSCAN
library(randomForest) # Per il modello di classificazione Random Forest
library(mapview)      # Per la visualizzazione dei raster
library(viridis)      # Per le palette di colori viridis

# Imposta la directory di lavoro
setwd("C:/composite prove")  # Imposta la directory di lavoro dove sono salvati i file

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")  # Carica il raster multibanda da file TIFF

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))  # Estrae i valori delle bande dal raster e li converte in un dataframe

# Filtra solo i valori non nulli
values_bande_non_na <- values_bande[complete.cases(values_bande), ]  # Rimuove le righe con valori NA

# Applica il clustering DBSCAN sull'intero dataset
eps_value <- 0.009  # Distanza massima tra i punti per considerarli come parte dello stesso cluster; regola in base ai tuoi dati
minPts_value <- 400  # Numero minimo di punti in un cluster; regola in base ai tuoi dati, andare a ribasso
sample_matrix <- as.matrix(values_bande_non_na)  # Converte i dati in una matrice per DBSCAN
db_result <- dbscan(sample_matrix, eps = eps_value, minPts = minPts_value)  # Applica il clustering DBSCAN

# Aggiungi i cluster ai dati
values_bande_non_na$cluster <- db_result$cluster  # Aggiunge i risultati del clustering come nuova colonna nel dataframe

# Addestra il modello di Random Forest
rf_model <- randomForest(x = sample_matrix, y = as.factor(values_bande_non_na$cluster), ntree = 100)  # Addestra il modello Random Forest con i dati di clustering come etichette

# Predici i cluster per tutto il raster
# Nota: Questo passo può richiedere molta memoria a causa delle dimensioni del dataset
preds <- predict(rf_model, sample_matrix)  # Predice i cluster per tutti i pixel usando il modello Random Forest

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Controlla la lunghezza delle previsioni; dovrebbe corrispondere al numero di righe nel dataframe

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), 
                    ncol = ncol(nuove_bande_selezionate), 
                    crs = crs(nuove_bande_selezionate), 
                    ext = ext(nuove_bande_selezionate))  # Crea un raster vuoto con le stesse dimensioni e proiezione dell'originale

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutti i valori del raster a NA
values(pred_raster)[complete.cases(values_bande)] <- preds  # Assegna le previsioni ai pixel non nulli nel raster

# Visualizza il raster classificato utilizzando viridis per i colori
mapview(pred_raster, 
        col.regions = viridis(length(unique(preds))),  # Usa la palette di colori viridis basata sul numero di classi uniche
        main = "Raster Classificato con Random Forest",  # Titolo della mappa
        maxpixels = ncell(pred_raster))  # Aumenta maxpixels al numero totale di celle del raster per visualizzare tutto






#MCLUST ANN, NON DISTINGUE ACQUA DA CASE..

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(nnet)  # Per ANN (Rete Neurale)
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per ANN
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Input
y_train <- class.ind(as.factor(values_bande_non_na$classe))  # One-hot encoding per le etichette

# Crea il modello ANN utilizzando nnet
# 'size' indica il numero di neuroni nello strato nascosto, puoi modificare questo valore
ann_model <- nnet(X_train, y_train, size = 5, softmax = TRUE, maxit = 200)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)

# Previsione con ANN
preds <- predict(ann_model, X_pred, type = "class")

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con ANN", maxpixels = ncell(pred_raster))





#MCLUST KNN

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(class)  # Per KNN
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per KNN
X_train <- values_bande_non_na %>% select(-classe)  # Tutte le colonne tranne 'classe'
y_train <- as.factor(values_bande_non_na$classe)  # Le etichette devono essere fattori

# Imposta il numero di vicini per KNN
k <- 5  # Cambia il valore di k se necessario

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- values_bande_non_na_full

# Applica il modello KNN
preds <- knn(train = X_train, test = X_pred, cl = y_train, k = k)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- as.numeric(preds) - 1  # Converte le classi predette a partire da 0

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con KNN", maxpixels = ncell(pred_raster))



# fuzzy con RF

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(e1071)  # Per Fuzzy C-Means
library(randomForest)  # Per Random Forest
library(mapview)
library(viridis)

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering con Fuzzy C-Means
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering Fuzzy C-Means con la libreria e1071
num_clusters <- 7  # Cambia questo valore se necessario
fcm_result <- cmeans(X, centers = num_clusters, m = 2, iter.max = 100, verbose = FALSE)

# Aggiungi le etichette dei cluster fuzzy ai dati
values_bande_non_na$classe <- as.factor(apply(fcm_result$membership, 1, which.max) - 1)  # Le etichette devono partire da 0

# Prepara i dati di training per Random Forest
X_train <- values_bande_non_na %>% select(-classe)  # Tutte le colonne tranne 'classe'
y_train <- values_bande_non_na$classe  # Le etichette devono essere fattori

# Crea il modello Random Forest
rf_model <- randomForest(classe ~ ., data = data.frame(X_train, classe = y_train), ntree = 100, mtry = 3)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- values_bande_non_na_full

# Effettua le previsioni con Random Forest
preds <- predict(rf_model, newdata = X_pred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- as.numeric(preds) - 1  # Converte le classi predette a partire da 0

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con Random Forest e Fuzzy C-Means", maxpixels = ncell(pred_raster))




#12 ore ma  A MANI BASSE IL MIGLIORE SVM

# Carica le librerie necessarie
library(terra)       # Per la manipolazione di dati raster e spaziali
library(e1071)       # Per l'implementazione del Support Vector Machine (SVM)
library(mapview)     # Per la visualizzazione interattiva dei dati spaziali
library(viridis)     # Per le palette di colori
library(mclust)      # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite prove")  # Cambia la directory di lavoro al percorso specificato

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")  # Carica un raster da un file TIFF

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))  # Estrae i valori del raster in un dataframe

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)  # Crea una maschera per i valori non nulli
values_bande_non_na <- values_bande[non_na_mask, ]  # Filtra il dataframe per mantenere solo i valori non nulli

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)  # Ottiene i nomi delle colonne del dataframe

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na[, band_columns])  # Converte i valori non nulli in una matrice

# Applica il clustering basato su modelli
num_clusters <- 7  # Definisce il numero di cluster desiderato
mclust_result <- Mclust(X, G = num_clusters)  # Esegue il clustering con il modello Mclust

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Aggiunge le etichette dei cluster al dataframe (partendo da 0)

# Prepara i dati di training per SVM
X_train <- values_bande_non_na[, band_columns]  # Seleziona le colonne delle bande per l'input
y_train <- as.factor(values_bande_non_na$classe)  # Converte le etichette in fattori per il modello SVM

# Crea il modello SVM
svm_model <- svm(X_train, y_train, probability = TRUE)  # Allena il modello SVM sui dati di training

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))  # Estrae i valori dal raster completo
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]  # Filtra per i valori non nulli
X_pred <- as.matrix(values_bande_non_na_full)  # Converte i dati di previsione in una matrice

# Previsione con SVM
preds <- predict(svm_model, X_pred)  # Effettua le previsioni utilizzando il modello SVM

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Stampa la lunghezza delle previsioni (dovrebbe corrispondere al numero di righe di valori non nulli)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))  # Inizializza un raster vuoto

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente imposta tutti i valori a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds  # Sostituisce i valori NA con le previsioni

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con SVM", maxpixels = ncell(pred_raster))  # Visualizza il raster classificato con la palette di colori magma






#kmeans ++ XGBOOST

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)  # Per l'algoritmo k-means++

# Imposta la directory di lavoro
setwd("C:/composite prove")

# Carica il raster multibanda
nuove_bande_selezionate <- rast("nuove_bande_selezionate.tif")

# Estrai i valori delle bande come dataframe
values_bande <- as.data.frame(values(nuove_bande_selezionate))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering k-means++ utilizzando ClusterR
num_clusters <- 7  # Cambia questo valore se necessario
set.seed(123)  # Per riproducibilità
kmeans_result <- KMeans_rcpp(X, clusters = num_clusters, initializer = 'kmeans++')

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- kmeans_result$clusters - 1  # Le etichette devono partire da 0

# Prepara i dati di training per XGBoost
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Tutte le colonne tranne 'classe'
y_train <- as.numeric(values_bande_non_na$classe)  # XGBoost richiede etichette numeriche

# Crea una matrice DMatrix per XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Parametri per XGBoost
params <- list(
    objective = "multi:softmax",  # Classificazione multiclasse
    num_class = num_clusters,     # Numero di classi (cluster)
    eval_metric = "mlogloss",     # Log-loss multiclasse
    
    # Parametri aggiuntivi
    eta = 0.01,                   # Tasso di apprendimento
    max_depth = 6,                # Profondità massima degli alberi
    subsample = 0.8,              # Percentuale di dati da campionare per ogni albero
    colsample_bytree = 0.8,       # Percentuale di colonne da campionare per ogni albero
    min_child_weight = 1,         # Peso minimo dei nodi foglia per la divisione
    gamma = 0,                    # Regolarizzazione per il controllo dell'overfitting
    lambda = 1,                   # Regolarizzazione L2 (Ridge)
    alpha = 0                     # Regolarizzazione L1 (Lasso)
)

# Addestra il modello XGBoost
xgb_model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 500,  # Numero di iterazioni (boosting rounds)
    early_stopping_rounds = 50,  # Arresto anticipato
    watchlist = list(train = dtrain),  # Monitoraggio delle prestazioni
    verbose = 1
)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(nuove_bande_selezionate))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)
dpred <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni con XGBoost
preds <- predict(xgb_model, dpred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(nuove_bande_selezionate), ncol = ncol(nuove_bande_selezionate), crs = crs(nuove_bande_selezionate), ext = ext(nuove_bande_selezionate))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con XGBoost", maxpixels = ncell(pred_raster))









# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)  # Per l'algoritmo k-means++

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dallo stack raster come dataframe
values_bande <- as.data.frame(values(stack_1984))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande e degli indici
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering K-means++ utilizzando ClusterR
num_clusters <- 7  # Cambia questo valore se necessario
set.seed(123)  # Per riproducibilità
kmeans_result <- KMeans_rcpp(X, clusters = num_clusters, initializer = 'kmeans++')

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- kmeans_result$clusters - 1  # Le etichette devono partire da 0

# Prepara i dati di training per XGBoost (se necessario)
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Tutte le colonne tranne 'classe'
y_train <- as.numeric(values_bande_non_na$classe)  # XGBoost richiede etichette numeriche

# Crea una matrice DMatrix per XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Parametri per XGBoost
params <- list(
    objective = "multi:softmax",  # Classificazione multiclasse
    num_class = num_clusters,     # Numero di classi (cluster)
    eval_metric = "mlogloss",     # Log-loss multiclasse
    
    # Parametri aggiuntivi
    eta = 0.01,                   # Tasso di apprendimento
    max_depth = 6,                # Profondità massima degli alberi
    subsample = 0.8,              # Percentuale di dati da campionare per ogni albero
    colsample_bytree = 0.8,       # Percentuale di colonne da campionare per ogni albero
    min_child_weight = 1,         # Peso minimo dei nodi foglia per la divisione
    gamma = 0,                    # Regolarizzazione per il controllo dell'overfitting
    lambda = 1,                   # Regolarizzazione L2 (Ridge)
    alpha = 0                     # Regolarizzazione L1 (Lasso)
)

# Addestra il modello XGBoost (opzionale)
xgb_model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 500,  # Numero di iterazioni (boosting rounds)
    early_stopping_rounds = 50,  # Arresto anticipato
    watchlist = list(train = dtrain),  # Monitoraggio delle prestazioni
    verbose = 1
)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(stack_1984))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)
dpred <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni con XGBoost
preds <- predict(xgb_model, dpred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(stack_1984), ncol = ncol(stack_1984), crs = crs(stack_1984), ext = ext(stack_1984))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[non_na_mask] <- preds  # Usa la maschera per riempire i pixel

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con XGBoost", maxpixels = ncell(pred_raster))


#GOMITO
# Carica le librerie necessarie
library(terra)
library(ClusterR)  # Per l'algoritmo k-means++
library(factoextra)  # Per la visualizzazione del gomito
library(ggplot2)  # Per i grafici

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dallo stack raster come dataframe
values_bande <- as.data.frame(values(stack_1984))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande e degli indici
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Funzione per calcolare WSS (somma dei quadrati intra-cluster) per diversi valori di K usando K-means++
wss_kmeanspp <- function(k) {
  kmeans_result <- KMeans_rcpp(X, clusters = k, initializer = 'kmeans++')
  return(sum(kmeans_result$WCSS_per_cluster))  # Somma dei quadrati intra-cluster per tutti i cluster
}

# Definisci l'intervallo di K da provare (ad esempio, da 1 a 10 cluster)
k_values <- 1:10
wss_values <- sapply(k_values, wss_kmeanspp)

# Crea il grafico del metodo del gomito
plot(k_values, wss_values, type = "b", pch = 19, frame = FALSE,
     xlab = "Numero di cluster K",
     ylab = "Somma dei quadrati intra-cluster (WSS)",
     main = "Metodo del Gomito per K-means++")

