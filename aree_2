# determinazione n cluster iterato su tutte le som con nbclust


# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("kohonen", "NbClust", "dplyr")
check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

# Directory contenente i modelli SOM salvati come file RDS
rds_dir <- "C:/Aspromonte/som_aspromonte"

# Elenca tutti i file RDS nella cartella
rds_files <- list.files(path = rds_dir, pattern = "\\.rds$", full.names = TRUE)

# Variabile per salvare i risultati
optimal_clusters_results <- list()

# ====================================================
# Sezione 3: Calcolo del numero ottimale di cluster per ogni SOM
# ====================================================

for (rds_path in rds_files) {
    start_time <- Sys.time()  # Avvia il cronometro
    
    cat("\nProcesso il file SOM:", rds_path, "\n")
    
    # Carica il modello SOM
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    # Estrai i valori delle codebook
    som_values <- som_model$codes[[1]]
    
    # Determinazione del numero ottimale di cluster con NbClust
    cat("Determinazione del numero ottimale di cluster...\n")
    nbclust_result <- NbClust(
        data = som_values, 
        diss = NULL, 
        distance = "euclidean",  # Distanza euclidea
        min.nc = 2,              # Numero minimo di cluster
        max.nc = 10,             # Numero massimo di cluster
        method = "kmeans",       # Metodo di clustering K-means
        index = "all"            # Usa tutti i criteri di validazione
    )
    
    # Trova il numero ottimale di cluster dalla moda
    optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))
    
    # Numero di criteri che supportano il numero ottimale di cluster
    support_count <- max(table(nbclust_result$Best.nc[1, ]))
    
    # Estrai il range di anni dal nome del file
    file_name <- basename(rds_path)
    dates <- regmatches(file_name, gregexpr("\\d{4}", file_name))[[1]]
    if (length(dates) == 2) {
        year_range <- paste(dates[1], "-", dates[2])
    } else {
        year_range <- "range non trovato"
    }
    
    # Stampa il risultato per il file attuale
    cat("Numero ottimale di cluster per SOM", year_range, ":", optimal_clusters, 
        "(supportato da", support_count, "criteri)\n")
    
    # Salva il risultato
    optimal_clusters_results[[basename(rds_path)]] <- list(
        year_range = year_range,
        optimal_clusters = optimal_clusters,
        support_count = support_count,
        nbclust_result = nbclust_result
    )
    
    # Calcola il tempo di esecuzione per il file corrente
    end_time <- Sys.time()
    execution_time <- round(difftime(end_time, start_time, units = "secs"), 2)
    cat("Tempo di esecuzione per", file_name, ":", execution_time, "secondi.\n")
}

# ====================================================
# Sezione 4: Risultati finali
# ====================================================

cat("\nRisultati finali:\n")
results_summary <- lapply(names(optimal_clusters_results), function(name) {
    list(
        File = name,
        Year_Range = optimal_clusters_results[[name]]$year_range,
        Optimal_Clusters = optimal_clusters_results[[name]]$optimal_clusters,
        Support_Count = optimal_clusters_results[[name]]$support_count
    )
}) %>% bind_rows()

print(results_summary)





























#tiene i primi due cluster per maggior frequenza escluso "2" come numero di cluster 

# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("kohonen", "NbClust", "dplyr")
check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

# Directory contenente i modelli SOM salvati come file RDS
rds_dir <- "C:/Sila/som_sila"

# Elenca tutti i file RDS nella cartella
rds_files <- list.files(path = rds_dir, pattern = "\\.rds$", full.names = TRUE)

# Variabile per salvare i risultati
optimal_clusters_results <- list()

# ====================================================
# Sezione 3: Calcolo del numero ottimale di cluster per ogni SOM
# ====================================================

for (rds_path in rds_files) {
    start_time <- Sys.time()  # Avvia il cronometro
    
    cat("\nProcesso il file SOM:", rds_path, "\n")
    
    # Carica il modello SOM
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    # Estrai i valori delle codebook
    som_values <- som_model$codes[[1]]
    
    # Determinazione del numero ottimale di cluster con NbClust
    cat("Determinazione del numero ottimale di cluster...\n")
    nbclust_result <- NbClust(
        data = som_values, 
        diss = NULL, 
        distance = "euclidean",  # Distanza euclidea
        min.nc = 2,              # Numero minimo di cluster
        max.nc = 10,             # Numero massimo di cluster
        method = "kmeans",       # Metodo di clustering K-means
        index = "all"            # Usa tutti i criteri di validazione
    )
    
    # Calcola le frequenze dei numeri di cluster suggeriti
    cluster_frequencies <- sort(table(nbclust_result$Best.nc[1, ]), decreasing = TRUE)
    
    # Rimuove il cluster con numero 2
    cluster_frequencies <- cluster_frequencies[names(cluster_frequencies) != "2"]
    
    # Controlla se rimangono cluster disponibili
    if (length(cluster_frequencies) > 0) {
        # Estrai il cluster più rappresentato
        primary_cluster <- as.numeric(names(cluster_frequencies)[1])
        primary_support <- as.numeric(cluster_frequencies[1])
        
        # Estrai il secondo cluster più rappresentato (se esiste)
        if (length(cluster_frequencies) > 1) {
            secondary_cluster <- as.numeric(names(cluster_frequencies)[2])
            secondary_support <- as.numeric(cluster_frequencies[2])
        } else {
            secondary_cluster <- NA
            secondary_support <- NA
        }
    } else {
        # Caso in cui non ci sono cluster disponibili dopo la rimozione
        primary_cluster <- NA
        primary_support <- NA
        secondary_cluster <- NA
        secondary_support <- NA
    }
    
    # Estrai il range di anni dal nome del file
    file_name <- basename(rds_path)
    dates <- regmatches(file_name, gregexpr("\\d{4}", file_name))[[1]]
    if (length(dates) == 2) {
        year_range <- paste(dates[1], "-", dates[2])
    } else {
        year_range <- "range non trovato"
    }
    
    # Stampa il risultato per il file attuale
    cat("Cluster più rappresentato (escluso 2):", primary_cluster, 
        "(supportato da", primary_support, "criteri)\n")
    if (!is.na(secondary_cluster)) {
        cat("Secondo cluster più rappresentato:", secondary_cluster, 
            "(supportato da", secondary_support, "criteri)\n")
    }
    
    # Salva il risultato
    optimal_clusters_results[[basename(rds_path)]] <- list(
        year_range = year_range,
        primary_cluster = primary_cluster,
        primary_support = primary_support,
        secondary_cluster = secondary_cluster,
        secondary_support = secondary_support,
        nbclust_result = nbclust_result
    )
    
    # Calcola il tempo di esecuzione per il file corrente
    end_time <- Sys.time()
    execution_time <- round(difftime(end_time, start_time, units = "secs"), 2)
    cat("Tempo di esecuzione per", file_name, ":", execution_time, "secondi.\n")
}

# ====================================================
# Sezione 4: Risultati finali
# ====================================================

cat("\nRisultati finali:\n")
results_summary <- lapply(names(optimal_clusters_results), function(name) {
    list(
        File = name,
        Year_Range = optimal_clusters_results[[name]]$year_range,
        Primary_Cluster = optimal_clusters_results[[name]]$primary_cluster,
        Primary_Support = optimal_clusters_results[[name]]$primary_support,
        Secondary_Cluster = optimal_clusters_results[[name]]$secondary_cluster,
        Secondary_Support = optimal_clusters_results[[name]]$secondary_support
    )
}) %>% bind_rows()

print(results_summary)
























#clusterboot su tutte le som con il numero di cluster ritenuto corretto

# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("kohonen", "NbClust", "dplyr", "fpc", "tibble", "openxlsx")
check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

# Directory contenente i modelli SOM salvati come file RDS
rds_dir <- "C:/Aspromonte/som_aspromonte"

# Elenca tutti i file RDS nella cartella
rds_files <- list.files(path = rds_dir, pattern = "\\.rds$", full.names = TRUE)

# Variabile per salvare i risultati
clusterboot_results <- list()

# Imposta il numero di cluster ottimale (modificabile dall'utente)
optimal_clusters <- 4

# Avvia il cronometro globale
global_start_time <- Sys.time()

# ====================================================
# Sezione 3: Esecuzione di Clusterboot per ogni SOM
# ====================================================

for (rds_path in rds_files) {
    start_time <- Sys.time()  # Avvia il cronometro per il file corrente
    
    cat("\nProcesso il file SOM:", rds_path, "\n")
    
    # Carica il modello SOM
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    # Estrai i valori delle codebook
    som_values <- som_model$codes[[1]]
    
    # Determinazione dei cluster tramite Clusterboot
    cat("Esecuzione di Clusterboot con", optimal_clusters, "cluster...\n")
    clusterboot_result <- clusterboot(
        data = som_values,            # Usa i valori SOM
        B = 500,                      # Numero di campioni bootstrap
        clustermethod = kmeansCBI,    # Metodo K-means tramite interfaccia kmeansCBI
        bootmethod = "boot",          # Usa bootstrap non parametrico
        dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
        recover = 0.75,               # Valore di recupero per i cluster stabili
        count = FALSE,                # Mostra il progresso durante il bootstrap
        k = optimal_clusters          # Usa il numero ottimale di cluster impostato
    )
    
    # Estrai la stabilità dei cluster
    cluster_stability <- clusterboot_result$bootmean
    
    # Estrai il range di anni dal nome del file
    file_name <- basename(rds_path)
    dates <- regmatches(file_name, gregexpr("\\d{4}", file_name))[[1]]
    if (length(dates) == 2) {
        year_range <- paste(dates[1], "-", dates[2])
    } else {
        year_range <- "range non trovato"
    }
    
    # Salva il risultato in formato tabellare
    clusterboot_results[[basename(rds_path)]] <- tibble(
        File = file_name,
        Year_Range = year_range,
        Cluster_Stability = cluster_stability
    )
    
    # Calcola il tempo di esecuzione per il file corrente
    end_time <- Sys.time()
    execution_time <- round(difftime(end_time, start_time, units = "secs"), 2)
    cat("Tempo di esecuzione per", file_name, ":", execution_time, "secondi.\n")
}

# ====================================================
# Sezione 4: Risultati finali
# ====================================================

# Combina tutti i risultati in un'unica tabella
results_summary <- bind_rows(clusterboot_results)

# Stampa un messaggio di separazione per ogni blocco di anni
cat("\nRisultati finali con separazione per blocchi di anni:\n")
for (year_range in unique(results_summary$Year_Range)) {
    cat("\n=== Risultati per il periodo:", year_range, "===\n")
    print.data.frame(filter(results_summary, Year_Range == year_range), row.names = FALSE)
}

# ====================================================
# Sezione 5: Salvataggio dei risultati in Excel
# ====================================================

# Percorso del file Excel
output_excel_path <- "C:/Aspromonte/clusterboot_results.xlsx"

# Scrivi i risultati in Excel
write.xlsx(results_summary, file = output_excel_path, rowNames = FALSE)

cat("\nRisultati salvati in formato Excel:", output_excel_path, "\n")

# ====================================================
# Sezione 6: Tempo di esecuzione totale
# ====================================================

global_end_time <- Sys.time()
global_execution_time <- round(difftime(global_end_time, global_start_time, units = "secs"), 2)

cat("\nTempo di esecuzione totale:", global_execution_time, "secondi.\n")




















# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "tclust", "viridisLite", "htmltools"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

# Il setwd non è necessario se si specificano i percorsi completi.
# setwd("C:/composite_sila")

# Directory contenente i file tif
tif_dir <- "C:/composite_sila"

# Directory contenente i file rds
rds_dir <- "C:/composite_sila/som_sila"

# ====================================================
# Sezione 3: Individuazione e loop sui file
# ====================================================

# Elenca tutti i file .tif nella cartella delle immagini
tif_files <- list.files(path = tif_dir, pattern = "\\.tif$", full.names = TRUE)

for (tif_path in tif_files) {
    # Costruisci il percorso per il file RDS corrispondente
    rds_name <- paste0(basename(tif_path), "_som_model.rds")
    rds_path <- file.path(rds_dir, rds_name)
    
    if (!file.exists(rds_path)) {
        cat("File RDS corrispondente non trovato per:", tif_path, "\n")
        next
    }
    
    cat("\nProcesso il file:", tif_path, "con il modello:", rds_path, "\n")
    
    # Estrazione date dal nome del file tif
    file_name <- basename(tif_path)
    # Trova tutte le occorrenze di YYYY-MM-DD nel nome
    dates <- regmatches(file_name, gregexpr("\\d{4}-\\d{2}-\\d{2}", file_name))[[1]]
    
    # Assumiamo che ci siano due date (inizio e fine periodo)
    if (length(dates) == 2) {
        start_date <- dates[1]
        end_date <- dates[2]
    } else {
        # Se non si trovano due date, impostiamo valori di default
        start_date <- "Data_iniziale"
        end_date <- "Data_finale"
    }
    
    # ====================================================
    # Caricamento dati raster e modello SOM
    # ====================================================
    
    img <- rast(tif_path)
    selected_bands <- c(1, 2, 3, 4, 5, 7)  
    l_data <- img[[selected_bands]]
    
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    som_values <- som_model$codes[[1]]
    
    # ====================================================
    # Numero ottimale di cluster
    # ====================================================
    
    optimal_clusters <- 6
    cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")
    
    # ====================================================
    # Clustering con K-means
    # ====================================================
    
    kmeans_nbclust <- kmeans(
        som_values, 
        centers = optimal_clusters, 
        nstart = 20, 
        iter.max = 1000
    )
    cat("Clustering con kmeans completato.\n")
    
    # ====================================================
    # Creazione del raster classificato
    # ====================================================
    
    classified_raster <- rast(img)
    values(classified_raster) <- NA
    mask <- !is.na(values(img[[1]]))
    
    cluster_assignments <- kmeans_nbclust$cluster[som_model$unit.classif]
    
    if (length(cluster_assignments) != sum(mask)) {
        stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
    }
    
    values(classified_raster)[mask] <- cluster_assignments
    classified_raster_single <- classified_raster[[1]]
    
    # ====================================================
    # Calcolo delle aree dei cluster
    # ====================================================
    
    area_totale <- expanse(classified_raster_single, byValue = TRUE, unit = "km")
    area_totale <- area_totale[order(area_totale$value), ]
    
    class_labels_updated <- data.frame(
        value = area_totale$value,
        Classe = paste("Cluster", area_totale$value, 
                       "(", round(area_totale$area, 2), " km²)")
    )
    
    levels(classified_raster_single) <- class_labels_updated
    print(levels(classified_raster_single))
    
    # ====================================================
    # Creazione della mappa Leaflet con data
    # ====================================================
    
    col_pal <- viridisLite::turbo(length(class_labels_updated$value))
    
    color_pal <- colorNumeric(
        palette = col_pal,
        domain = class_labels_updated$value,
        na.color = "transparent"
    )
    
    # Inseriamo le date nel titolo della legenda
    legend_title <- paste0("Cluster (", start_date, " - ", end_date, ")")
    
    leaflet_map <- leaflet() %>%
        addTiles(group = "OpenStreetMap") %>%
        addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
        addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
        addRasterImage(
            classified_raster_single, 
            colors = color_pal, 
            opacity = 0.8,
            project = TRUE,
            group = "Raster Classificato"
        ) %>%
        addLegend(
            position = "bottomright",
            colors = col_pal,
            labels = class_labels_updated$Classe,
            title = legend_title,
            opacity = 1
        ) %>%
        addLayersControl(
            baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
            overlayGroups = c("Raster Classificato"),
            options = layersControlOptions(collapsed = FALSE),
            position = "topright"
        )
    
    print(leaflet_map)
    
    cat("Elaborazione completata per:", tif_path, "\n")
}

























# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "tclust", "viridisLite", "htmltools"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

setwd("C:/composite")

# ====================================================
# Sezione 3: Caricamento e preparazione dei dati
# ====================================================

img_84 <- rast("L5 Composite 1984-1990_masked.tif")
selected_bands <- c(1, 2, 3, 4, 5, 7)
l1984 <- img_84[[selected_bands]]

som_model <- readRDS("som_model_20X20_84-90_1000_NO_PCA.rds")
cat("Modello SOM caricato correttamente.\n")

som_values <- som_model$codes[[1]]

# ====================================================
# Sezione 4: Impostazione del numero ottimale di cluster
# ====================================================

optimal_clusters <- 6
cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")

# ====================================================
# Sezione 5: Clustering con K-means
# ====================================================

kmeans_nbclust <- kmeans(
    som_values, 
    centers = optimal_clusters, 
    nstart = 20, 
    iter.max = 1000
)
cat("Clustering con kmeans completato.\n")

# ====================================================
# Sezione 6: Creazione del raster classificato
# ====================================================

classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))

cluster_assignments <- kmeans_nbclust$cluster[som_model$unit.classif]

if (length(cluster_assignments) != sum(mask)) {
    stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
}

values(classified_raster_nbclust)[mask] <- cluster_assignments
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# ====================================================
# Sezione 7: Calcolo delle aree dei cluster
# ====================================================

area_totale <- expanse(classified_raster_nbclust_single, byValue = TRUE, unit = "km")
area_totale <- area_totale[order(area_totale$value), ]

class_labels_updated <- data.frame(
    value = area_totale$value,
    Classe = paste("Cluster", area_totale$value, 
                   "(", round(area_totale$area, 2), " km²)")
)

levels(classified_raster_nbclust_single) <- class_labels_updated
print(levels(classified_raster_nbclust_single))

# ====================================================
# Sezione 8: Creazione della mappa Leaflet
# ====================================================

col_pal <- viridisLite::turbo(length(class_labels_updated$value))

color_pal <- colorNumeric(
    palette = col_pal,
    domain = class_labels_updated$value,
    na.color = "transparent"
)

leaflet_map_updated <- leaflet() %>%
    addTiles(group = "OpenStreetMap") %>%
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
    addRasterImage(
        classified_raster_nbclust_single, 
        colors = color_pal, 
        opacity = 0.8,
        project = TRUE,
        group = "Raster Classificato"
    ) %>%
    addLegend(
        position = "bottomright",
        colors = col_pal,
        labels = class_labels_updated$Classe,
        title = "Cluster",
        opacity = 1
    ) %>%
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
        overlayGroups = c("Raster Classificato"),
        options = layersControlOptions(collapsed = FALSE),
        position = "topright"
    )

leaflet_map_updated























# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "tclust", "viridisLite", "htmltools"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

tif_dir <- "C:/composite_sila"
rds_dir <- "C:/composite_sila/som_sila"

# ====================================================
# Sezione 3: Individuazione e loop sui file
# ====================================================

tif_files <- list.files(path = tif_dir, pattern = "\\.tif$", full.names = TRUE)

for (tif_path in tif_files) {
    rds_name <- paste0(basename(tif_path), "_som_model.rds")
    rds_path <- file.path(rds_dir, rds_name)
    
    if (!file.exists(rds_path)) {
        cat("File RDS corrispondente non trovato per:", tif_path, "\n")
        next
    }
    
    cat("\nProcesso il file:", tif_path, "con il modello:", rds_path, "\n")
    
    # Estrazione date dal nome del file tif
    file_name <- basename(tif_path)
    # Trova tutte le occorrenze di YYYY-MM-DD nel nome
    dates <- regmatches(file_name, gregexpr("\\d{4}-\\d{2}-\\d{2}", file_name))[[1]]
    
    # Assumiamo che ci siano due date (inizio e fine periodo)
    if (length(dates) == 2) {
        start_date <- dates[1]
        end_date <- dates[2]
    } else {
        # Se non si trovano due date, impostiamo valori di default
        start_date <- "Data_iniziale"
        end_date <- "Data_finale"
    }
    
    # Caricamento dati raster e modello SOM
    img <- rast(tif_path)
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    som_values <- som_model$codes[[1]]
    
    # Numero ottimale di cluster
    optimal_clusters <- 6
    cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")
    
    # Clustering con K-means
    kmeans_nbclust <- kmeans(
        som_values, 
        centers = optimal_clusters, 
        nstart = 20, 
        iter.max = 1000
    )
    cat("Clustering con kmeans completato.\n")
    
    # Creazione del raster classificato
    classified_raster <- rast(img)
    values(classified_raster) <- NA
    mask <- !is.na(values(img[[1]]))
    
    cluster_assignments <- kmeans_nbclust$cluster[som_model$unit.classif]
    
    if (length(cluster_assignments) != sum(mask)) {
        stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
    }
    
    values(classified_raster)[mask] <- cluster_assignments
    classified_raster_single <- classified_raster[[1]]
    
    # Calcolo delle aree dei cluster
    area_totale <- expanse(classified_raster_single, byValue = TRUE, unit = "km")
    area_totale <- area_totale[order(area_totale$value), ]
    
    class_labels_updated <- data.frame(
        value = area_totale$value,
        Classe = paste("Cluster", area_totale$value, 
                       "(", round(area_totale$area, 2), " km²)")
    )
    
    levels(classified_raster_single) <- class_labels_updated
    print(levels(classified_raster_single))
    
    # Creazione della mappa Leaflet con date
    col_pal <- viridisLite::turbo(length(class_labels_updated$value))
    
    color_pal <- colorNumeric(
        palette = col_pal,
        domain = class_labels_updated$value,
        na.color = "transparent"
    )
    
    legend_title <- paste0("Cluster (", start_date, " - ", end_date, ")")
    
    leaflet_map <- leaflet() %>%
        addTiles(group = "OpenStreetMap") %>%
        addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
        addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
        addRasterImage(
            classified_raster_single, 
            colors = color_pal, 
            opacity = 0.8,
            project = TRUE,
            group = "Raster Classificato"
        ) %>%
        addLegend(
            position = "bottomright",
            colors = col_pal,
            labels = class_labels_updated$Classe,
            title = legend_title,
            opacity = 1
        ) %>%
        addLayersControl(
            baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
            overlayGroups = c("Raster Classificato"),
            options = layersControlOptions(collapsed = FALSE),
            position = "topright"
        )
    
    print(leaflet_map)
    
    cat("Elaborazione completata per:", tif_path, "\n")
}




















#KMEANS ++




# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "tclust", "viridisLite", "htmltools", "ClusterR"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

tif_dir <- "C:/composite_sila"
rds_dir <- "C:/composite_sila/som_sila"

# ====================================================
# Sezione 3: Individuazione e loop sui file
# ====================================================

tif_files <- list.files(path = tif_dir, pattern = "\\.tif$", full.names = TRUE)

for (tif_path in tif_files) {
    rds_name <- paste0(basename(tif_path), "_som_model.rds")
    rds_path <- file.path(rds_dir, rds_name)
    
    if (!file.exists(rds_path)) {
        cat("File RDS corrispondente non trovato per:", tif_path, "\n")
        next
    }
    
    cat("\nProcesso il file:", tif_path, "con il modello:", rds_path, "\n")
    
    # Estrazione date dal nome del file tif
    file_name <- basename(tif_path)
    # Trova tutte le occorrenze di YYYY-MM-DD nel nome
    dates <- regmatches(file_name, gregexpr("\\d{4}-\\d{2}-\\d{2}", file_name))[[1]]
    
    # Assumiamo che ci siano due date (inizio e fine periodo)
    if (length(dates) == 2) {
        start_date <- dates[1]
        end_date <- dates[2]
    } else {
        start_date <- "Data_iniziale"
        end_date <- "Data_finale"
    }
    
    # Caricamento dati raster e modello SOM
    img <- rast(tif_path)
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    som_values <- som_model$codes[[1]]
    
    # Numero ottimale di cluster
    optimal_clusters <- 6
    cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")
    
    # Clustering con k-means++ tramite ClusterR::KMeans_rcpp
    library(ClusterR)
    kmeans_res <- KMeans_rcpp(
        data = som_values,
        clusters = optimal_clusters,
        initializer = "kmeans++",
        max_iters = 1000,
        num_init = 100,    # aggiunto questo parametro
        verbose = FALSE
    )
    
    # kmeans_res$clusters contiene l'assegnamento dei cluster per ogni punto
    cluster_assignments <- kmeans_res$clusters[som_model$unit.classif]
    
    cat("Clustering con kmeans++ (ClusterR) completato.\n")
    
    # Creazione del raster classificato
    classified_raster <- rast(img)
    values(classified_raster) <- NA
    mask <- !is.na(values(img[[1]]))
    
    if (length(cluster_assignments) != sum(mask)) {
        stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
    }
    
    values(classified_raster)[mask] <- cluster_assignments
    classified_raster_single <- classified_raster[[1]]
    
    # Calcolo delle aree dei cluster
    area_totale <- expanse(classified_raster_single, byValue = TRUE, unit = "km")
    area_totale <- area_totale[order(area_totale$value), ]
    
    class_labels_updated <- data.frame(
        value = area_totale$value,
        Classe = paste("Cluster", area_totale$value, 
                       "(", round(area_totale$area, 2), " km²)")
    )
    
    levels(classified_raster_single) <- class_labels_updated
    print(levels(classified_raster_single))
    
    # Creazione della mappa Leaflet con date
    col_pal <- viridisLite::turbo(length(class_labels_updated$value))
    
    color_pal <- colorNumeric(
        palette = col_pal,
        domain = class_labels_updated$value,
        na.color = "transparent"
    )
    
    legend_title <- paste0("Cluster (", start_date, " - ", end_date, ")")
    
    leaflet_map <- leaflet() %>%
        addTiles(group = "OpenStreetMap") %>%
        addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
        addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
        addRasterImage(
            classified_raster_single, 
            colors = color_pal, 
            opacity = 0.8,
            project = TRUE,
            group = "Raster Classificato"
        ) %>%
        addLegend(
            position = "bottomright",
            colors = col_pal,
            labels = class_labels_updated$Classe,
            title = legend_title,
            opacity = 1
        ) %>%
        addLayersControl(
            baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
            overlayGroups = c("Raster Classificato"),
            options = layersControlOptions(collapsed = FALSE),
            position = "topright"
        )
    
    print(leaflet_map)
    
    cat("Elaborazione completata per:", tif_path, "\n")
}























# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "tclust", "viridisLite", "htmltools"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

tif_dir <- "C:/composite_sila"
rds_dir <- "C:/composite_sila/som_sila"

# ====================================================
# Sezione 3: Individuazione e loop sui file
# ====================================================

tif_files <- list.files(path = tif_dir, pattern = "\\.tif$", full.names = TRUE)

for (tif_path in tif_files) {
    rds_name <- paste0(basename(tif_path), "_som_model.rds")
    rds_path <- file.path(rds_dir, rds_name)
    
    if (!file.exists(rds_path)) {
        cat("File RDS corrispondente non trovato per:", tif_path, "\n")
        next
    }
    
    cat("\nProcesso il file:", tif_path, "con il modello:", rds_path, "\n")
    
    # Estrazione date dal nome del file tif
    file_name <- basename(tif_path)
    # Trova tutte le occorrenze di YYYY-MM-DD nel nome
    dates <- regmatches(file_name, gregexpr("\\d{4}-\\d{2}-\\d{2}", file_name))[[1]]
    
    # Assumiamo che ci siano due date (inizio e fine periodo)
    if (length(dates) == 2) {
        start_date <- dates[1]
        end_date <- dates[2]
    } else {
        start_date <- "Data_iniziale"
        end_date <- "Data_finale"
    }
    
    # Caricamento dati raster e modello SOM
    img <- rast(tif_path)
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    som_values <- som_model$codes[[1]]
    
    # Numero ottimale di cluster
    optimal_clusters <- 6
    cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")
    
    # Clustering con tclustCBI
    fixmahal_result <- tclustCBI(som_values, 
                                 k = optimal_clusters, 
                                 trim = 0, 
                                 restr.fact = 256)
    cat("Clustering con tclustCBI completato.\n")
    
    # Creazione del raster classificato
    classified_raster <- rast(img)
    values(classified_raster) <- NA
    mask <- !is.na(values(img[[1]]))
    
    cluster_assignments <- fixmahal_result$partition[som_model$unit.classif]
    
    if (length(cluster_assignments) != sum(mask)) {
        stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
    }
    
    values(classified_raster)[mask] <- cluster_assignments
    classified_raster_single <- classified_raster[[1]]
    
    # Calcolo delle aree dei cluster
    area_totale <- expanse(classified_raster_single, byValue = TRUE, unit = "km")
    # Ordiniamo per valore di cluster
    area_totale <- area_totale[order(area_totale$value), ]
    
    # Crea la tabella aggiornata delle etichette
    class_labels_updated <- data.frame(
        value = area_totale$value,
        Classe = paste("Cluster", area_totale$value, 
                       "(", round(area_totale$area, 2), " km²)")
    )
    
    # Aggiorna i livelli del raster
    levels(classified_raster_single) <- class_labels_updated
    print(levels(classified_raster_single))
    
    # Creazione della mappa Leaflet con date
    col_pal <- viridisLite::turbo(length(class_labels_updated$value))
    
    color_pal <- colorNumeric(
        palette = col_pal,
        domain = class_labels_updated$value,
        na.color = "transparent"
    )
    
    legend_title <- paste0("Cluster (", start_date, " - ", end_date, ")")
    
    leaflet_map <- leaflet() %>%
        addTiles(group = "OpenStreetMap") %>%
        addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
        addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
        addRasterImage(
            classified_raster_single, 
            colors = color_pal, 
            opacity = 0.8,
            project = TRUE,
            group = "Raster Classificato"
        ) %>%
        addLegend(
            position = "bottomright",
            colors = col_pal,
            labels = class_labels_updated$Classe,
            title = legend_title,
            opacity = 1
        ) %>%
        addLayersControl(
            baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
            overlayGroups = c("Raster Classificato"),
            options = layersControlOptions(collapsed = FALSE),
            position = "topright"
        )
    
    print(leaflet_map)
    
    cat("Elaborazione completata per:", tif_path, "\n")
}














#mclust

# ====================================================
# Sezione 1: Installazione e caricamento delle librerie
# ====================================================

check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed], dependencies = TRUE)
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c(
    "fpc", "terra", "dplyr", "kohonen",
    "parallel", "leaflet", "ggplot2", "viridis", 
    "mclust", "viridisLite", "htmltools"
)

check_and_install(required_packages)

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================

tif_dir <- "C:/composite_stelvio"
rds_dir <- "C:/composite_stelvio/som_stelvio"

# ====================================================
# Sezione 3: Individuazione e loop sui file
# ====================================================

tif_files <- list.files(path = tif_dir, pattern = "\\.tif$", full.names = TRUE)

for (tif_path in tif_files) {
    rds_name <- paste0(basename(tif_path), "_som_model.rds")
    rds_path <- file.path(rds_dir, rds_name)
    
    if (!file.exists(rds_path)) {
        cat("File RDS corrispondente non trovato per:", tif_path, "\n")
        next
    }
    
    cat("\nProcesso il file:", tif_path, "con il modello:", rds_path, "\n")
    
    # Estrazione date dal nome del file tif
    file_name <- basename(tif_path)
    # Trova tutte le occorrenze di YYYY-MM-DD nel nome
    dates <- regmatches(file_name, gregexpr("\\d{4}-\\d{2}-\\d{2}", file_name))[[1]]
    
    # Assumiamo che ci siano due date (inizio e fine periodo)
    if (length(dates) == 2) {
        start_date <- dates[1]
        end_date <- dates[2]
    } else {
        start_date <- "Data_iniziale"
        end_date <- "Data_finale"
    }
    
    # Caricamento dati raster e modello SOM
    img <- rast(tif_path)
    som_model <- readRDS(rds_path)
    cat("Modello SOM caricato correttamente.\n")
    
    som_values <- som_model$codes[[1]]
    
    # Numero ottimale di cluster (impostato manualmente)
    optimal_clusters <- 3
    cat("Numero ottimale di cluster impostato a:", optimal_clusters, "\n")
    
    # Clustering con Mclust
    mclust_model <- Mclust(som_values, G = optimal_clusters)
    cat("Clustering con Mclust completato.\n")
    
    # Associazioni dei cluster alle unità SOM
    unit_clusters <- mclust_model$classification
    # Per ogni pixel, assegnamo il cluster dell'unità SOM corrispondente
    cluster_assignments <- unit_clusters[som_model$unit.classif]
    
    # Creazione del raster classificato
    classified_raster <- rast(img)
    values(classified_raster) <- NA
    mask <- !is.na(values(img[[1]]))
    
    if (length(cluster_assignments) != sum(mask)) {
        stop("La lunghezza di 'cluster_assignments' non corrisponde al numero di pixel mascherati.")
    }
    
    values(classified_raster)[mask] <- cluster_assignments
    classified_raster_single <- classified_raster[[1]]
    
    # Calcolo delle aree dei cluster
    area_totale <- expanse(classified_raster_single, byValue = TRUE, unit = "km")
    # Ordiniamo per valore di cluster
    area_totale <- area_totale[order(area_totale$value), ]
    
    # Crea la tabella aggiornata delle etichette
    class_labels_updated <- data.frame(
        value = area_totale$value,
        Classe = paste("Cluster", area_totale$value, 
                       "(", round(area_totale$area, 2), " km²)")
    )
    
    # Aggiorna i livelli del raster
    levels(classified_raster_single) <- class_labels_updated
    print(levels(classified_raster_single))
    
    # Creazione della mappa Leaflet con date
    col_pal <- viridisLite::turbo(length(class_labels_updated$value))
    
    color_pal <- colorNumeric(
        palette = col_pal,
        domain = class_labels_updated$value,
        na.color = "transparent"
    )
    
    legend_title <- paste0("Cluster (", start_date, " - ", end_date, ")")
    
    leaflet_map <- leaflet() %>%
        addTiles(group = "OpenStreetMap") %>%
        addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
        addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
        addRasterImage(
            classified_raster_single, 
            colors = color_pal, 
            opacity = 0.8,
            project = TRUE,
            group = "Raster Classificato"
        ) %>%
        addLegend(
            position = "bottomright",
            colors = col_pal,
            labels = class_labels_updated$Classe,
            title = legend_title,
            opacity = 1
        ) %>%
        addLayersControl(
            baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
            overlayGroups = c("Raster Classificato"),
            options = layersControlOptions(collapsed = FALSE),
            position = "topright"
        )
    
    print(leaflet_map)
    
    cat("Elaborazione completata per:", tif_path, "\n")
}
