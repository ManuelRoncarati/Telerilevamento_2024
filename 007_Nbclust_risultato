# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", "leaflet", "ggplot2", "viridis")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglino.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime due componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime due componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))
# [1] "Numero di osservazioni valide: 1069509"

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))
# [1] "Numero suggerito di neuroni: 5171"

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))
# [1] "Dimensioni della griglia suggerite: 72 x 72"

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input e alpha = 0
som_model <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 500, 
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Determina il numero ottimale di cluster con NbClust
library(NbClust)

set.seed(123)  # Per riproducibilità
nbclust_result <- NbClust(
    data = som_values, 
    diss = NULL, 
    distance = "euclidean",  # Distanza euclidea
    min.nc = 2,              # Numero minimo di cluster
    max.nc = 10,             # Numero massimo di cluster
    method = "kmeans",       # Metodo di clustering K-means
    index = "all"            # Usa tutti i criteri di validazione
)

# **Risultati di NbClust**:
# La maggior parte dei criteri (11 su 23) ha indicato che il numero ottimale di cluster è 5.

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))

# Stampa il numero ottimale di cluster
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")
# Il numero ottimale di cluster secondo NbClust è: 5

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
library(fpc)

clusterboot_result <- clusterboot(
    data = som_values,            # Usa i valori SOM
    B = 500,                      # Numero di campioni bootstrap
    clustermethod = kmeansCBI,    # Metodo K-means tramite interfaccia kmeansCBI
    bootmethod = "boot",          # Usa bootstrap non parametrico
    dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
    recover = 0.75,               # Valore di recupero per i cluster stabili
    count = FALSE,                # Mostra il progresso durante il bootstrap
    k = optimal_clusters          # Usa il numero ottimale di cluster trovato con NbClust
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
# Risultati della stabilità dei cluster con clusterboot:

print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
# [1] 0.9606279 0.8999107 0.8846796 0.9088574 0.9564157

print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
# [1] 498 438 438 445 463

print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
# [1]  0 35 60 22  0

# Visualizzazione della stabilità
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")


#ora visualizziamo la clusterizzazione con kemeans e il numero di cluster ritenuto ottimale

# Esegui K-means con 5 cluster e gestisci le iterazioni
set.seed(42)  # Imposta il seme per garantire la riproducibilità
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con 5 cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))  # Crea una maschera dai valori non NA del raster originale
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
    # Aggiungi le tiles di base
    addTiles(group = "OpenStreetMap") %>%
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
    
    # Aggiungi il raster classificato con 5 cluster
    addRasterImage(classified_raster_nbclust_single, 
                   colors = palette_turbo(optimal_clusters), 
                   opacity = 0.6, 
                   group = "Classificato con K-means (5 Cluster)") %>%
    
    # Aggiungi i controlli per cambiare i layer di base e i gruppi di layer
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),  # Layer di base
        overlayGroups = c("Classificato con K-means (5 Cluster)"),  # Layer classificati
        options = layersControlOptions(collapsed = FALSE)  # Espandi il menu dei layer di default
    ) %>%
    
    # Aggiungi una barra di scala
    addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
    
    # Centra la mappa sul raster (modifica i valori per il tuo AOI)
    setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")






















# Carica le librerie necessarie
library(terra)
library(leaflet)
library(leafem)
library(raster)
library(OpenImageR)
library(SuperpixelImageSegmentation)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Riduci il numero di bande a 3 per evitare problemi di dimensionalità
l1984_reduced <- l1984[[1:3]]

# Crea una maschera per i valori non NA
valid_mask <- !is.na(l1984_reduced[[1]]) & !is.na(l1984_reduced[[2]]) & !is.na(l1984_reduced[[3]])

# Applica la maschera per ottenere solo i valori non NA
l1984_reduced_non_na <- mask(l1984_reduced, valid_mask, maskvalue = FALSE)

# Converti il raster ridotto in un RasterBrick per leaflet
rgb_image_raster <- brick(l1984_reduced_non_na)

# Converti l'immagine in array per OpenImageR
pca_rgb_array <- as.array(l1984_reduced_non_na)

# Normalizza i valori dell'immagine tra 0 e 255
pca_rgb_array <- pca_rgb_array * 255 / max(pca_rgb_array, na.rm = TRUE)

# Inizializza l'oggetto Image_Segmentation
init <- Image_Segmentation$new()

# Esegui la segmentazione dei superpixel con Affinity Propagation e SLIC (SLICAP)
spx <- init$spixel_segmentation(
    method = "slic",
    input_image = pca_rgb_array,
    superpixel = 1000,
    AP_data = TRUE,
    use_median = TRUE,
    sim_wL = 3,
    sim_wA = 10,
    sim_wB = 10,
    sim_color_radius = 10,
    kmeans_method = "kmeans",
    kmeans_initializer = "kmeans++",
    kmeans_num_init = 3,
    kmeans_max_iters = 100,
    colour_type = "LAB",
    verbose = TRUE
)

# Visualizza la struttura dell'output spx
str(spx)

# Applica la maschera di valori validi all'immagine segmentata KMeans
if (!is.null(spx$KMeans_image_data)) {
    kmeans_rgb_array <- spx$KMeans_image_data
    kmeans_rgb_array[!as.array(valid_mask)] <- NA  # Imposta i valori non validi a NA per la trasparenza
    kmeans_raster_1 <- raster(as.matrix(kmeans_rgb_array[,,1]))
    kmeans_raster_2 <- raster(as.matrix(kmeans_rgb_array[,,2]))
    kmeans_raster_3 <- raster(as.matrix(kmeans_rgb_array[,,3]))
    kmeans_rgb_image_raster <- brick(kmeans_raster_1, kmeans_raster_2, kmeans_raster_3)
    crs(kmeans_rgb_image_raster) <- crs(l1984_reduced_non_na)
    extent(kmeans_rgb_image_raster) <- extent(rgb_image_raster)
    leaflet_map <- leaflet() %>%
        addProviderTiles(providers$Esri.WorldImagery, group = "Esri World Imagery") %>%
        addProviderTiles(providers$CartoDB.Positron, group = "CartoDB Positron") %>%
        addProviderTiles(providers$OpenStreetMap, group = "OpenStreetMap") %>%
        addRasterRGB(
            rgb_image_raster,
            r = 1, g = 2, b = 3,
            group = "Original RGB",
            options = tileOptions(opacity = 0.7, minZoom = 1, maxZoom = 18)
        ) %>%
        addRasterRGB(
            kmeans_rgb_image_raster,
            r = 1, g = 2, b = 3,
            group = "KMeans RGB",
            options = tileOptions(opacity = 0.7, minZoom = 1, maxZoom = 18)
        ) %>%
        addLayersControl(
            baseGroups = c("Esri World Imagery", "CartoDB Positron", "OpenStreetMap"),
            overlayGroups = c("Original RGB", "KMeans RGB"),
            options = layersControlOptions(collapsed = FALSE)
        )
}

leaflet_map





































# Carica le librerie necessarie
check_and_install <- function(packages) {
  installed <- packages %in% rownames(installed.packages())
  if (any(!installed)) {
    install.packages(packages[!installed])
  }
  invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", "leaflet", "ggplot2", "viridis")
check_and_install(required_packages)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglino.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

library(terra)
library(mmand)

# Crea lo stack
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Converte lo stack in un array
stack_array <- as.array(stack_1984)

# Crea il kernel "diamond"
k <- shapeKernel(c(3, 3), type = "diamond")

# Applica l'erosione su tutte le bande
eroded_stack_array <- opening(stack_array, k)

# Riconverti l'array in uno SpatRaster
eroded_stack_raster <- rast(eroded_stack_array, crs = crs(stack_1984), extent = ext(stack_1984))

# Assegna i nomi corretti ai layer
band_names <- c("SR_B1", "SR_B2", "SR_B3", "SR_B4", "SR_B5", "SR_B7")
index_names <- c("NDVI_1984", "MNDWI_1984", "NDBI_1984")
names(eroded_stack_raster) <- c(band_names, index_names)

# Visualizza il risultato
plot(eroded_stack_raster)

# Rimuovi valori Inf e NA da eroded_stack_raster
eroded_stack_raster[is.infinite(eroded_stack_raster)] <- NA
eroded_stack_raster[is.na(eroded_stack_raster)] <- NA

# Oppure, se vuoi sostituire con un valore specifico, ad esempio 0:
# eroded_stack_raster[is.infinite(eroded_stack_raster)] <- 0
# eroded_stack_raster[is.na(eroded_stack_raster)] <- 0

# Visualizza un riepilogo per verificare
summary(eroded_stack_raster)

# Visualizza il risultato
plot(eroded_stack_raster)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime due componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime due componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))
# [1] "Numero di osservazioni valide: 1069509"

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))
# [1] "Numero suggerito di neuroni: 5171"

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))
# [1] "Dimensioni della griglia suggerite: 72 x 72"

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input e alpha = 0
som_model <- supersom(
  list(pca_values), 
  grid = som_grid, 
  rlen = 500, 
  mode = "pbatch", 
  cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Determina il numero ottimale di cluster con NbClust
library(NbClust)


nbclust_result <- NbClust(
  data = som_values, 
  diss = NULL, 
  distance = "euclidean",  # Distanza euclidea
  min.nc = 2,              # Numero minimo di cluster
  max.nc = 10,             # Numero massimo di cluster
  method = "kmeans",       # Metodo di clustering K-means
  index = "all"            # Usa tutti i criteri di validazione
)

# **Risultati di NbClust**:
# La maggior parte dei criteri (11 su 23) ha indicato che il numero ottimale di cluster è 5.

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))

# Stampa il numero ottimale di cluster
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")
# Il numero ottimale di cluster secondo NbClust è: 5

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
library(fpc)

clusterboot_result <- clusterboot(
  data = som_values,            # Usa i valori SOM
  B = 500,                      # Numero di campioni bootstrap
  clustermethod = kmeansCBI,    # Metodo K-means tramite interfaccia kmeansCBI
  bootmethod = "boot",          # Usa bootstrap non parametrico
  dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
  recover = 0.75,               # Valore di recupero per i cluster stabili
  count = FALSE,                # Mostra il progresso durante il bootstrap
  k = optimal_clusters          # Usa il numero ottimale di cluster trovato con NbClust
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
# Risultati della stabilità dei cluster con clusterboot:

print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
# [1] 0.9606279 0.8999107 0.8846796 0.9088574 0.9564157

print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
# [1] 498 438 438 445 463

print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
# [1]  0 35 60 22  0

# Visualizzazione della stabilità
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")


#ora visualizziamo la clusterizzazione con kemeans e il numero di cluster ritenuto ottimale

# Esegui K-means con 5 cluster e gestisci le iterazioni
kmeans_nbclust <- kmeans(som_values, centers = 3, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con 5 cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))  # Crea una maschera dai valori non NA del raster originale
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
  # Aggiungi le tiles di base
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
  
  # Aggiungi il raster classificato con 5 cluster
  addRasterImage(classified_raster_nbclust_single, 
                 colors = palette_turbo(3), 
                 opacity = 0.6, 
                 group = "Classificato con K-means (5 Cluster)") %>%
  
  # Aggiungi i controlli per cambiare i layer di base e i gruppi di layer
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),  # Layer di base
    overlayGroups = c("Classificato con K-means (5 Cluster)"),  # Layer classificati
    options = layersControlOptions(collapsed = FALSE)  # Espandi il menu dei layer di default
  ) %>%
  
  # Aggiungi una barra di scala
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
  
  # Centra la mappa sul raster (modifica i valori per il tuo AOI)
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")


























# Carica le librerie necessarie
check_and_install <- function(packages) {
  installed <- packages %in% rownames(installed.packages())
  if (any(!installed)) {
    install.packages(packages[!installed])
  }
  invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", 'mmand',"kohonen", "parallel", "leaflet", "ggplot2", "viridis")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglino.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime due componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime due componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))
# [1] "Numero di osservazioni valide: 1069509"

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))
# [1] "Numero suggerito di neuroni: 5171"

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))
# [1] "Dimensioni della griglia suggerite: 72 x 72"

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input e alpha = 0
som_model <- supersom(
  list(pca_values), 
  grid = som_grid, 
  rlen = 500, 
  mode = "pbatch", 
  cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Determina il numero ottimale di cluster con NbClust
library(NbClust)

set.seed(123)  # Per riproducibilità
nbclust_result <- NbClust(
  data = som_values, 
  diss = NULL, 
  distance = "euclidean",  # Distanza euclidea
  min.nc = 2,              # Numero minimo di cluster
  max.nc = 10,             # Numero massimo di cluster
  method = "kmeans",       # Metodo di clustering K-means
  index = "all"            # Usa tutti i criteri di validazione
)

# **Risultati di NbClust**:
# La maggior parte dei criteri (11 su 23) ha indicato che il numero ottimale di cluster è 5.

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))

# Stampa il numero ottimale di cluster
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")
# Il numero ottimale di cluster secondo NbClust è: 5

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
library(fpc)

clusterboot_result <- clusterboot(
  data = som_values,            # Usa i valori SOM
  B = 500,                      # Numero di campioni bootstrap
  clustermethod = kmeansCBI,    # Metodo K-means tramite interfaccia kmeansCBI
  bootmethod = "boot",          # Usa bootstrap non parametrico
  dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
  recover = 0.75,               # Valore di recupero per i cluster stabili
  count = FALSE,                # Mostra il progresso durante il bootstrap
  k = optimal_clusters          # Usa il numero ottimale di cluster trovato con NbClust
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
# Risultati della stabilità dei cluster con clusterboot:

print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
# [1] 0.9606279 0.8999107 0.8846796 0.9088574 0.9564157

print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
# [1] 498 438 438 445 463

print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
# [1]  0 35 60 22  0

# Visualizzazione della stabilità
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")


#ora visualizziamo la clusterizzazione con kemeans e il numero di cluster ritenuto ottimale

# Esegui K-means con 5 cluster e gestisci le iterazioni
set.seed(42)  # Imposta il seme per garantire la riproducibilità
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con 5 cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))  # Crea una maschera dai valori non NA del raster originale
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
  # Aggiungi le tiles di base
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
  
  # Aggiungi il raster classificato con 5 cluster
  addRasterImage(classified_raster_nbclust_single, 
                 colors = palette_turbo(optimal_clusters), 
                 opacity = 0.6, 
                 group = "Classificato con K-means (5 Cluster)") %>%
  
  # Aggiungi i controlli per cambiare i layer di base e i gruppi di layer
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),  # Layer di base
    overlayGroups = c("Classificato con K-means (5 Cluster)"),  # Layer classificati
    options = layersControlOptions(collapsed = FALSE)  # Espandi il menu dei layer di default
  ) %>%
  
  # Aggiungi una barra di scala
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
  
  # Centra la mappa sul raster (modifica i valori per il tuo AOI)
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")





# Converte lo stack in un array
stack_array <- as.array(classified_raster_nbclust[[1]])

# Crea il kernel "diamond"
k <- shapeKernel(c(5,5), type = "disc")

# Applica l'erosione su tutte le bande
eroded_stack_array <- closing(stack_array,k) 
#pippo<- erode(eroded_stack_array,k)
#eroded_stack_array<-pippo
# Riconverti l'array in uno SpatRaster
eroded_stack_raster <- rast(eroded_stack_array, crs = crs(classified_raster_nbclust), extent = ext(classified_raster_nbclust))

plot(eroded_stack_raster)



























# Carica le librerie necessarie
check_and_install <- function(packages) {
  installed <- packages %in% rownames(installed.packages())
  if (any(!installed)) {
    install.packages(packages[!installed])
  }
  invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", 'mmand',"kohonen", "parallel", "leaflet", "ggplot2", "viridis")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni valide:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input
som_model <- supersom(
  list(pca_values), 
  grid = som_grid, 
  rlen = 50, 
  mode = "pbatch", 
  cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Determina il numero ottimale di cluster con NbClust
nbclust_result <- NbClust(
  data = som_values, 
  diss = NULL, 
  distance = "euclidean",  # Distanza euclidea
  min.nc = 2,              # Numero minimo di cluster
  max.nc = 10,             # Numero massimo di cluster
  method = "kmeans",       # Metodo di clustering K-means
  index = "all"            # Usa tutti i criteri di validazione
)

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))

# Stampa il numero ottimale di cluster
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
clusterboot_result <- clusterboot(
  data = som_values,            # Usa i valori SOM
  B = 500,                      # Numero di campioni bootstrap
  clustermethod = kmeansCBI,    # Metodo K-means tramite interfaccia kmeansCBI
  bootmethod = "boot",          # Usa bootstrap non parametrico
  dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
  recover = 0.75,               # Valore di recupero per i cluster stabili
  count = FALSE,                # Mostra il progresso durante il bootstrap
  k = optimal_clusters          # Usa il numero ottimale di cluster trovato con NbClust
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto

# Visualizzazione della stabilità
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero di cluster ottimale
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))  # Crea una maschera dai valori non NA del raster originale
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
  addRasterImage(classified_raster_nbclust_single, 
                 colors = palette_turbo(optimal_clusters), 
                 opacity = 0.6, 
                 group = "Classificato con K-means (5 Cluster)") %>%
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("Classificato con K-means (5 Cluster)"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
  hideGroup("Classificato con K-means (5 Cluster)") %>%  # Nascondi i layer inizialmente per evitare conflitti
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")

# Converte lo stack in un array
stack_array <- as.array(classified_raster_nbclust)

# Crea il kernel "diamond"
k <- shapeKernel(c(2,2), type = "disc")

# Applica l'erosione su tutte le bande
eroded_stack_array <- opening(stack_array, k)

# Riconverti l'array in uno SpatRaster
eroded_stack_raster <- rast(eroded_stack_array, crs = crs(classified_raster_nbclust_single), extent = ext(classified_raster_nbclust_single))
pippo <- eroded_stack_raster[[1]]
plot(pippo)

# Sostituisci valori non validi con NA
pippo[is.infinite(pippo)] <- NA
pippo[pippo < 0] <- NA  # Elimina valori negativi non attesi

leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
  addRasterImage(classified_raster_nbclust_single, 
                 colors = palette_turbo(optimal_clusters), opacity = 0.6,
                 group = "Classificato con kmeans") %>%
  addRasterImage(pippo, 
                 colors = palette_turbo(optimal_clusters), opacity = 0.6,
                 group = "Classificato con kmeans + erode") %>%
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("Classificato con kmeans", "Classificato con kmeans + erode"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
  hideGroup("Classificato con kmeans") %>%  # Nascondi i layer inizialmente per evitare conflitti
  hideGroup("Classificato con kmeans + erode") %>%
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")







# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("terra", "OpenImageR")
check_and_install(required_packages)

# Carica l'immagine con un singolo layer
cazzo <- rast('cazzo.tif')

# Normalizza i valori dell'immagine tra 0 e 255
cazzo_values <- values(cazzo)
cazzo_normalized <- cazzo_values * 255 / max(cazzo_values, na.rm = TRUE)

# Converti l'immagine in un array a due dimensioni per SNIC
cazzo_array <- matrix(cazzo_normalized, nrow = nrow(cazzo), ncol = ncol(cazzo), byrow = TRUE)

# Applica l'algoritmo di superpixel utilizzando OpenImageR (usando una rappresentazione bidimensionale)
superpixel_result <- superpixels(
    input_image = cazzo_array,
    method = "slic",
    superpixel = 500,
    compactness = 10,
    return_labels = TRUE
)

# Ottieni le etichette dei superpixel
superpixel_labels <- superpixel_result$labels

# Visualizza la struttura dell'output "superpixel_labels"
str(superpixel_labels)

# Crea un raster per i superpixel
superpixel_raster <- rast(matrix(superpixel_labels, nrow = nrow(cazzo), ncol = ncol(cazzo), byrow = TRUE))

# Imposta l'estensione e il sistema di riferimento del raster per mantenerli consistenti con l'immagine originale
ext(superpixel_raster) <- ext(cazzo)
crs(superpixel_raster) <- crs(cazzo)

# Salva il risultato dei superpixel come raster
writeRaster(superpixel_raster, 'superpixel_result_singolo_layer.tif', overwrite = TRUE)

# Visualizza il raster dei superpixel
plot(superpixel_raster, main = "Superpixel Segmentation (Layer Singolo)")


















#NBCLUST COMPOSITA 84 90 20X20 1000_SOM NO PCA 20 ORE PER TUTTO, FORSE 6 ORE PER NBCLUST?



# Salva il modello SOM in un file
saveRDS(som_model, file = "som_model_20X20_84-90_1000_NO_PCA.rds")
cat("Modello SOM salvato correttamente.\n")

# Carica il modello SOM dal file
som_model <- readRDS("som_model_20X20_84-90_1000_NO_PCA.rds")
cat("Modello SOM caricato correttamente.\n")



*** : The Hubert index is a graphical method of determining the number of clusters.
                In the plot of Hubert index, we seek a significant knee that corresponds to a 
                significant increase of the value of the measure i.e the significant peak in Hubert
                index second differences plot. 
 
*** : The D index is a graphical method of determining the number of clusters. 
                In the plot of D index, we seek a significant knee (the significant peak in Dindex
                second differences plot) that corresponds to a significant increase of the value of
                the measure. 
 
******************************************************************* 
* Among all indices:                                                
* 9 proposed 2 as the best number of clusters 
* 3 proposed 3 as the best number of clusters 
* 1 proposed 5 as the best number of clusters 
* 8 proposed 6 as the best number of clusters 
* 1 proposed 9 as the best number of clusters 
* 2 proposed 10 as the best number of clusters 

                   ***** Conclusion *****                            
 
* According to the majority rule, the best number of clusters is  2 
 
 
******************************************************************* 
