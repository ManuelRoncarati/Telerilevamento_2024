#xgboost mclust

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(mclust)  # Per il clustering basato su modelli

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (img_84)
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori delle bande e indici come dataframe
values_bande <- as.data.frame(values(stack_1984))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande e indici
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering basato su modelli
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering basato su modelli
num_clusters <- 7  # Cambia questo valore se necessario
mclust_result <- Mclust(X, G = num_clusters)

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- mclust_result$classification - 1  # Le etichette devono partire da 0

# Prepara i dati di training per XGBoost
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Tutte le colonne tranne 'classe'
y_train <- as.numeric(values_bande_non_na$classe)  # XGBoost richiede etichette numeriche

# Crea una matrice DMatrix per XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Parametri per XGBoost
params <- list(
    objective = "multi:softmax",  # Classificazione multiclasse
    num_class = num_clusters,     # Numero di classi (cluster)
    eval_metric = "mlogloss",     # Log-loss multiclasse (puoi cambiarlo in "merror" se vuoi la precisione)
    
    # Parametri aggiuntivi
    eta = 0.01,                    # Tasso di apprendimento
    max_depth = 6,                # Profondità massima degli alberi
    subsample = 0.8,              # Percentuale di dati da campionare per ogni albero (evita l'overfitting)
    colsample_bytree = 0.8,       # Percentuale di colonne da campionare per ogni albero
    min_child_weight = 1,         # Peso minimo dei nodi foglia per la divisione
    gamma = 0,                    # Regolarizzazione per il controllo dell'overfitting
    lambda = 1,                   # Regolarizzazione L2 (Ridge)
    alpha = 0                     # Regolarizzazione L1 (Lasso)
)

# Addestra il modello XGBoost
xgb_model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 500,  # Numero di iterazioni (boosting rounds)
    early_stopping_rounds = 50,  # Arresto anticipato
    watchlist = list(train = dtrain),  # Lista per monitorare le prestazioni
    verbose = 1
)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(stack_1984))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)
dpred <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni con XGBoost
preds <- predict(xgb_model, dpred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(stack_1984), ncol = ncol(stack_1984), crs = crs(stack_1984), ext = ext(stack_1984))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[complete.cases(values_bande_full)] <- preds

# Visualizza il raster classificato utilizzando mapview
mapview(pred_raster, col.regions = magma(num_clusters), main = "Raster Classificato con XGBoost", maxpixels = ncell(pred_raster))






#bootstrap

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)  # Per l'algoritmo k-means++
library(fpc)       # Per clusterboot()

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dallo stack raster come dataframe
values_bande <- as.data.frame(values(stack_1984))

# Filtra solo i valori non nulli
non_na_mask <- complete.cases(values_bande)
values_bande_non_na <- values_bande[non_na_mask, ]

# Identifica le colonne delle bande e degli indici
band_columns <- names(values_bande_non_na)

# Prepara i dati per il clustering
X <- as.matrix(values_bande_non_na %>% select(all_of(band_columns)))

# Applica il clustering K-means++ utilizzando ClusterR
num_clusters <- 5  # Cambia questo valore se necessario
set.seed(123)  # Per riproducibilità
kmeans_result <- KMeans_rcpp(X, clusters = num_clusters, initializer = 'kmeans++')

# Aggiungi le etichette dei cluster ai dati
values_bande_non_na$classe <- kmeans_result$clusters - 1  # Le etichette devono partire da 0

# Valutazione della stabilità dei cluster utilizzando clusterboot()
set.seed(123)
cluster_stability <- clusterboot(
  X,                         # Dati di input
  B = 100,                   # Numero di bootstrap (puoi aumentare se necessario)
  clustermethod = kmeansCBI, # Metodo di clustering, qui k-means
  k = num_clusters,          # Numero di cluster
  bootmethod = "boot"        # Metodo di bootstrapping
)

# Stampa i risultati della stabilità dei cluster
cat("Stabilità dei cluster (Jaccard Index per cluster):", cluster_stability$bootmean, "\n")
cat("Cluster che sono stati ritenuti stabili:", cluster_stability$result$nc, "\n")

# Visualizza la stabilità per ciascun cluster
print(cluster_stability$bootmean)

# Prepara i dati di training per XGBoost (se necessario)
X_train <- as.matrix(values_bande_non_na %>% select(-classe))  # Tutte le colonne tranne 'classe'
y_train <- as.numeric(values_bande_non_na$classe)  # XGBoost richiede etichette numeriche

# Crea una matrice DMatrix per XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# Parametri per XGBoost
params <- list(
  objective = "multi:softmax",  # Classificazione multiclasse
  num_class = num_clusters,     # Numero di classi (cluster)
  eval_metric = "mlogloss",     # Log-loss multiclasse
  
  # Parametri aggiuntivi
  eta = 0.01,                   # Tasso di apprendimento
  max_depth = 6,                # Profondità massima degli alberi
  subsample = 0.8,              # Percentuale di dati da campionare per ogni albero
  colsample_bytree = 0.8,       # Percentuale di colonne da campionare per ogni albero
  min_child_weight = 1,         # Peso minimo dei nodi foglia per la divisione
  gamma = 0,                    # Regolarizzazione per il controllo dell'overfitting
  lambda = 1,                   # Regolarizzazione L2 (Ridge)
  alpha = 0                     # Regolarizzazione L1 (Lasso)
)

# Addestra il modello XGBoost (opzionale)
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 500,  # Numero di iterazioni (boosting rounds)
  early_stopping_rounds = 50,  # Arresto anticipato
  watchlist = list(train = dtrain),  # Monitoraggio delle prestazioni
  verbose = 1
)

# Effettua previsioni su tutto il raster
values_bande_full <- as.data.frame(values(stack_1984))
values_bande_non_na_full <- values_bande_full[complete.cases(values_bande_full), ]
X_pred <- as.matrix(values_bande_non_na_full)
dpred <- xgb.DMatrix(data = X_pred)

# Effettua le previsioni con XGBoost
preds <- predict(xgb_model, dpred)

# Verifica che il numero di previsioni corrisponda ai valori non nulli
print(length(preds))  # Deve essere uguale a nrow(values_bande_non_na_full)

# Crea un raster vuoto con le stesse dimensioni e risoluzione del raster originale
pred_raster <- rast(nrow = nrow(stack_1984), ncol = ncol(stack_1984), crs = crs(stack_1984), ext = ext(stack_1984))

# Riempie il raster con le previsioni solo per i pixel non nulli
values(pred_raster) <- NA  # Inizialmente setta tutto a NA
values(pred_raster)[non_na_mask] <- preds  # Usa la maschera per riempire i pixel


















# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)  # Per l'algoritmo k-means++
library(fpc)       # Per clusterboot()
library(e1071)     # Per Fuzzy C-means
library(clusterSim)

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come matrice e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# Esegui la PCA su tutti i dati scalati
pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)

# Seleziona le prime 2 componenti principali dalla PCA
pca_2comp <- pca_result$x[, 1:2]

# Definisci il numero massimo di cluster da testare
k_max <- 15

# Inizializza le variabili per memorizzare i valori degli indici Calinski-Harabasz e Davies-Bouldin
ch_index_values <- numeric()
db_index_values <- numeric()

# Ciclo per eseguire Fuzzy C-means sulle prime 2 componenti principali e calcolare gli indici CH e DB
for (k in 2:k_max) {
    # Esegui Fuzzy C-means con e1071 utilizzando le prime 2 componenti principali
    fcm_result <- cmeans(pca_2comp, centers = k, m = 2, iter.max = 100, verbose = FALSE)
    
    # Converti i risultati fuzzy in assegnazioni dure (cluster con il massimo grado di appartenenza)
    hard_clusters <- apply(fcm_result$membership, 1, which.max)
    
    # Calcola l'indice Calinski-Harabasz
    ch_index <- index.G1(pca_2comp, hard_clusters)
    ch_index_values[k] <- ch_index
    
    # Calcola l'indice Davies-Bouldin
    db_index <- index.DB(pca_2comp, hard_clusters)$DB
    db_index_values[k] <- db_index
}

# Determina e stampa il numero ottimale di cluster secondo il Calinski-Harabasz Index
optimal_ch_clusters <- which.max(ch_index_values)
cat("Numero ottimale di cluster secondo il Calinski-Harabasz Index con Fuzzy C-means sulle prime 2 componenti principali:", optimal_ch_clusters, "\n")

# Determina e stampa il numero ottimale di cluster secondo il Davies-Bouldin Index
optimal_db_clusters <- which.min(db_index_values)
cat("Numero ottimale di cluster secondo il Davies-Bouldin Index con Fuzzy C-means sulle prime 2 componenti principali:", optimal_db_clusters, "\n")

# Grafico dell'indice Calinski-Harabasz per ciascun numero di cluster
plot(2:k_max, ch_index_values[2:k_max], type = "b", main = "Calinski-Harabasz Index con Fuzzy C-means sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Calinski-Harabasz Index")

# Grafico dell'indice Davies-Bouldin per ciascun numero di cluster
plot(2:k_max, db_index_values[2:k_max], type = "b", main = "Davies-Bouldin Index con Fuzzy C-means sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Davies-Bouldin Index")







#kmeans++

# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)  # Per l'algoritmo k-means++
library(fpc)       # Per clusterboot()
library(clusterSim)

# Imposta la directory di lavoro
setwd("D:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come matrice e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# Esegui la PCA su tutti i dati scalati
pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)

# Seleziona le prime 2 componenti principali dalla PCA
pca_2comp <- pca_result$x[, 1:3]  # Seleziona le prime 2 componenti principali

# Definisci il numero massimo di cluster da testare
k_max <- 15

# Inizializza le variabili per memorizzare i valori degli indici Calinski-Harabasz e Davies-Bouldin
ch_index_values <- numeric()
db_index_values <- numeric()

# Ciclo per eseguire K-means++ sulle prime 2 componenti principali e calcolare gli indici CH e DB
for (k in 2:k_max) {
    # Esegui K-means++ con ClusterR utilizzando le prime 2 componenti principali
    kmeans_result <- KMeans_rcpp(pca_2comp, clusters = k, num_init = 15, initializer = 'kmeans++', seed = 123,verbose = TRUE,max_iters = 100)
    
    # Assegna i cluster ottenuti
    hard_clusters <- kmeans_result$clusters
    
    # Calcola l'indice Calinski-Harabasz
    ch_index <- index.G1(pca_2comp, hard_clusters)
    ch_index_values[k] <- ch_index
    
    # Calcola l'indice Davies-Bouldin
    db_index <- index.DB(pca_2comp, hard_clusters)$DB
    db_index_values[k] <- db_index
}

# Determina e stampa il numero ottimale di cluster secondo il Calinski-Harabasz Index
optimal_ch_clusters <- which.max(ch_index_values)
cat("Numero ottimale di cluster secondo il Calinski-Harabasz Index con K-means++ sulle prime 2 componenti principali:", optimal_ch_clusters, "\n")

# Determina e stampa il numero ottimale di cluster secondo il Davies-Bouldin Index
optimal_db_clusters <- which.min(db_index_values)
cat("Numero ottimale di cluster secondo il Davies-Bouldin Index con K-means++ sulle prime 2 componenti principali:", optimal_db_clusters, "\n")

# Grafico dell'indice Calinski-Harabasz per ciascun numero di cluster
plot(2:k_max, ch_index_values[2:k_max], type = "b", main = "Calinski-Harabasz Index con K-means++ sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Calinski-Harabasz Index")

# Grafico dell'indice Davies-Bouldin per ciascun numero di cluster
plot(2:k_max, db_index_values[2:k_max], type = "b", main = "Davies-Bouldin Index con K-means++ sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Davies-Bouldin Index")













#mclust prime 3 componenti PCA
# Carica le librerie necessarie
library(terra)
library(dplyr)
library(mclust)    # Per il clustering con Mclust
library(clusterSim) # Per il calcolo degli indici CH e DB

# Imposta la directory di lavoro
setwd("C:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7) e gli indici (ad esempio NDVI, MNDWI, NDBI)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come matrice e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# Esegui la PCA su tutti i dati scalati
pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)

# Seleziona le prime 2 componenti principali dalla PCA
pca_2comp <- pca_result$x[, 1:2]

# Numero massimo di cluster da testare
k_max <- 15

# Inizializza le variabili per memorizzare i valori degli indici Calinski-Harabasz e Davies-Bouldin
ch_index_values <- numeric()
db_index_values <- numeric()

# Ciclo per eseguire Mclust sulle prime 2 componenti principali e calcolare gli indici CH e DB
for (k in 2:k_max) {
    # Esegui Mclust con il numero di cluster limitato a k
    mclust_result <- Mclust(pca_2comp, G = k)
    
    # Estrai le assegnazioni dure (classificazioni)
    hard_clusters_mclust <- mclust_result$classification
    
    # Calcola l'indice Calinski-Harabasz
    ch_index <- index.G1(pca_2comp, hard_clusters_mclust)
    ch_index_values[k] <- ch_index
    
    # Calcola l'indice Davies-Bouldin
    db_index <- index.DB(pca_2comp, hard_clusters_mclust)$DB
    db_index_values[k] <- db_index
}

# Determina e stampa il numero ottimale di cluster secondo il Calinski-Harabasz Index
optimal_ch_clusters <- which.max(ch_index_values)
cat("Numero ottimale di cluster secondo il Calinski-Harabasz Index con Mclust sulle prime 2 componenti principali:", optimal_ch_clusters, "\n")

# Determina e stampa il numero ottimale di cluster secondo il Davies-Bouldin Index
optimal_db_clusters <- which.min(db_index_values)
cat("Numero ottimale di cluster secondo il Davies-Bouldin Index con Mclust sulle prime 2 componenti principali:", optimal_db_clusters, "\n")

# Grafico dell'indice Calinski-Harabasz per ciascun numero di cluster
plot(2:k_max, ch_index_values[2:k_max], type = "b", main = "Calinski-Harabasz Index con Mclust sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Calinski-Harabasz Index")

# Grafico dell'indice Davies-Bouldin per ciascun numero di cluster
plot(2:k_max, db_index_values[2:k_max], type = "b", main = "Davies-Bouldin Index con Mclust sulle prime 2 componenti",
     xlab = "Numero di Cluster", ylab = "Davies-Bouldin Index")








#SOM
# Carica le librerie necessarie
library(terra)
library(dplyr)
library(xgboost)
library(mapview)
library(viridis)
library(ClusterR)
library(fpc)
library(e1071)
library(clusterSim)
library(kohonen)
library(ggplot2)
library(NbClust)  # Per determinare il numero ottimale di cluster

# Imposta la directory di lavoro
setwd("D:/composite")

# Carica il raster multibanda (stack raster con bande e indici)
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Assegna i nomi specifici agli indici
names(ndvi_1984) <- "NDVI_1984"
names(mndwi_1984) <- "MNDWI_1984"
names(ndbi_1984) <- "NDBI_1984"

# Crea lo stack per il periodo 1984-1990 (bande + indici)
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come matrice e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# Esegui la PCA su tutti i dati scalati
pca_result <- prcomp(values_stack_1984_non_na, scale. = TRUE)

# Seleziona le prime 2 componenti principali dalla PCA
pca_2comp <- pca_result$x[, 1:2]

# Calcola la griglia per la mappa auto-organizzante (SOM)
som_grid <- somgrid(xdim = 5, ydim = 5, topo = "hexagonal")

# Esegui l'algoritmo SOM sulle prime due componenti principali
som_model <- som(scale(pca_2comp), grid = som_grid, rlen = 100)

# Visualizza il codice di attivazione per determinare il numero ottimale di cluster
plot(som_model, type = "codes", main = "Codici dell'SOM")

# Visualizza la distribuzione dei cluster sulla mappa auto-organizzante
plot(som_model, type = "mapping", main = "Distribuzione dei cluster sulla mappa SOM")

# Estrai i codici (centroidi) dall'SOM
codes <- som_model$codes[[1]]

# Calcola il metodo del gomito per trovare il numero ottimale di cluster
wss <- numeric(10)  # Inizializza un vettore per i WSS (Within Sum of Squares)

# Calcola la somma delle varianze entro i gruppi per ogni numero di cluster
for (i in 1:10) {
  som_cluster_temp <- cutree(hclust(dist(codes)), k = i)
  wss[i] <- sum(sapply(1:i, function(k) {
    sum(dist(codes[som_cluster_temp == k, ])^2)
  }))
}

# Funzione per trovare il punto di "ginocchio" nella curva WSS
find_elbow_point <- function(wss) {
  # Differenze tra punti successivi della curva
  diff_wss <- diff(wss)
  # Differenze tra le differenze
  diff2_wss <- diff(diff_wss)
  
  # Trova il punto in cui la seconda differenza è minima (ginocchio)
  elbow_point <- which(diff2_wss == min(diff2_wss)) + 1
  return(elbow_point)
}

# Calcola automaticamente il numero ottimale di cluster
optimal_clusters <- find_elbow_point(wss)
cat("Numero ottimale di cluster:", optimal_clusters, "\n")

# Visualizza il metodo del gomito con il numero ottimale di cluster indicato
plot(1:10, wss, type = "b", xlab = "Numero di cluster", ylab = "Within groups sum of squares", 
     main = "Metodo del gomito per il numero ottimale di cluster")
abline(v = optimal_clusters, col = "red", lwd = 2, lty = 2)

# Esegui il clustering gerarchico sui codici dei neuroni
hc <- hclust(dist(codes))

# Determina il numero ottimale di cluster trovato
som_cluster <- cutree(hc, k = optimal_clusters)

# Aggiungi i risultati del clustering ai dati originali
values_stack_1984_non_na$cluster <- som_cluster[som_model$unit.classif]

# Visualizza i cluster nei primi due componenti della PCA
ggplot(values_stack_1984_non_na, aes(x = pca_2comp[,1], y = pca_2comp[,2], color = as.factor(cluster))) +
  geom_point() +
  labs(color = "Cluster") +
  ggtitle(paste("Cluster individuati sulle prime due componenti della PCA (", optimal_clusters, " cluster)", sep = "")) +
  theme_minimal()
