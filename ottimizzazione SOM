# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", 
                       "leaflet", "ggplot2", "viridis", "mclust", "tclust", 
                       "cluster", "data.table", "progress")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come data.table e rimuovi i valori NA
values_stack_1984 <- as.data.table(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984)]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Definisci i range dei parametri da ottimizzare
alpha_start_values <- seq(0.01, 0.1, length.out = 5)   # Valori per alpha_start
alpha_end_values <- seq(0.001, 0.05, length.out = 5)   # Valori per alpha_end
radius_values <- seq(0.5, 3.0, length.out = 5)         # Valori per radius

# Crea una griglia di combinazioni di parametri
param_grid <- expand.grid(alpha_start = alpha_start_values,
                          alpha_end = alpha_end_values,
                          radius = radius_values)

# Inizializza un data.frame per memorizzare i risultati
results <- data.frame()
library(progress)
pb <- progress_bar$new(total = nrow(param_grid))

# Itera su tutte le combinazioni di parametri
for (i in 1:nrow(param_grid)) {
    alpha_start <- param_grid$alpha_start[i]
    alpha_end <- param_grid$alpha_end[i]
    radius <- param_grid$radius[i]
    
    # Esegui il modello SOM con i parametri attuali
    som_model <- tryCatch({
        supersom(
            list(pca_values), 
            grid = som_grid, 
            rlen = 300,  # Iterazioni fissate a 300
            alpha = c(alpha_start, alpha_end), 
            radius = radius,  # Raggio corrente
            mode = "pbatch", 
            cores = -1  # Usa tutti i core disponibili
        )
    }, error = function(e) {
        NULL
    })
    
    # Se la SOM fallisce, passa alla prossima iterazione
    if (is.null(som_model)) {
        pb$tick()
        next
    }
    
    # Ottieni i codici SOM
    som_values <- som_model$codes[[1]]
    
    # Applica K-means ai codici SOM per creare cluster (ad esempio 5 cluster)
    kmeans_result <- kmeans(som_values, centers = 5, nstart = 10)
    
    # Calcola l'indice di Calinski-Harabasz (CH)
    ch_index <- cluster.stats(dist(som_values), kmeans_result$cluster)$ch
    
    # Salva i risultati
    results <- rbind(results, data.frame(
        alpha_start = alpha_start,
        alpha_end = alpha_end,
        radius = radius,
        ch_index = ch_index
    ))
    
    pb$tick()
}

# Trova la combinazione di parametri che massimizza l'indice CH
best_params <- results[which.max(results$ch_index), ]

cat("Parametri ottimali trovati:\n")
cat("Tasso di apprendimento iniziale:", best_params$alpha_start, "\n")
cat("Tasso di apprendimento finale:", best_params$alpha_end, "\n")
cat("Raggio ottimale:", best_params$radius, "\n")

# SOM senza parametri ottimizzati (utilizzando valori di default)
som_model_default <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(0.05, 0.01),  # Valori di default
    radius = quantile(dist(som_grid$pts), 2/3),  # Raggio di default
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# SOM con i parametri ottimizzati
som_model_optimized <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(best_params$alpha_start, best_params$alpha_end), 
    radius = best_params$radius,  # Raggio ottimizzato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Plot dei cambiamenti per la SOM ottimizzata
plot(som_model_optimized, type = "changes", main = "SOM Ottimizzata - Changes")

# Plot dei cambiamenti per la SOM senza ottimizzazione
plot(som_model_default, type = "changes", main = "SOM Default - Changes")

# Ottieni i codici della SOM ottimizzata
som_values_optimized <- som_model_optimized$codes[[1]]

# Ottieni i codici della SOM senza ottimizzazione
som_values_default <- som_model_default$codes[[1]]

# Esegui tclustIC per trovare il numero ottimale di cluster sulla SOM ottimizzata
tclustIC_result <- tclustIC(
    x = som_values_optimized, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione (MIXMIX, MIXCLA, CLACLA)
    parallel = TRUE,           # Esegui in parallelo
    n.cores = parallel::detectCores(),   # Utilizza tutti i core disponibili
    trace = FALSE              # Non stampare i risultati intermedi
)

# Visualizza i risultati per i criteri
plot(tclustIC_result, which = "MIXMIX")
plot(tclustIC_result, which = "MIXCLA")
plot(tclustIC_result, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix <- min(tclustIC_result$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix <- which(tclustIC_result$MIXMIX == min_value_mixmix)
G_mixmix <- max(tclustIC_result$kk[optimal_indices_mixmix])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla <- min(tclustIC_result$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla <- which(tclustIC_result$MIXCLA == min_value_mixcla)
G_mixcla <- max(tclustIC_result$kk[optimal_indices_mixcla])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla <- min(tclustIC_result$CLACLA, na.rm = TRUE)
optimal_indices_clacla <- which(tclustIC_result$CLACLA == min_value_clacla)
G_clacla <- max(tclustIC_result$kk[optimal_indices_clacla])

# Stampa i risultati ottimali
print(paste("Numero ottimale di cluster secondo MIXMIX:", G_mixmix))
print(paste("Numero ottimale di cluster secondo MIXCLA:", G_mixcla))
print(paste("Numero ottimale di cluster secondo CLACLA:", G_clacla))

# Funzione per eseguire clusterboot e stampare i risultati per ciascun criterio
run_clusterboot <- function(k_value, som_values, label) {
    cat("\nEsecuzione di clusterboot per:", label, "con k =", k_value, "\n")
    result <- clusterboot(
        data = som_values,            # Usa i valori SOM
        B = 150,                      # Numero di campioni bootstrap
        clustermethod = tclustCBI,    # Metodo tclust tramite interfaccia tclustCBI
        bootmethod = "boot",          # Usa bootstrap non parametrico
        dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
        recover = 0.75,               # Valore di recupero per i cluster stabili
        count = FALSE,                # Non mostrare il progresso durante il bootstrap
        k = k_value,                  # Numero di cluster da tclust
        trim = 0                      # Nessun outlier
    )
    
    # Stampa i risultati della stabilità dei cluster
    cat("\nRisultati della stabilità dei cluster per:", label, "\n")
    print(result$bootmean)    # Media della stabilità per ogni cluster
    print(result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
    print(result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
    
    # Visualizzazione della stabilità
    barplot(result$bootmean, 
            main = paste("Stabilità dei Cluster -", label), 
            ylab = "Media della Similarità di Jaccard", 
            xlab = "Cluster", 
            col = "lightblue")
    
    return(result)
}

# Esegui il bootstrap per ciascun valore di cluster sulla SOM ottimizzata
clusterboot_mixmix <- run_clusterboot(G_mixmix, som_values_optimized, "MIXMIX")
clusterboot_mixcla <- run_clusterboot(G_mixcla, som_values_optimized, "MIXCLA")
clusterboot_clacla <- run_clusterboot(G_clacla, som_values_optimized, "CLACLA")

# Esegui la clusterizzazione con Mclust utilizzando G_mixmix sulla SOM ottimizzata
mclust_mixmix <- Mclust(som_values_optimized, G = G_mixmix)
# Esegui la clusterizzazione con Mclust utilizzando G_mixcla sulla SOM ottimizzata
mclust_mixcla <- Mclust(som_values_optimized, G = G_mixcla)
# Esegui la clusterizzazione con Mclust utilizzando G_clacla sulla SOM ottimizzata
mclust_clacla <- Mclust(som_values_optimized, G = G_clacla)

# Crea una maschera per identificare i pixel validi
mask <- !is.na(values(img_84[[1]]))

# Ottieni le unità SOM classificate per ogni punto del dataset
unit_classifications_optimized <- som_model_optimized$unit.classif
unit_classifications_default <- som_model_default$unit.classif

# Crea un raster classificato per ogni risultato sulla SOM ottimizzata

# Raster per MIXMIX
classified_raster_mixmix <- rast(img_84)
values(classified_raster_mixmix) <- NA
values(classified_raster_mixmix)[mask] <- mclust_mixmix$classification[unit_classifications_optimized]

# Raster per MIXCLA
classified_raster_mixcla <- rast(img_84)
values(classified_raster_mixcla) <- NA
values(classified_raster_mixcla)[mask] <- mclust_mixcla$classification[unit_classifications_optimized]

# Raster per CLACLA
classified_raster_clacla <- rast(img_84)
values(classified_raster_clacla) <- NA
values(classified_raster_clacla)[mask] <- mclust_clacla$classification[unit_classifications_optimized]

# Seleziona solo la prima banda per evitare messaggi di avvertimento
classified_raster_mixmix_single <- classified_raster_mixmix[[1]]
classified_raster_mixcla_single <- classified_raster_mixcla[[1]]
classified_raster_clacla_single <- classified_raster_clacla[[1]]

# Visualizzazione con leaflet
palette_turbo <- viridisLite::turbo

leaflet() %>% 
  addTiles(group = "OpenStreetMap") %>% 
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
  addRasterImage(classified_raster_mixmix_single, colors = palette_turbo(G_mixmix), opacity = 0.6, group = "Classificato con MIXMIX - SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_mixcla_single, colors = palette_turbo(G_mixcla), opacity = 0.6, group = "Classificato con MIXCLA - SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_clacla_single, colors = palette_turbo(G_clacla), opacity = 0.6, group = "Classificato con CLACLA - SOM Ottimizzata") %>% 
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("Classificato con MIXMIX - SOM Ottimizzata", "Classificato con MIXCLA - SOM Ottimizzata", "Classificato con CLACLA - SOM Ottimizzata"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>% 
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")

# Se desideri anche visualizzare i risultati della SOM senza parametri ottimizzati, puoi ripetere i passi con 'som_values_default'

# Esempio per la SOM senza parametri ottimizzati:

# Esegui tclustIC per la SOM senza ottimizzazione
tclustIC_result_default <- tclustIC(
    x = som_values_default, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione
    parallel = TRUE,           
    n.cores = parallel::detectCores(),   
    trace = FALSE              
)

# Visualizza i risultati per i criteri
plot(tclustIC_result_default, which = "MIXMIX")
plot(tclustIC_result_default, which = "MIXCLA")
plot(tclustIC_result_default, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix_def <- min(tclustIC_result_default$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix_def <- which(tclustIC_result_default$MIXMIX == min_value_mixmix_def)
G_mixmix_def <- max(tclustIC_result_default$kk[optimal_indices_mixmix_def])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla_def <- min(tclustIC_result_default$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla_def <- which(tclustIC_result_default$MIXCLA == min_value_mixcla_def)
G_mixcla_def <- max(tclustIC_result_default$kk[optimal_indices_mixcla_def])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla_def <- min(tclustIC_result_default$CLACLA, na.rm = TRUE)
optimal_indices_clacla_def <- which(tclustIC_result_default$CLACLA == min_value_clacla_def)
G_clacla_def <- max(tclustIC_result_default$kk[optimal_indices_clacla_def])

# Stampa i risultati ottimali per la SOM senza ottimizzazione
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXMIX:", G_mixmix_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXCLA:", G_mixcla_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo CLACLA:", G_clacla_def))

cat("Analisi completata con successo.\n")







#2


# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", 
                       "leaflet", "ggplot2", "viridis", "data.table", "progress")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come data.table e rimuovi i valori NA
values_stack_1984 <- as.data.table(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984)]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Definisci i range dei parametri da ottimizzare
alpha_start_values <- seq(0.01, 0.1, length.out = 5)   # Valori per alpha_start
alpha_end_values <- seq(0.001, 0.05, length.out = 5)   # Valori per alpha_end
radius_values <- seq(0.5, 3.0, length.out = 5)         # Valori per radius

# Crea una griglia di combinazioni di parametri
param_grid <- expand.grid(alpha_start = alpha_start_values,
                          alpha_end = alpha_end_values,
                          radius = radius_values)

# Inizializza un data.frame per memorizzare i risultati
results <- data.frame()
library(progress)
pb <- progress_bar$new(total = nrow(param_grid))

# Itera su tutte le combinazioni di parametri
for (i in 1:nrow(param_grid)) {
    alpha_start <- param_grid$alpha_start[i]
    alpha_end <- param_grid$alpha_end[i]
    radius <- param_grid$radius[i]
    
    # Esegui il modello SOM con i parametri attuali
    som_model <- tryCatch({
        supersom(
            list(pca_values), 
            grid = som_grid, 
            rlen = 300,  # Iterazioni fissate a 300
            alpha = c(alpha_start, alpha_end), 
            radius = radius,  # Raggio corrente
            mode = "pbatch", 
            cores = -1  # Usa tutti i core disponibili
        )
    }, error = function(e) {
        NULL
    })
    
    # Se la SOM fallisce, passa alla prossima iterazione
    if (is.null(som_model)) {
        pb$tick()
        next
    }
    
    # Ottieni i codici SOM
    som_values <- som_model$codes[[1]]
    
    # Applica K-means ai codici SOM per creare cluster (ad esempio 5 cluster)
    kmeans_result <- kmeans(som_values, centers = 5, nstart = 10)
    
    # Calcola l'indice di Calinski-Harabasz (CH)
    ch_index <- cluster.stats(dist(som_values), kmeans_result$cluster)$ch
    
    # Salva i risultati
    results <- rbind(results, data.frame(
        alpha_start = alpha_start,
        alpha_end = alpha_end,
        radius = radius,
        ch_index = ch_index
    ))
    
    pb$tick()
}

# Trova la combinazione di parametri che massimizza l'indice CH
best_params <- results[which.max(results$ch_index), ]

cat("Parametri ottimali trovati:\n")
cat("Tasso di apprendimento iniziale:", best_params$alpha_start, "\n")
cat("Tasso di apprendimento finale:", best_params$alpha_end, "\n")
cat("Raggio ottimale:", best_params$radius, "\n")

# SOM senza parametri ottimizzati (utilizzando valori di default)
som_model_default <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(0.05, 0.01),  # Valori di default
    radius = quantile(dist(som_grid$pts), 2/3),  # Raggio di default
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# SOM con i parametri ottimizzati
som_model_optimized <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(best_params$alpha_start, best_params$alpha_end), 
    radius = best_params$radius,  # Raggio ottimizzato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Plot dei cambiamenti per la SOM ottimizzata
plot(som_model_optimized, type = "changes", main = "SOM Ottimizzata - Changes")

# Plot dei cambiamenti per la SOM senza ottimizzazione
plot(som_model_default, type = "changes", main = "SOM Default - Changes")

# Ottieni i codici della SOM ottimizzata
som_values_optimized <- som_model_optimized$codes[[1]]

# Ottieni i codici della SOM senza ottimizzazione
som_values_default <- som_model_default$codes[[1]]

# Determina il numero ottimale di cluster con NbClust sulla SOM ottimizzata
library(NbClust)
set.seed(123)  # Per riproducibilità
nbclust_result_opt <- NbClust(
    data = som_values_optimized, 
    diss = NULL, 
    distance = "euclidean",  
    min.nc = 2,              
    max.nc = 10,             
    method = "kmeans",       
    index = "all"            
)

# Trova il numero ottimale di cluster dalla moda dei risultati
cluster_counts <- table(nbclust_result_opt$Best.nc[1, ])
max_votes <- max(cluster_counts)
modes <- as.numeric(names(cluster_counts[cluster_counts == max_votes]))
optimal_clusters_opt <- max(modes) # Seleziona il numero maggiore in caso di pareggio
cat("SOM Ottimizzata - Il numero ottimale di cluster secondo NbClust è:", optimal_clusters_opt, "\n")

# Determina il numero ottimale di cluster con NbClust sulla SOM senza ottimizzazione
nbclust_result_def <- NbClust(
    data = som_values_default, 
    diss = NULL, 
    distance = "euclidean",  
    min.nc = 2,              
    max.nc = 10,             
    method = "kmeans",       
    index = "all"            
)

# Trova il numero ottimale di cluster dalla moda dei risultati
cluster_counts_def <- table(nbclust_result_def$Best.nc[1, ])
max_votes_def <- max(cluster_counts_def)
modes_def <- as.numeric(names(cluster_counts_def[cluster_counts_def == max_votes_def]))
optimal_clusters_def <- max(modes_def) # Seleziona il numero maggiore in caso di pareggio
cat("SOM Senza Ottimizzazione - Il numero ottimale di cluster secondo NbClust è:", optimal_clusters_def, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI sulla SOM ottimizzata
library(fpc)
clusterboot_result_opt <- clusterboot(
    data = som_values_optimized,            
    B = 150,                      
    clustermethod = kmeansCBI,    
    bootmethod = "boot",          
    dissolution = 0.5,            
    recover = 0.75,               
    count = FALSE,                
    k = optimal_clusters_opt      
)

# Stampa i risultati della stabilità dei cluster sulla SOM ottimizzata
cat("SOM Ottimizzata - Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result_opt$bootmean)    
print(clusterboot_result_opt$bootrecover) 
print(clusterboot_result_opt$bootbrd)     

# Visualizzazione della stabilità per la SOM ottimizzata
barplot(clusterboot_result_opt$bootmean, 
        main = "SOM Ottimizzata - Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Ripeti lo stesso per la SOM senza ottimizzazione
clusterboot_result_def <- clusterboot(
    data = som_values_default,            
    B = 150,                      
    clustermethod = kmeansCBI,    
    bootmethod = "boot",          
    dissolution = 0.5,            
    recover = 0.75,               
    count = FALSE,                
    k = optimal_clusters_def      
)

# Stampa i risultati della stabilità dei cluster sulla SOM senza ottimizzazione
cat("SOM Senza Ottimizzazione - Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result_def$bootmean)    
print(clusterboot_result_def$bootrecover) 
print(clusterboot_result_def$bootbrd)     

# Visualizzazione della stabilità per la SOM senza ottimizzazione
barplot(clusterboot_result_def$bootmean, 
        main = "SOM Senza Ottimizzazione - Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero ottimale di cluster sulla SOM ottimizzata
set.seed(42)
kmeans_opt <- kmeans(som_values_optimized, centers = optimal_clusters_opt, nstart = 100, iter.max = 1000)

# Esegui K-means con il numero ottimale di cluster sulla SOM senza ottimizzazione
kmeans_def <- kmeans(som_values_default, centers = optimal_clusters_def, nstart = 100, iter.max = 1000)

# Crea una maschera per identificare i pixel validi
mask <- !is.na(values(img_84[[1]]))

# Ottieni le unità SOM classificate per ogni punto del dataset
unit_classifications_optimized <- som_model_optimized$unit.classif
unit_classifications_default <- som_model_default$unit.classif

# Crea un raster classificato per la SOM ottimizzata
classified_raster_opt <- rast(img_84)
values(classified_raster_opt) <- NA
values(classified_raster_opt)[mask] <- kmeans_opt$cluster[unit_classifications_optimized]

# Crea un raster classificato per la SOM senza ottimizzazione
classified_raster_def <- rast(img_84)
values(classified_raster_def) <- NA
values(classified_raster_def)[mask] <- kmeans_def$cluster[unit_classifications_default]

# Seleziona solo la prima banda per evitare messaggi di avvertimento
classified_raster_opt_single <- classified_raster_opt[[1]]
classified_raster_def_single <- classified_raster_def[[1]]

# Visualizzazione con leaflet
palette_turbo <- viridisLite::turbo

leaflet() %>% 
  addTiles(group = "OpenStreetMap") %>% 
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
  addRasterImage(classified_raster_opt_single, colors = palette_turbo(optimal_clusters_opt), opacity = 0.6, group = "SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_def_single, colors = palette_turbo(optimal_clusters_def), opacity = 0.6, group = "SOM Senza Ottimizzazione") %>% 
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("SOM Ottimizzata", "SOM Senza Ottimizzazione"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>% 
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")




#TESTATI 10 VALORI DI RAGGIO TUTTO IL RANG, NO CAMPIONATURA 


# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", 
                       "leaflet", "ggplot2", "viridis", "mclust", "tclust", 
                       "cluster", "data.table", "progress")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come data.table e rimuovi i valori NA
values_stack_1984 <- as.data.table(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984)]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Calcola tutte le distanze tra le unità
unit_distances <- dist(som_grid$pts)

# Calcola il valore predefinito di radius
default_radius <- quantile(unit_distances, 2/3)
cat("Valore predefinito di radius (2/3 quantile delle distanze unità-unità):", default_radius, "\n")

# Ottieni un riassunto delle distanze
distance_summary <- summary(unit_distances)
print("Riassunto delle distanze unità-unità:")
print(distance_summary)

# Definisci i valori di radius da testare basandoti sulle distanze
radius_values <- seq(distance_summary["Min."], distance_summary["Max."], length.out = 10)
print("Valori di radius da testare:")
print(radius_values)

# Definisci i range dei parametri da ottimizzare
alpha_start_values <- seq(0.01, 0.3, length.out = 10)   # Valori per alpha_start
alpha_end_values <- seq(0.001, 0.1, length.out = 10)    # Valori per alpha_end

# Crea una griglia di combinazioni di parametri
param_grid <- expand.grid(alpha_start = alpha_start_values,
                          alpha_end = alpha_end_values,
                          radius = radius_values)

# Inizializza un data.frame per memorizzare i risultati
results <- data.frame()
library(progress)
pb <- progress_bar$new(total = nrow(param_grid))

# Itera su tutte le combinazioni di parametri
for (i in 1:nrow(param_grid)) {
    alpha_start <- param_grid$alpha_start[i]
    alpha_end <- param_grid$alpha_end[i]
    radius <- param_grid$radius[i]
    
    # Esegui il modello SOM con i parametri attuali
    som_model <- tryCatch({
        supersom(
            list(pca_values), 
            grid = som_grid, 
            rlen = 300,  # Iterazioni fissate a 300
            alpha = c(alpha_start, alpha_end), 
            radius = radius,  # Raggio corrente
            mode = "pbatch", 
            cores = -1  # Usa tutti i core disponibili
        )
    }, error = function(e) {
        NULL
    })
    
    # Se la SOM fallisce, passa alla prossima iterazione
    if (is.null(som_model)) {
        pb$tick()
        next
    }
    
    # Ottieni i codici SOM
    som_values <- som_model$codes[[1]]
    
    # Applica K-means ai codici SOM per creare cluster (ad esempio 5 cluster)
    kmeans_result <- kmeans(som_values, centers = 5, nstart = 10)
    
    # Calcola l'indice di Calinski-Harabasz (CH)
    ch_index <- cluster.stats(dist(som_values), kmeans_result$cluster)$ch
    
    # Salva i risultati
    results <- rbind(results, data.frame(
        alpha_start = alpha_start,
        alpha_end = alpha_end,
        radius = radius,
        ch_index = ch_index
    ))
    
    pb$tick()
}

# Trova la combinazione di parametri che massimizza l'indice CH
best_params <- results[which.max(results$ch_index), ]

cat("Parametri ottimali trovati:\n")
cat("Tasso di apprendimento iniziale:", best_params$alpha_start, "\n")
cat("Tasso di apprendimento finale:", best_params$alpha_end, "\n")
cat("Raggio ottimale:", best_params$radius, "\n")

# SOM senza parametri ottimizzati (utilizzando valori di default)
som_model_default <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(0.05, 0.01),  # Valori di default
    radius = default_radius,  # Raggio di default calcolato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# SOM con i parametri ottimizzati
som_model_optimized <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(best_params$alpha_start, best_params$alpha_end), 
    radius = best_params$radius,  # Raggio ottimizzato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Plot dei cambiamenti per la SOM ottimizzata
plot(som_model_optimized, type = "changes", main = "SOM Ottimizzata - Changes")

# Plot dei cambiamenti per la SOM senza ottimizzazione
plot(som_model_default, type = "changes", main = "SOM Default - Changes")

# Ottieni i codici della SOM ottimizzata
som_values_optimized <- som_model_optimized$codes[[1]]

# Ottieni i codici della SOM senza ottimizzazione
som_values_default <- som_model_default$codes[[1]]

# Esegui tclustIC per trovare il numero ottimale di cluster sulla SOM ottimizzata
tclustIC_result <- tclustIC(
    x = som_values_optimized, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione (MIXMIX, MIXCLA, CLACLA)
    parallel = TRUE,           # Esegui in parallelo
    n.cores = parallel::detectCores(),   # Utilizza tutti i core disponibili
    trace = FALSE              # Non stampare i risultati intermedi
)

# Visualizza i risultati per i criteri
plot(tclustIC_result, which = "MIXMIX")
plot(tclustIC_result, which = "MIXCLA")
plot(tclustIC_result, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix <- min(tclustIC_result$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix <- which(tclustIC_result$MIXMIX == min_value_mixmix)
G_mixmix <- max(tclustIC_result$kk[optimal_indices_mixmix])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla <- min(tclustIC_result$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla <- which(tclustIC_result$MIXCLA == min_value_mixcla)
G_mixcla <- max(tclustIC_result$kk[optimal_indices_mixcla])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla <- min(tclustIC_result$CLACLA, na.rm = TRUE)
optimal_indices_clacla <- which(tclustIC_result$CLACLA == min_value_clacla)
G_clacla <- max(tclustIC_result$kk[optimal_indices_clacla])

# Stampa i risultati ottimali
print(paste("Numero ottimale di cluster secondo MIXMIX:", G_mixmix))
print(paste("Numero ottimale di cluster secondo MIXCLA:", G_mixcla))
print(paste("Numero ottimale di cluster secondo CLACLA:", G_clacla))

# Funzione per eseguire clusterboot e stampare i risultati per ciascun criterio
run_clusterboot <- function(k_value, som_values, label) {
    cat("\nEsecuzione di clusterboot per:", label, "con k =", k_value, "\n")
    result <- clusterboot(
        data = som_values,            # Usa i valori SOM
        B = 150,                      # Numero di campioni bootstrap
        clustermethod = tclustCBI,    # Metodo tclust tramite interfaccia tclustCBI
        bootmethod = "boot",          # Usa bootstrap non parametrico
        dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
        recover = 0.75,               # Valore di recupero per i cluster stabili
        count = FALSE,                # Non mostrare il progresso durante il bootstrap
        k = k_value,                  # Numero di cluster da tclust
        trim = 0                      # Nessun outlier
    )
    
    # Stampa i risultati della stabilità dei cluster
    cat("\nRisultati della stabilità dei cluster per:", label, "\n")
    print(result$bootmean)    # Media della stabilità per ogni cluster
    print(result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
    print(result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
    
    # Visualizzazione della stabilità
    barplot(result$bootmean, 
            main = paste("Stabilità dei Cluster -", label), 
            ylab = "Media della Similarità di Jaccard", 
            xlab = "Cluster", 
            col = "lightblue")
    
    return(result)
}

# Esegui il bootstrap per ciascun valore di cluster sulla SOM ottimizzata
clusterboot_mixmix <- run_clusterboot(G_mixmix, som_values_optimized, "MIXMIX")
clusterboot_mixcla <- run_clusterboot(G_mixcla, som_values_optimized, "MIXCLA")
clusterboot_clacla <- run_clusterboot(G_clacla, som_values_optimized, "CLACLA")

# Esegui la clusterizzazione con Mclust utilizzando G_mixmix sulla SOM ottimizzata
mclust_mixmix <- Mclust(som_values_optimized, G = G_mixmix)
# Esegui la clusterizzazione con Mclust utilizzando G_mixcla sulla SOM ottimizzata
mclust_mixcla <- Mclust(som_values_optimized, G = G_mixcla)
# Esegui la clusterizzazione con Mclust utilizzando G_clacla sulla SOM ottimizzata
mclust_clacla <- Mclust(som_values_optimized, G = G_clacla)

# Crea una maschera per identificare i pixel validi
mask <- !is.na(values(img_84[[1]]))

# Ottieni le unità SOM classificate per ogni punto del dataset
unit_classifications_optimized <- som_model_optimized$unit.classif
unit_classifications_default <- som_model_default$unit.classif

# Crea un raster classificato per ogni risultato sulla SOM ottimizzata

# Raster per MIXMIX
classified_raster_mixmix <- rast(img_84)
values(classified_raster_mixmix) <- NA
values(classified_raster_mixmix)[mask] <- mclust_mixmix$classification[unit_classifications_optimized]

# Raster per MIXCLA
classified_raster_mixcla <- rast(img_84)
values(classified_raster_mixcla) <- NA
values(classified_raster_mixcla)[mask] <- mclust_mixcla$classification[unit_classifications_optimized]

# Raster per CLACLA
classified_raster_clacla <- rast(img_84)
values(classified_raster_clacla) <- NA
values(classified_raster_clacla)[mask] <- mclust_clacla$classification[unit_classifications_optimized]

# Seleziona solo la prima banda per evitare messaggi di avvertimento
classified_raster_mixmix_single <- classified_raster_mixmix[[1]]
classified_raster_mixcla_single <- classified_raster_mixcla[[1]]
classified_raster_clacla_single <- classified_raster_clacla[[1]]

# Visualizzazione con leaflet
palette_turbo <- viridisLite::turbo

leaflet() %>% 
  addTiles(group = "OpenStreetMap") %>% 
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
  addRasterImage(classified_raster_mixmix_single, colors = palette_turbo(G_mixmix), opacity = 0.6, group = "Classificato con MIXMIX - SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_mixcla_single, colors = palette_turbo(G_mixcla), opacity = 0.6, group = "Classificato con MIXCLA - SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_clacla_single, colors = palette_turbo(G_clacla), opacity = 0.6, group = "Classificato con CLACLA - SOM Ottimizzata") %>% 
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("Classificato con MIXMIX - SOM Ottimizzata", "Classificato con MIXCLA - SOM Ottimizzata", "Classificato con CLACLA - SOM Ottimizzata"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>% 
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")

# Se desideri anche visualizzare i risultati della SOM senza parametri ottimizzati, puoi ripetere i passi con 'som_values_default'

# Esempio per la SOM senza parametri ottimizzati:

# Esegui tclustIC per la SOM senza ottimizzazione
tclustIC_result_default <- tclustIC(
    x = som_values_default, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione
    parallel = TRUE,           
    n.cores = parallel::detectCores(),   
    trace = FALSE              
)

# Visualizza i risultati per i criteri
plot(tclustIC_result_default, which = "MIXMIX")
plot(tclustIC_result_default, which = "MIXCLA")
plot(tclustIC_result_default, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix_def <- min(tclustIC_result_default$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix_def <- which(tclustIC_result_default$MIXMIX == min_value_mixmix_def)
G_mixmix_def <- max(tclustIC_result_default$kk[optimal_indices_mixmix_def])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla_def <- min(tclustIC_result_default$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla_def <- which(tclustIC_result_default$MIXCLA == min_value_mixcla_def)
G_mixcla_def <- max(tclustIC_result_default$kk[optimal_indices_mixcla_def])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla_def <- min(tclustIC_result_default$CLACLA, na.rm = TRUE)
optimal_indices_clacla_def <- which(tclustIC_result_default$CLACLA == min_value_clacla_def)
G_clacla_def <- max(tclustIC_result_default$kk[optimal_indices_clacla_def])

# Stampa i risultati ottimali per la SOM senza ottimizzazione
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXMIX:", G_mixmix_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXCLA:", G_mixcla_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo CLACLA:", G_clacla_def))

cat("Analisi completata con successo.\n")



#TESTATI 10 VOLORI DI RAGGIO NON CAMPIONATI NBCLUST

# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", 
                       "leaflet", "ggplot2", "viridis", "data.table", "progress")
check_and_install(required_packages)

# Imposta la working directory
setwd("D:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come data.table e rimuovi i valori NA
values_stack_1984 <- as.data.table(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984)]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona le prime tre componenti

# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni:", n))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni:", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Calcola tutte le distanze tra le unità
unit_distances <- dist(som_grid$pts)

# Calcola il valore predefinito di radius
default_radius <- quantile(unit_distances, 2/3)
cat("Valore predefinito di radius (2/3 quantile delle distanze unità-unità):", default_radius, "\n")

# Ottieni un riassunto delle distanze
distance_summary <- summary(unit_distances)
print("Riassunto delle distanze unità-unità:")
print(distance_summary)

# Definisci i valori di radius da testare basandoti sulle distanze
radius_values <- seq(distance_summary["Min."], distance_summary["Max."], length.out = 10)
print("Valori di radius da testare:")
print(radius_values)

# Definisci i range dei parametri da ottimizzare
alpha_start_values <- seq(0.01, 0.3, length.out = 10)   # Valori per alpha_start
alpha_end_values <- seq(0.001, 0.1, length.out = 10)    # Valori per alpha_end

# Crea una griglia di combinazioni di parametri
param_grid <- expand.grid(alpha_start = alpha_start_values,
                          alpha_end = alpha_end_values,
                          radius = radius_values)

# Inizializza un data.frame per memorizzare i risultati
results <- data.frame()
library(progress)
pb <- progress_bar$new(total = nrow(param_grid))

# Itera su tutte le combinazioni di parametri
for (i in 1:nrow(param_grid)) {
    alpha_start <- param_grid$alpha_start[i]
    alpha_end <- param_grid$alpha_end[i]
    radius <- param_grid$radius[i]
    
    # Esegui il modello SOM con i parametri attuali
    som_model <- tryCatch({
        supersom(
            list(pca_values), 
            grid = som_grid, 
            rlen = 300,  # Iterazioni fissate a 300
            alpha = c(alpha_start, alpha_end), 
            radius = radius,  # Raggio corrente
            mode = "pbatch", 
            cores = -1  # Usa tutti i core disponibili
        )
    }, error = function(e) {
        NULL
    })
    
    # Se la SOM fallisce, passa alla prossima iterazione
    if (is.null(som_model)) {
        pb$tick()
        next
    }
    
    # Ottieni i codici SOM
    som_values <- som_model$codes[[1]]
    
    # Applica K-means ai codici SOM per creare cluster (ad esempio 5 cluster)
    kmeans_result <- kmeans(som_values, centers = 5, nstart = 10)
    
    # Calcola l'indice di Calinski-Harabasz (CH)
    ch_index <- cluster.stats(dist(som_values), kmeans_result$cluster)$ch
    
    # Salva i risultati
    results <- rbind(results, data.frame(
        alpha_start = alpha_start,
        alpha_end = alpha_end,
        radius = radius,
        ch_index = ch_index
    ))
    
    pb$tick()
}

# Trova la combinazione di parametri che massimizza l'indice CH
best_params <- results[which.max(results$ch_index), ]

cat("Parametri ottimali trovati:\n")
cat("Tasso di apprendimento iniziale:", best_params$alpha_start, "\n")
cat("Tasso di apprendimento finale:", best_params$alpha_end, "\n")
cat("Raggio ottimale:", best_params$radius, "\n")

# SOM senza parametri ottimizzati (utilizzando valori di default)
som_model_default <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(0.05, 0.01),  # Valori di default
    radius = default_radius,  # Raggio di default calcolato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# SOM con i parametri ottimizzati
som_model_optimized <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(best_params$alpha_start, best_params$alpha_end), 
    radius = best_params$radius,  # Raggio ottimizzato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Plot dei cambiamenti per la SOM ottimizzata
plot(som_model_optimized, type = "changes", main = "SOM Ottimizzata - Changes")

# Plot dei cambiamenti per la SOM senza ottimizzazione
plot(som_model_default, type = "changes", main = "SOM Default - Changes")

# Ottieni i codici della SOM ottimizzata
som_values_optimized <- som_model_optimized$codes[[1]]

# Ottieni i codici della SOM senza ottimizzazione
som_values_default <- som_model_default$codes[[1]]

# Determina il numero ottimale di cluster con NbClust sulla SOM ottimizzata
library(NbClust)
set.seed(123)  # Per riproducibilità
nbclust_result_opt <- NbClust(
    data = som_values_optimized, 
    diss = NULL, 
    distance = "euclidean",  
    min.nc = 2,              
    max.nc = 10,             
    method = "kmeans",       
    index = "all"            
)

# Trova il numero ottimale di cluster dalla moda dei risultati
cluster_counts <- table(nbclust_result_opt$Best.nc[1, ])
max_votes <- max(cluster_counts)
modes <- as.numeric(names(cluster_counts[cluster_counts == max_votes]))
optimal_clusters_opt <- max(modes) # Seleziona il numero maggiore in caso di pareggio
cat("SOM Ottimizzata - Il numero ottimale di cluster secondo NbClust è:", optimal_clusters_opt, "\n")

# Determina il numero ottimale di cluster con NbClust sulla SOM senza ottimizzazione
nbclust_result_def <- NbClust(
    data = som_values_default, 
    diss = NULL, 
    distance = "euclidean",  
    min.nc = 2,              
    max.nc = 10,             
    method = "kmeans",       
    index = "all"            
)

# Trova il numero ottimale di cluster dalla moda dei risultati
cluster_counts_def <- table(nbclust_result_def$Best.nc[1, ])
max_votes_def <- max(cluster_counts_def)
modes_def <- as.numeric(names(cluster_counts_def[cluster_counts_def == max_votes_def]))
optimal_clusters_def <- max(modes_def) # Seleziona il numero maggiore in caso di pareggio
cat("SOM Senza Ottimizzazione - Il numero ottimale di cluster secondo NbClust è:", optimal_clusters_def, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI sulla SOM ottimizzata
library(fpc)
clusterboot_result_opt <- clusterboot(
    data = som_values_optimized,            
    B = 150,                      
    clustermethod = kmeansCBI,    
    bootmethod = "boot",          
    dissolution = 0.5,            
    recover = 0.75,               
    count = FALSE,                
    k = optimal_clusters_opt      
)

# Stampa i risultati della stabilità dei cluster sulla SOM ottimizzata
cat("SOM Ottimizzata - Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result_opt$bootmean)    
print(clusterboot_result_opt$bootrecover) 
print(clusterboot_result_opt$bootbrd)     

# Visualizzazione della stabilità per la SOM ottimizzata
barplot(clusterboot_result_opt$bootmean, 
        main = "SOM Ottimizzata - Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Ripeti lo stesso per la SOM senza ottimizzazione
clusterboot_result_def <- clusterboot(
    data = som_values_default,            
    B = 150,                      
    clustermethod = kmeansCBI,    
    bootmethod = "boot",          
    dissolution = 0.5,            
    recover = 0.75,               
    count = FALSE,                
    k = optimal_clusters_def      
)

# Stampa i risultati della stabilità dei cluster sulla SOM senza ottimizzazione
cat("SOM Senza Ottimizzazione - Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result_def$bootmean)    
print(clusterboot_result_def$bootrecover) 
print(clusterboot_result_def$bootbrd)     

# Visualizzazione della stabilità per la SOM senza ottimizzazione
barplot(clusterboot_result_def$bootmean, 
        main = "SOM Senza Ottimizzazione - Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero ottimale di cluster sulla SOM ottimizzata
set.seed(42)
kmeans_opt <- kmeans(som_values_optimized, centers = optimal_clusters_opt, nstart = 100, iter.max = 1000)

# Esegui K-means con il numero ottimale di cluster sulla SOM senza ottimizzazione
kmeans_def <- kmeans(som_values_default, centers = optimal_clusters_def, nstart = 100, iter.max = 1000)

# Crea una maschera per identificare i pixel validi
mask <- !is.na(values(img_84[[1]]))

# Ottieni le unità SOM classificate per ogni punto del dataset
unit_classifications_optimized <- som_model_optimized$unit.classif
unit_classifications_default <- som_model_default$unit.classif

# Crea un raster classificato per la SOM ottimizzata
classified_raster_opt <- rast(img_84)
values(classified_raster_opt) <- NA
values(classified_raster_opt)[mask] <- kmeans_opt$cluster[unit_classifications_optimized]

# Crea un raster classificato per la SOM senza ottimizzazione
classified_raster_def <- rast(img_84)
values(classified_raster_def) <- NA
values(classified_raster_def)[mask] <- kmeans_def$cluster[unit_classifications_default]

# Seleziona solo la prima banda per evitare messaggi di avvertimento
classified_raster_opt_single <- classified_raster_opt[[1]]
classified_raster_def_single <- classified_raster_def[[1]]

# Visualizzazione con leaflet
palette_turbo <- viridisLite::turbo

leaflet() %>% 
  addTiles(group = "OpenStreetMap") %>% 
  addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
  addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
  addRasterImage(classified_raster_opt_single, colors = palette_turbo(optimal_clusters_opt), opacity = 0.6, group = "SOM Ottimizzata") %>% 
  addRasterImage(classified_raster_def_single, colors = palette_turbo(optimal_clusters_def), opacity = 0.6, group = "SOM Senza Ottimizzazione") %>% 
  addLayersControl(
    baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
    overlayGroups = c("SOM Ottimizzata", "SOM Senza Ottimizzazione"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>% 
  addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
  setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")










#6 parametri e campionamento

# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", 
                       "leaflet", "ggplot2", "viridis", "mclust", "tclust", 
                       "cluster", "data.table", "progress")
check_and_install(required_packages)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]

# Calcola gli indici NDVI, MNDWI e NDBI
ndvi_1984 <- (l1984[[4]] - l1984[[3]]) / (l1984[[4]] + l1984[[3]])
mndwi_1984 <- (l1984[[2]] - l1984[[5]]) / (l1984[[2]] + l1984[[5]])
ndbi_1984 <- (l1984[[5]] - l1984[[4]]) / (l1984[[5]] + l1984[[4]])

# Crea lo stack con bande e indici
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984)

# Estrai i valori dal raster stack come data.table e rimuovi i valori NA
values_stack_1984 <- as.data.table(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984)]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# **Aggiunta del Campionamento in Percentuale**
# Conta il numero di osservazioni valide
n <- nrow(pca_values)
print(paste("Numero di osservazioni:", n))

# Specifica la percentuale di campionamento (ad esempio, 10% del dataset)
sample_percentage <- 0.50  # Modifica questo valore per cambiare la percentuale

# Calcola la dimensione del campione
sample_size <- round(n * sample_percentage)
print(paste("Dimensione del campione (", sample_percentage * 100, "%): ", sample_size, sep=""))

# Campiona una sottoparte dei dati per l'ottimizzazione
set.seed(123)
if (n > sample_size) {
    sampled_indices <- sample(1:n, sample_size)
    sampled_pca_values <- pca_values[sampled_indices, ]
} else {
    sampled_pca_values <- pca_values
}
n_sampled <- nrow(sampled_pca_values)
print(paste("Numero di osservazioni nel campione:", n_sampled))

# Calcola il numero totale di neuroni suggerito dalla formula
neurons <- 5 * sqrt(n_sampled)
print(paste("Numero suggerito di neuroni (campione):", round(neurons)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(neurons))
y_dim <- round(neurons / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Calcola tutte le distanze tra le unità
unit_distances <- dist(som_grid$pts)

# Calcola il valore predefinito di radius
default_radius <- quantile(unit_distances, 2/3)
cat("Valore predefinito di radius (2/3 quantile delle distanze unità-unità):", default_radius, "\n")

# Ottieni un riassunto delle distanze
distance_summary <- summary(unit_distances)
print("Riassunto delle distanze unità-unità:")
print(distance_summary)

# Definisci i valori di radius da testare basandoti sulle distanze
radius_values <- seq(distance_summary["Min."], distance_summary["Max."], length.out = 6)
print("Valori di radius da testare:")
print(radius_values)

# Definisci i range dei parametri da ottimizzare
alpha_start_values <- seq(0.01, 0.3, length.out = 6)   # Valori per alpha_start
alpha_end_values <- seq(0.001, 0.1, length.out = 6)    # Valori per alpha_end

# Crea una griglia di combinazioni di parametri
param_grid <- expand.grid(alpha_start = alpha_start_values,
                          alpha_end = alpha_end_values,
                          radius = radius_values)

# Inizializza un data.frame per memorizzare i risultati
results <- data.frame()
library(progress)
pb <- progress_bar$new(total = nrow(param_grid))

# **Usa il campione per l'ottimizzazione**
# Itera su tutte le combinazioni di parametri
for (i in 1:nrow(param_grid)) {
    alpha_start <- param_grid$alpha_start[i]
    alpha_end <- param_grid$alpha_end[i]
    radius <- param_grid$radius[i]
    
    # Esegui il modello SOM con i parametri attuali sul campione
    som_model <- tryCatch({
        supersom(
            list(sampled_pca_values), 
            grid = som_grid, 
            rlen = 300,  # Iterazioni fissate a 300
            alpha = c(alpha_start, alpha_end), 
            radius = radius,  # Raggio corrente
            mode = "pbatch", 
            cores = -1  # Usa tutti i core disponibili
        )
    }, error = function(e) {
        NULL
    })
    
    # Se la SOM fallisce, passa alla prossima iterazione
    if (is.null(som_model)) {
        pb$tick()
        next
    }
    
    # Ottieni i codici SOM
    som_values <- som_model$codes[[1]]
    
    # Applica K-means ai codici SOM per creare cluster (ad esempio 5 cluster)
    kmeans_result <- kmeans(som_values, centers = 5, nstart = 10)
    
    # Calcola l'indice di Calinski-Harabasz (CH)
    ch_index <- cluster.stats(dist(som_values), kmeans_result$cluster)$ch
    
    # Salva i risultati
    results <- rbind(results, data.frame(
        alpha_start = alpha_start,
        alpha_end = alpha_end,
        radius = radius,
        ch_index = ch_index
    ))
    
    pb$tick()
}

# Trova la combinazione di parametri che massimizza l'indice CH
best_params <- results[which.max(results$ch_index), ]

cat("Parametri ottimali trovati:\n")
cat("Tasso di apprendimento iniziale:", best_params$alpha_start, "\n")
cat("Tasso di apprendimento finale:", best_params$alpha_end, "\n")
cat("Raggio ottimale:", best_params$radius, "\n")

# **Reimposta la griglia SOM per l'intero dataset**
# Calcola il numero totale di neuroni per l'intero dataset
neurons_full <- 5 * sqrt(n)
print(paste("Numero suggerito di neuroni (intero dataset):", round(neurons_full)))

# Suggerisci una configurazione di griglia approssimata
x_dim_full <- round(sqrt(neurons_full))
y_dim_full <- round(neurons_full / x_dim_full)
print(paste("Dimensioni della griglia per l'intero dataset:", x_dim_full, "x", y_dim_full))

# Definisci una nuova griglia SOM con le dimensioni calcolate
som_grid_full <- somgrid(xdim = x_dim_full, ydim = y_dim_full, topo = "hexagonal")

# **Ricalcola il default_radius per la nuova griglia**
unit_distances_full <- dist(som_grid_full$pts)
default_radius_full <- quantile(unit_distances_full, 2/3)

# SOM senza parametri ottimizzati (utilizzando valori di default) sull'intero dataset
som_model_default <- supersom(
    list(pca_values), 
    grid = som_grid_full, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(0.05, 0.01),  # Valori di default
    radius = default_radius_full,  # Raggio di default calcolato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# SOM con i parametri ottimizzati sull'intero dataset
som_model_optimized <- supersom(
    list(pca_values), 
    grid = som_grid_full, 
    rlen = 300,  # Iterazioni fissate a 300
    alpha = c(best_params$alpha_start, best_params$alpha_end), 
    radius = best_params$radius,  # Raggio ottimizzato
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Plot dei cambiamenti per la SOM ottimizzata
plot(som_model_optimized, type = "changes", main = "SOM Ottimizzata - Changes")

# Plot dei cambiamenti per la SOM senza ottimizzazione
plot(som_model_default, type = "changes", main = "SOM Default - Changes")

# Ottieni i codici della SOM ottimizzata
som_values_optimized <- som_model_optimized$codes[[1]]

# Ottieni i codici della SOM senza ottimizzazione
som_values_default <- som_model_default$codes[[1]]

# Esegui tclustIC per trovare il numero ottimale di cluster sulla SOM ottimizzata
tclustIC_result <- tclustIC(
    x = som_values_optimized, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione (MIXMIX, MIXCLA, CLACLA)
    parallel = TRUE,           # Esegui in parallelo
    n.cores = parallel::detectCores(),   # Utilizza tutti i core disponibili
    trace = FALSE              # Non stampare i risultati intermedi
)

# Visualizza i risultati per i criteri
plot(tclustIC_result, which = "MIXMIX")
plot(tclustIC_result, which = "MIXCLA")
plot(tclustIC_result, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix <- min(tclustIC_result$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix <- which(tclustIC_result$MIXMIX == min_value_mixmix)
G_mixmix <- max(tclustIC_result$kk[optimal_indices_mixmix])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla <- min(tclustIC_result$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla <- which(tclustIC_result$MIXCLA == min_value_mixcla)
G_mixcla <- max(tclustIC_result$kk[optimal_indices_mixcla])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla <- min(tclustIC_result$CLACLA, na.rm = TRUE)
optimal_indices_clacla <- which(tclustIC_result$CLACLA == min_value_clacla)
G_clacla <- max(tclustIC_result$kk[optimal_indices_clacla])

# Stampa i risultati ottimali
print(paste("Numero ottimale di cluster secondo MIXMIX:", G_mixmix))
print(paste("Numero ottimale di cluster secondo MIXCLA:", G_mixcla))
print(paste("Numero ottimale di cluster secondo CLACLA:", G_clacla))

# Funzione per eseguire clusterboot e stampare i risultati per ciascun criterio
run_clusterboot <- function(k_value, som_values, label) {
    cat("\nEsecuzione di clusterboot per:", label, "con k =", k_value, "\n")
    result <- clusterboot(
        data = som_values,            # Usa i valori SOM
        B = 150,                      # Numero di campioni bootstrap
        clustermethod = tclustCBI,    # Metodo tclust tramite interfaccia tclustCBI
        bootmethod = "boot",          # Usa bootstrap non parametrico
        dissolution = 0.5,            # Valore di dissoluzione per i cluster instabili
        recover = 0.75,               # Valore di recupero per i cluster stabili
        count = FALSE,                # Non mostrare il progresso durante il bootstrap
        k = k_value,                  # Numero di cluster da tclust
        trim = 0                      # Nessun outlier
    )
    
    # Stampa i risultati della stabilità dei cluster
    cat("\nRisultati della stabilità dei cluster per:", label, "\n")
    print(result$bootmean)    # Media della stabilità per ogni cluster
    print(result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
    print(result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto
    
    # Visualizzazione della stabilità
    barplot(result$bootmean, 
            main = paste("Stabilità dei Cluster -", label), 
            ylab = "Media della Similarità di Jaccard", 
            xlab = "Cluster", 
            col = "lightblue")
    
    return(result)
}

# Esegui il bootstrap per ciascun valore di cluster sulla SOM ottimizzata
clusterboot_mixmix <- run_clusterboot(G_mixmix, som_values_optimized, "MIXMIX")
clusterboot_mixcla <- run_clusterboot(G_mixcla, som_values_optimized, "MIXCLA")
clusterboot_clacla <- run_clusterboot(G_clacla, som_values_optimized, "CLACLA")

# Esegui la clusterizzazione con Mclust utilizzando G_mixmix sulla SOM ottimizzata
mclust_mixmix <- Mclust(som_values_optimized, G = G_mixmix)
# Esegui la clusterizzazione con Mclust utilizzando G_mixcla sulla SOM ottimizzata
mclust_mixcla <- Mclust(som_values_optimized, G = G_mixcla)
# Esegui la clusterizzazione con Mclust utilizzando G_clacla sulla SOM ottimizzata
mclust_clacla <- Mclust(som_values_optimized, G = G_clacla)

# Crea una maschera per identificare i pixel validi
mask <- !is.na(values(img_84[[1]]))

# Ottieni le unità SOM classificate per ogni punto del dataset
unit_classifications_optimized <- som_model_optimized$unit.classif
unit_classifications_default <- som_model_default$unit.classif

# Crea un raster classificato per ogni risultato sulla SOM ottimizzata

# Raster per MIXMIX
classified_raster_mixmix <- rast(img_84)
values(classified_raster_mixmix) <- NA
values(classified_raster_mixmix)[mask] <- mclust_mixmix$classification[unit_classifications_optimized]

# Raster per MIXCLA
classified_raster_mixcla <- rast(img_84)
values(classified_raster_mixcla) <- NA
values(classified_raster_mixcla)[mask] <- mclust_mixcla$classification[unit_classifications_optimized]

# Raster per CLACLA
classified_raster_clacla <- rast(img_84)
values(classified_raster_clacla) <- NA
values(classified_raster_clacla)[mask] <- mclust_clacla$classification[unit_classifications_optimized]

# Seleziona solo la prima banda per evitare messaggi di avvertimento
classified_raster_mixmix_single <- classified_raster_mixmix[[1]]
classified_raster_mixcla_single <- classified_raster_mixcla[[1]]
classified_raster_clacla_single <- classified_raster_clacla[[1]]

# Visualizzazione con leaflet
palette_turbo <- viridisLite::turbo

leaflet() %>% 
    addTiles(group = "OpenStreetMap") %>% 
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>% 
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>% 
    addRasterImage(classified_raster_mixmix_single, colors = palette_turbo(G_mixmix), opacity = 0.6, group = "Classificato con MIXMIX - SOM Ottimizzata") %>% 
    addRasterImage(classified_raster_mixcla_single, colors = palette_turbo(G_mixcla), opacity = 0.6, group = "Classificato con MIXCLA - SOM Ottimizzata") %>% 
    addRasterImage(classified_raster_clacla_single, colors = palette_turbo(G_clacla), opacity = 0.6, group = "Classificato con CLACLA - SOM Ottimizzata") %>% 
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
        overlayGroups = c("Classificato con MIXMIX - SOM Ottimizzata", "Classificato con MIXCLA - SOM Ottimizzata", "Classificato con CLACLA - SOM Ottimizzata"),
        options = layersControlOptions(collapsed = FALSE)
    ) %>% 
    addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>% 
    setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")

# Se desideri anche visualizzare i risultati della SOM senza parametri ottimizzati, puoi ripetere i passi con 'som_values_default'

# Esempio per la SOM senza parametri ottimizzati:

# Esegui tclustIC per la SOM senza ottimizzazione
tclustIC_result_default <- tclustIC(
    x = som_values_default, 
    kk = 2:10,                 # Numero di cluster da 2 a 10
    cc = 128,                  # Fattore di restrizione fisso a 128
    alpha = 0,                 # Nessun outlier, impostato a 0
    whichIC = "ALL",           # Calcola tutti i criteri di informazione
    parallel = TRUE,           
    n.cores = parallel::detectCores(),   
    trace = FALSE              
)

# Visualizza i risultati per i criteri
plot(tclustIC_result_default, which = "MIXMIX")
plot(tclustIC_result_default, which = "MIXCLA")
plot(tclustIC_result_default, which = "CLACLA")

# Trova il numero ottimale di cluster per MIXMIX
min_value_mixmix_def <- min(tclustIC_result_default$MIXMIX, na.rm = TRUE)
optimal_indices_mixmix_def <- which(tclustIC_result_default$MIXMIX == min_value_mixmix_def)
G_mixmix_def <- max(tclustIC_result_default$kk[optimal_indices_mixmix_def])

# Trova il numero ottimale di cluster per MIXCLA
min_value_mixcla_def <- min(tclustIC_result_default$MIXCLA, na.rm = TRUE)
optimal_indices_mixcla_def <- which(tclustIC_result_default$MIXCLA == min_value_mixcla_def)
G_mixcla_def <- max(tclustIC_result_default$kk[optimal_indices_mixcla_def])

# Trova il numero ottimale di cluster per CLACLA
min_value_clacla_def <- min(tclustIC_result_default$CLACLA, na.rm = TRUE)
optimal_indices_clacla_def <- which(tclustIC_result_default$CLACLA == min_value_clacla_def)
G_clacla_def <- max(tclustIC_result_default$kk[optimal_indices_clacla_def])

# Stampa i risultati ottimali per la SOM senza ottimizzazione
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXMIX:", G_mixmix_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo MIXCLA:", G_mixcla_def))
print(paste("SOM Senza Ottimizzazione - Numero ottimale di cluster secondo CLACLA:", G_clacla_def))

cat("Analisi completata con successo.\n")
















# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", "leaflet", "ggplot2","aweSOM", "viridisLite", "mclust", "tclust")
check_and_install(required_packages)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("L5 Composite 1984-1990_masked.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
names(l1984) <- c("B1", "B2", "B3", "B4", "B5", "B7")

# Calcola gli indici selezionati
ndvi_1984 <- (l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]])
mndwi_1984 <- (l1984[["B2"]] - l1984[["B5"]]) / (l1984[["B2"]] + l1984[["B5"]])
ndbi_1984 <- (l1984[["B5"]] - l1984[["B4"]]) / (l1984[["B5"]] + l1984[["B4"]])
bsi_1984 <- ((l1984[["B5"]] + l1984[["B3"]]) - (l1984[["B4"]] + l1984[["B1"]])) /
    ((l1984[["B5"]] + l1984[["B3"]]) + (l1984[["B4"]] + l1984[["B1"]]))
L <- 0.5
savi_1984 <- ((l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]] + L)) * (1 + L)

# Crea lo stack con le bande e gli indici selezionati
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984, bsi_1984, savi_1984)
names(stack_1984) <- c("B1", "B2", "B3", "B4", "B5", "B7", "NDVI", "MNDWI", "NDBI", "BSI", "SAVI")

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di campioni
m <- nrow(pca_values)

# Calcola il numero totale di nodi usando la formula della mappa compressa (small map)
nodes <- (5 * sqrt(m)) 
print(paste("Numero di nodi suggerito per la mappa compressa (small map):", round(nodes)))

# Suggerisci una configurazione di griglia approssimata
x_dim <- round(sqrt(nodes))
y_dim <- round(nodes / x_dim)
print(paste("Dimensioni della griglia suggerite:", x_dim, "x", y_dim))

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input e alpha = 0
som_model <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 500,
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Calcola le metriche di qualità del SOM
quality <- somQuality(som_model, as.matrix(pca_values))

# Stampa le metriche di qualità per valutare le performance del SOM
cat("Qualità della mappa SOM:\n")
cat("Quantization Error:", quality$err.quant, "\n")
cat("Percentage of Explained Variance:", quality$err.varratio, "\n")
cat("Topographic Error:", quality$err.topo, "\n")
cat("Kaski-Lagus Error:", quality$err.kaski, "\n")

# Determina il numero ottimale di cluster con NbClust
set.seed(123)
nbclust_result <- NbClust(
    data = som_values, 
    diss = NULL, 
    distance = "euclidean", 
    min.nc = 2, 
    max.nc = 10, 
    method = "kmeans", 
    index = "all"
)

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
clusterboot_result <- clusterboot(
    data = som_values, 
    B = 500, 
    clustermethod = kmeansCBI, 
    bootmethod = "boot", 
    dissolution = 0.5, 
    recover = 0.75, 
    count = FALSE, 
    k = optimal_clusters
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto

# Visualizzazione della stabilità dei cluster
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero ottimale di cluster e gestisci le iterazioni
set.seed(42)
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con il numero ottimale di cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
    addTiles(group = "OpenStreetMap") %>%
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
    addRasterImage(classified_raster_nbclust_single, 
                   colors = palette_turbo(optimal_clusters), 
                   opacity = 0.6, 
                   group = "Classificato con K-means (Optimal Clusters)") %>%
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
        overlayGroups = c("Classificato con K-means (Optimal Clusters)"),
        options = layersControlOptions(collapsed = FALSE)
    ) %>%
    addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
    setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")





















diverse griglie


# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", "leaflet", "ggplot2","aweSOM", "viridisLite", "mclust", "tclust")
check_and_install(required_packages)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
names(l1984) <- c("B1", "B2", "B3", "B4", "B5", "B7")

# Calcola gli indici selezionati
ndvi_1984 <- (l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]])
mndwi_1984 <- (l1984[["B2"]] - l1984[["B5"]]) / (l1984[["B2"]] + l1984[["B5"]])
ndbi_1984 <- (l1984[["B5"]] - l1984[["B4"]]) / (l1984[["B5"]] + l1984[["B4"]])
bsi_1984 <- ((l1984[["B5"]] + l1984[["B3"]]) - (l1984[["B4"]] + l1984[["B1"]])) /
    ((l1984[["B5"]] + l1984[["B3"]]) + (l1984[["B4"]] + l1984[["B1"]]))
L <- 0.5
savi_1984 <- ((l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]] + L)) * (1 + L)

# Crea lo stack con le bande e gli indici selezionati
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984, bsi_1984, savi_1984)
names(stack_1984) <- c("B1", "B2", "B3", "B4", "B5", "B7", "NDVI", "MNDWI", "NDBI", "BSI", "SAVI")

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di campioni
m <- nrow(pca_values)

# Definisci le formule per le diverse configurazioni di griglia
formulas <- list(
    "small_map" = (5 * sqrt(m)) / 4,
    "default_map" = 5 * sqrt(m),
    "big_map" = 20 * sqrt(m)
)

# Inizializza variabili per memorizzare i risultati
results <- list()

# Itera su ogni metodo di calcolo della griglia
for (method in names(formulas)) {
    nodes <- formulas[[method]]
    x_dim <- round(sqrt(nodes))
    y_dim <- round(nodes / x_dim)
    
    # Definisci una griglia SOM con le dimensioni calcolate
    som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")
    
    # Esegui SuperSOM con parallelizzazione usando la PCA come input
    som_model <- supersom(
        list(pca_values),
        grid = som_grid,
        rlen = 500,
        mode = "pbatch",
        cores = -1
    )
    
    # Calcola le metriche di qualità del SOM
    quality <- somQuality(som_model, as.matrix(pca_values))
    
    # Salva i risultati
    results[[method]] <- list(
        "nodes" = nodes,
        "x_dim" = x_dim,
        "y_dim" = y_dim,
        "quantization_error" = quality$err.quant,
        "variance_explained" = quality$err.varratio,
        "topographic_error" = quality$err.topo,
        "kaski_lagus_error" = quality$err.kaski
    )
}

# Confronta i risultati dei diversi metodi
for (method in names(results)) {
    cat("\nRisultati per", method, ":\n")
    cat("Numero di nodi:", round(results[[method]]$nodes), "\n")
    cat("Dimensioni della griglia:", results[[method]]$x_dim, "x", results[[method]]$y_dim, "\n")
    cat("Quantization Error:", results[[method]]$quantization_error, "\n")
    cat("Percentage of Explained Variance:", results[[method]]$variance_explained, "\n")
    cat("Topographic Error:", results[[method]]$topographic_error, "\n")
    cat("Kaski-Lagus Error:", results[[method]]$kaski_lagus_error, "\n")
}

# Seleziona il metodo che minimizza l'errore di Kaski-Lagus
best_method <- names(which.min(sapply(results, function(x) x$kaski_lagus_error)))
best_result <- results[[best_method]]

cat("\nIl metodo migliore è:", best_method, "con un errore di Kaski-Lagus di", best_result$kaski_lagus_error, "\n")

# Definisci la griglia SOM con la configurazione migliore
som_grid <- somgrid(xdim = best_result$x_dim, ydim = best_result$y_dim, topo = "hexagonal")

# Esegui SuperSOM con la configurazione migliore
som_model <- supersom(
    list(pca_values), 
    grid = som_grid, 
    rlen = 500,
    mode = "pbatch", 
    cores = -1  # Usa tutti i core disponibili
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Calcola le metriche di qualità del SOM
quality <- somQuality(som_model, as.matrix(pca_values))

# Stampa le metriche di qualità per valutare le performance del SOM
cat("\nQualità della mappa SOM (migliore griglia):\n")
cat("Quantization Error:", quality$err.quant, "\n")
cat("Percentage of Explained Variance:", quality$err.varratio, "\n")
cat("Topographic Error:", quality$err.topo, "\n")
cat("Kaski-Lagus Error:", quality$err.kaski, "\n")

# Determina il numero ottimale di cluster con NbClust
nbclust_result <- NbClust(
    data = som_values, 
    diss = NULL, 
    distance = "euclidean", 
    min.nc = 2, 
    max.nc = 10, 
    method = "kmeans", 
    index = "all"
)

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
clusterboot_result <- clusterboot(
    data = som_values, 
    B = 500, 
    clustermethod = kmeansCBI, 
    bootmethod = "boot", 
    dissolution = 0.5, 
    recover = 0.75, 
    count = FALSE, 
    k = optimal_clusters
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto

# Visualizzazione della stabilità dei cluster
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero ottimale di cluster e gestisci le iterazioni
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con il numero ottimale di cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
    addTiles(group = "OpenStreetMap") %>%
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
    addRasterImage(classified_raster_nbclust_single, 
                   colors = palette_turbo(optimal_clusters), 
                   opacity = 0.6, 
                   group = "Classificato con K-means (Optimal Clusters)") %>%
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
        overlayGroups = c("Classificato con K-means (Optimal Clusters)"),
        options = layersControlOptions(collapsed = FALSE)
    ) %>%
    addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
    setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")



# Salva il modello SOM in un file
saveRDS(som_model, file = "som_model_best_map_best_grid_ritaglio.rds")
cat("Modello SOM salvato correttamente.\n")

# Carica il modello SOM dal file
som_model <- readRDS("som_model_best_map_best_grid_ritaglio.rds")
cat("Modello SOM caricato correttamente.\n")







#solo griglia grande



# Carica le librerie necessarie
check_and_install <- function(packages) {
    installed <- packages %in% rownames(installed.packages())
    if (any(!installed)) {
        install.packages(packages[!installed])
    }
    invisible(lapply(packages, library, character.only = TRUE))
}

required_packages <- c("fpc", "NbClust", "terra", "dplyr", "kohonen", "parallel", "leaflet", "ggplot2","aweSOM", "viridisLite", "mclust", "tclust")
check_and_install(required_packages)

# Imposta la working directory
setwd("C:/composite")

# Carica il raster multibanda
img_84 <- rast("ritaglio.tif")

# Seleziona le bande necessarie (B1, B2, B3, B4, B5, B7)
l1984 <- img_84[[c(1, 2, 3, 4, 5, 6)]]
names(l1984) <- c("B1", "B2", "B3", "B4", "B5", "B7")

# Calcola gli indici selezionati
ndvi_1984 <- (l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]])
mndwi_1984 <- (l1984[["B2"]] - l1984[["B5"]]) / (l1984[["B2"]] + l1984[["B5"]])
ndbi_1984 <- (l1984[["B5"]] - l1984[["B4"]]) / (l1984[["B5"]] + l1984[["B4"]])
bsi_1984 <- ((l1984[["B5"]] + l1984[["B3"]]) - (l1984[["B4"]] + l1984[["B1"]])) /
    ((l1984[["B5"]] + l1984[["B3"]]) + (l1984[["B4"]] + l1984[["B1"]]))
L <- 0.5
savi_1984 <- ((l1984[["B4"]] - l1984[["B3"]]) / (l1984[["B4"]] + l1984[["B3"]] + L)) * (1 + L)

# Crea lo stack con le bande e gli indici selezionati
stack_1984 <- c(l1984, ndvi_1984, mndwi_1984, ndbi_1984, bsi_1984, savi_1984)
names(stack_1984) <- c("B1", "B2", "B3", "B4", "B5", "B7", "NDVI", "MNDWI", "NDBI", "BSI", "SAVI")

# Estrai i valori dal raster stack come dataframe e rimuovi i valori NA
values_stack_1984 <- as.data.frame(values(stack_1984))
values_stack_1984_non_na <- values_stack_1984[complete.cases(values_stack_1984), ]

# PCA: esegui la PCA sullo stack e seleziona le prime tre componenti principali
pca_result <- prcomp(values_stack_1984_non_na, center = TRUE, scale. = TRUE)
pca_values <- pca_result$x[, 1:3]  # Seleziona solo le prime tre componenti

# Conta il numero di campioni
m <- nrow(pca_values)

# Definisci la formula per la griglia più grande
grid_size <- 20 * sqrt(m)
x_dim <- round(sqrt(grid_size))
y_dim <- round(grid_size / x_dim)

# Definisci una griglia SOM con le dimensioni calcolate
som_grid <- somgrid(xdim = x_dim, ydim = y_dim, topo = "hexagonal")

# Esegui SuperSOM con parallelizzazione usando la PCA come input
som_model <- supersom(
    list(pca_values),
    grid = som_grid,
    rlen = 500,
    mode = "pbatch",
    cores = -1
)

# Visualizza i cambiamenti durante l'addestramento della SOM
plot(som_model, type = "changes")

# Ottieni i codici della SOM (valori ridotti dimensionalmente)
som_values <- som_model$codes[[1]]

# Calcola le metriche di qualità del SOM
quality <- somQuality(som_model, as.matrix(pca_values))

# Stampa le metriche di qualità per valutare le performance del SOM
cat("\nQualità della mappa SOM (griglia più grande):\n")
cat("Quantization Error:", quality$err.quant, "\n")
cat("Percentage of Explained Variance:", quality$err.varratio, "\n")
cat("Topographic Error:", quality$err.topo, "\n")
cat("Kaski-Lagus Error:", quality$err.kaski, "\n")

# Determina il numero ottimale di cluster con NbClust
nbclust_result <- NbClust(
    data = som_values, 
    diss = NULL, 
    distance = "euclidean", 
    min.nc = 2, 
    max.nc = 10, 
    method = "kmeans", 
    index = "all"
)

# Trova il numero ottimale di cluster dalla moda dei risultati
optimal_clusters <- as.numeric(names(which.max(table(nbclust_result$Best.nc[1, ]))))
cat("Il numero ottimale di cluster secondo NbClust è:", optimal_clusters, "\n")

# Usa il numero ottimale di cluster con clusterboot e kmeansCBI
clusterboot_result <- clusterboot(
    data = som_values, 
    B = 500, 
    clustermethod = kmeansCBI, 
    bootmethod = "boot", 
    dissolution = 0.5, 
    recover = 0.75, 
    count = FALSE, 
    k = optimal_clusters
)

# Stampa i risultati della stabilità dei cluster
cat("Risultati della stabilità dei cluster con clusterboot:\n")
print(clusterboot_result$bootmean)    # Media della stabilità per ogni cluster
print(clusterboot_result$bootrecover) # Numero di volte che ogni cluster è stato recuperato
print(clusterboot_result$bootbrd)     # Numero di volte che ogni cluster è stato dissolto

# Visualizzazione della stabilità dei cluster
barplot(clusterboot_result$bootmean, 
        main = "Stabilità dei Cluster con K-means e Bootstrap", 
        ylab = "Media della Similarità di Jaccard", 
        xlab = "Cluster", 
        col = "lightblue")

# Esegui K-means con il numero ottimale di cluster e gestisci le iterazioni
kmeans_nbclust <- kmeans(som_values, centers = optimal_clusters, nstart = 100, iter.max = 1000)

# Crea un raster classificato usando i cluster di K-means con il numero ottimale di cluster
classified_raster_nbclust <- rast(img_84)
values(classified_raster_nbclust) <- NA
mask <- !is.na(values(img_84[[1]]))
values(classified_raster_nbclust)[mask] <- kmeans_nbclust$cluster[som_model$unit.classif]

# Seleziona solo la prima banda del raster per evitare messaggi di avvertimento
classified_raster_nbclust_single <- classified_raster_nbclust[[1]]

# Carica la palette turbo
palette_turbo <- viridisLite::turbo

# Visualizza il raster classificato con leaflet
leaflet() %>%
    addTiles(group = "OpenStreetMap") %>%
    addProviderTiles("Esri.WorldImagery", group = "Immagine Satellitare") %>%
    addProviderTiles("CartoDB.Positron", group = "Mappa Chiara") %>%
    addRasterImage(classified_raster_nbclust_single, 
                   colors = palette_turbo(optimal_clusters), 
                   opacity = 0.6, 
                   group = "Classificato con K-means (Optimal Clusters)") %>%
    addLayersControl(
        baseGroups = c("OpenStreetMap", "Immagine Satellitare", "Mappa Chiara"),
        overlayGroups = c("Classificato con K-means (Optimal Clusters)"),
        options = layersControlOptions(collapsed = FALSE)
    ) %>%
    addScaleBar(position = "bottomright", options = scaleBarOptions(imperial = FALSE)) %>%
    setView(lng = 16.5, lat = 39.0, zoom = 10)

cat("Visualizzazione completata con successo.\n")
