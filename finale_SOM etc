# Carica le librerie necessarie
library(terra)
library(kohonen)
library(parallel)

# Misura il tempo di esecuzione dell'intero script
start_time <- Sys.time()

# Funzione per la normalizzazione Min-Max
normalize <- function(x) {
    (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

# Funzione per elaborare una singola immagine
process_image <- function(image_path) {
    # Carica il raster multibanda e calcola gli indici
    raster_image <- rast(image_path)
    ndvi <- (raster_image[[4]] - raster_image[[3]]) / (raster_image[[4]] + raster_image[[3]])
    mndwi <- (raster_image[[2]] - raster_image[[5]]) / (raster_image[[2]] + raster_image[[5]])
    ndbi <- (raster_image[[5]] - raster_image[[4]]) / (raster_image[[5]] + raster_image[[4]])
    
    # Crea lo stack con bande e indici
    stacked_raster <- c(raster_image, ndvi, mndwi, ndbi)
    
    # Estrai i valori come matrice, rimuovi NA e normalizza
    matrix_values <- values(stacked_raster)
    cleaned_matrix <- matrix_values[complete.cases(matrix_values), ]
    normalized_matrix <- apply(cleaned_matrix, 2, normalize)
    
    # Calcola il numero totale di neuroni e definisci la griglia SOM
    num_observations <- nrow(normalized_matrix)
    total_neurons <- 5 * sqrt(num_observations)
    grid_x <- round(sqrt(total_neurons))
    grid_y <- round(total_neurons / grid_x)
    som_grid <- somgrid(xdim = grid_x, ydim = grid_y, topo = "hexagonal")
    
    # Esegui SuperSOM con parallelizzazione
    som_model <- supersom(
        list(normalized_matrix), 
        grid = som_grid, 
        rlen = 10, 
        mode = "pbatch", 
        cores = -1
    )
    
    # Salva il modello SOM
    output_path <- file.path("C:/Sila/som_sila", paste0(basename(image_path), "_som_model.rds"))
    saveRDS(som_model, output_path)
}

# Itera su diverse immagini
image_paths <- list.files(path = "C:/Sila", pattern = "\\.tif$", full.names = TRUE)
for (image_path in image_paths) {
    process_image(image_path)
}

# Calcola e stampa il tempo totale di esecuzione
total_time <- Sys.time() - start_time
cat("Tempo totale di esecuzione:", total_time, "\n")















#nblcust itereato sempplice
# ====================================================
# Sezione 1: Caricamento delle librerie
# ====================================================
library(kohonen)   # Per leggere i modelli SOM
library(NbClust)   # Per determinare il numero ottimale di cluster
library(dplyr)     # Per organizzare i risultati
library(tidyr)     # Per riorganizzare i conteggi in formato tabellare
library(openxlsx)  # Per salvare i risultati in Excel

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================
rds_dir <- "C:/Aspromonte/som_aspromonte"  # Directory dei file SOM
rds_files <- list.files(path = rds_dir, pattern = "\\.rds$", full.names = TRUE)  # Trova i file RDS

# ====================================================
# Sezione 3: Calcolo del numero ottimale di cluster
# ====================================================
results <- lapply(rds_files, function(rds_path) {
    cat("\nProcesso il file:", basename(rds_path), "\n")
    som_model <- readRDS(rds_path)  # Carica il modello SOM
    som_values <- som_model$codes[[1]]  # Estrai le codebook

    # Calcola il numero ottimale di cluster
    nbclust_result <- NbClust(data = som_values, distance = "euclidean", min.nc = 3, max.nc = 15, method = "kmeans", index = "all")
    
    # Calcola la distribuzione dei cluster suggeriti
    cluster_counts <- table(nbclust_result$Best.nc[1, ])
    
    # Numero ottimale di cluster e supporto massimo
    optimal_clusters <- as.numeric(names(which.max(cluster_counts)))
    support_count <- max(cluster_counts)

    # Estrai il range di anni dal nome del file
    dates <- regmatches(basename(rds_path), gregexpr("\\d{4}", basename(rds_path)))[[1]]
    year_range <- if (length(dates) == 2) paste(dates[1], "-", dates[2]) else "range non trovato"

    # Salva i conteggi dei cluster come stringa per output
    cluster_distribution <- paste(names(cluster_counts), cluster_counts, sep = ":", collapse = "; ")

    # Ritorna i risultati
    tibble(
        File = basename(rds_path),
        Year_Range = year_range,
        Optimal_Clusters = optimal_clusters,
        Support_Count = support_count,
        Cluster_Distribution = cluster_distribution
    )
})

# ====================================================
# Sezione 4: Risultati finali
# ====================================================
results_summary <- bind_rows(results)
print(results_summary)

# ====================================================
# Sezione 5: Salvataggio in formato Excel
# ====================================================
output_excel_path <- "C:/Aspromonte/nbclust_full_results.xlsx"
write.xlsx(results_summary, file 















#clusterboot semplice semplice
# ====================================================
# Sezione 1: Caricamento delle librerie
# ====================================================
library(kohonen)    # Per leggere i modelli SOM
library(fpc)        # Per Clusterboot
library(tibble)     # Per organizzare i risultati
library(openxlsx)   # Per salvare i risultati in Excel

# ====================================================
# Sezione 2: Impostazioni iniziali
# ====================================================
rds_dir <- "C:/Aspromonte/som_aspromonte"  # Directory dei file SOM
rds_files <- list.files(path = rds_dir, pattern = "\\.rds$", full.names = TRUE)  # Trova i file RDS
optimal_clusters <- 4  # Numero di cluster predefinito

# ====================================================
# Sezione 3: Clusterboot per ogni SOM
# ====================================================
results <- lapply(rds_files, function(rds_path) {
    cat("\nProcesso il file:", basename(rds_path), "\n")
    som_model <- readRDS(rds_path)  # Carica il modello SOM
    som_values <- som_model$codes[[1]]  # Estrai le codebook

    # Esegui Clusterboot
    clusterboot_result <- clusterboot(
        data = som_values, 
        B = 500, 
        clustermethod = kmeansCBI, 
        bootmethod = "boot", 
        dissolution = 0.5, 
        recover = 0.75, 
        k = optimal_clusters
    )

    # Estrai stabilitÃ  dei cluster
    cluster_stability <- clusterboot_result$bootmean

    # Estrai il range di anni dal nome del file
    dates <- regmatches(basename(rds_path), gregexpr("\\d{4}", basename(rds_path)))[[1]]
    year_range <- if (length(dates) == 2) paste(dates[1], "-", dates[2]) else "range non trovato"

    # Ritorna il risultato
    tibble(File = basename(rds_path), Year_Range = year_range, Cluster_Stability = cluster_stability)
})

# ====================================================
# Sezione 4: Risultati finali
# ====================================================
results_summary <- bind_rows(results)  # Combina i risultati in un'unica tabella
print(results_summary)

# ====================================================
# Sezione 5: Salvataggio in Excel
# ====================================================
output_excel_path <- "C:/Aspromonte/clusterboot_results.xlsx"
write.xlsx(results_summary, file = output_excel_path, rowNames = FALSE)
cat("\nRisultati salvati in formato Excel:", output_excel_path, "\n")

